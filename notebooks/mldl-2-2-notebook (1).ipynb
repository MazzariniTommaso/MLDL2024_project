{"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1XNh4ReVvaCnFcvxsLVHahkWxy2OqKrm4","authorship_tag":"ABX9TyOekpKEeKXtTbQhIZpLmV9P"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8412080,"sourceType":"datasetVersion","datasetId":5006755},{"sourceId":8412108,"sourceType":"datasetVersion","datasetId":5006778}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classic semantic segmentation network\nFor this step, you have to train a classic segmentation network (**DeepLabV2** [2]) on the Cityscapes dataset.\n- Dataset: **Cityscapes** [5]\n- Training epochs: 50\n- Training resolution (Cityscapes): 1024x512\n- Test resolution (Cityscapes): 1024x512\n- Backbone: **R101** (pre-trained on ImageNet) [2]\n- Semantic classes: 19\n- Metrics: Mean Intersection over Union (**mIoU**) [read this to understand the metrics], **latency**, **FLOPs**, number of **parameters**.\n","metadata":{"id":"OAZEiffSoALO"}},{"cell_type":"code","source":"!pip install -U fvcore","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:06:24.637485Z","iopub.execute_input":"2024-05-17T14:06:24.637833Z","iopub.status.idle":"2024-05-17T14:06:44.551819Z","shell.execute_reply.started":"2024-05-17T14:06:24.637806Z","shell.execute_reply":"2024-05-17T14:06:44.550918Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting fvcore\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m731.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore) (1.26.4)\nCollecting yacs>=0.1.6 (from fvcore)\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (6.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fvcore) (4.66.1)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (2.4.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from fvcore) (9.5.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.9.0)\nCollecting iopath>=0.1.7 (from fvcore)\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore) (4.9.0)\nCollecting portalocker (from iopath>=0.1.7->fvcore)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: fvcore, iopath\n  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=de29dee81604a5333d81cd7a4d0500dabe61d3b9fa922a1cea29bd26995c1af8\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=a82b0bbbc92214b9610567ebfb5f1e947c078a684d1738168e40af59fe481bed\n  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\nSuccessfully built fvcore iopath\nInstalling collected packages: yacs, portalocker, iopath, fvcore\nSuccessfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.8.2 yacs-0.1.8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 0 - Import libraries","metadata":{"id":"cNa1Un4uoZ6M"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nimport torch.optim as optim\n\nimport os\nimport zipfile\nimport numpy as np\nimport time\nfrom PIL import Image\nfrom fvcore.nn import FlopCountAnalysis, flop_count_table","metadata":{"id":"mYTc9GfSouYh","executionInfo":{"status":"ok","timestamp":1715695760300,"user_tz":-120,"elapsed":13275,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"}},"execution":{"iopub.status.busy":"2024-05-17T14:06:44.553691Z","iopub.execute_input":"2024-05-17T14:06:44.553971Z","iopub.status.idle":"2024-05-17T14:06:54.212357Z","shell.execute_reply.started":"2024-05-17T14:06:44.553947Z","shell.execute_reply":"2024-05-17T14:06:54.211448Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:06:54.213571Z","iopub.execute_input":"2024-05-17T14:06:54.214050Z","iopub.status.idle":"2024-05-17T14:06:54.282842Z","shell.execute_reply.started":"2024-05-17T14:06:54.214004Z","shell.execute_reply":"2024-05-17T14:06:54.281801Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"# 1 - Dataset","metadata":{"id":"sKK0P3Aloi9U"}},{"cell_type":"code","source":"class CityScapes(Dataset):\n    def __init__(self, root_dir, split='train', image_transform=None, label_transform=None):\n        super(CityScapes, self).__init__()\n        \"\"\"\n        Args:\n            root_dir (string): Directory with all the images and annotations.\n            split (string): 'train' or 'val'.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n\n        self.root_dir = root_dir\n        self.split = split\n        self.image_transform = image_transform\n        self.label_transform = label_transform\n\n        # Get the image and label directories\n        self.image_dir = os.path.join(root_dir, 'images', split)\n        self.label_dir = os.path.join(root_dir, 'gtFine', split)\n\n        # Get a list of all image files\n        self.image_files = []\n        for city_dir in os.listdir(self.image_dir):\n            city_image_dir = os.path.join(self.image_dir, city_dir)\n            self.image_files.extend([os.path.join(city_image_dir, f) for f in os.listdir(city_image_dir) if f.endswith('.png')])\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_name = self.image_files[idx]\n\n        # Get the corresponding label image path\n        label_name = img_name.replace('images', 'gtFine').replace('_leftImg8bit', '_gtFine_labelTrainIds')\n\n        # Load image and label\n        image = Image.open(img_name).convert('RGB')\n        label = Image.open(label_name).convert('L')\n\n        #print(np.unique(np.array(label).reshape(np.array(label).shape[0] * np.array(label).shape[1])).size)\n\n        if self.image_transform:\n            image = self.image_transform(image)\n        if self.label_transform:\n            label = self.label_transform(label)\n\n        #print(np.unique(np.array(label).reshape(np.array(label).shape[0] * np.array(label).shape[1])).size)\n\n        label = torch.Tensor(np.array(label))\n\n        return image, label","metadata":{"id":"TE5jHHpwaduG","executionInfo":{"status":"ok","timestamp":1715695833931,"user_tz":-120,"elapsed":3,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"}},"execution":{"iopub.status.busy":"2024-05-17T14:06:54.284986Z","iopub.execute_input":"2024-05-17T14:06:54.285266Z","iopub.status.idle":"2024-05-17T14:06:54.301939Z","shell.execute_reply.started":"2024-05-17T14:06:54.285242Z","shell.execute_reply":"2024-05-17T14:06:54.301286Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# 2 - Models","metadata":{"id":"breeFfksou_h"}},{"cell_type":"markdown","source":"## 2.1 - DeepLabV2","metadata":{}},{"cell_type":"code","source":"affine_par = True\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par)\n        for i in self.bn1.parameters():\n            i.requires_grad = False\n        padding = dilation\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n                               padding=padding, bias=False, dilation=dilation)\n        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n        for i in self.bn2.parameters():\n            i.requires_grad = False\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n        for i in self.bn3.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n        out = self.bn3(out)\n        if self.downsample is not None:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ClassifierModule(nn.Module):\n    def __init__(self, inplanes, dilation_series, padding_series, num_classes):\n        super(ClassifierModule, self).__init__()\n        self.conv2d_list = nn.ModuleList()\n        for dilation, padding in zip(dilation_series, padding_series):\n            self.conv2d_list.append(\n                nn.Conv2d(inplanes, num_classes, kernel_size=3, stride=1, padding=padding,\n                          dilation=dilation, bias=True))\n\n        for m in self.conv2d_list:\n            m.weight.data.normal_(0, 0.01)\n\n    def forward(self, x):\n        out = self.conv2d_list[0](x)\n        for i in range(len(self.conv2d_list) - 1):\n            out += self.conv2d_list[i + 1](x)\n        return out\n\n\nclass ResNetMulti(nn.Module):\n    def __init__(self, block, layers, num_classes):\n        self.inplanes = 64\n        super(ResNetMulti, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n        for i in self.bn1.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n        self.layer6 = ClassifierModule(2048, [6, 12, 18, 24], [6, 12, 18, 24], num_classes)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                m.weight.data.normal_(0, 0.01)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n        downsample = None\n        if (stride != 1\n                or self.inplanes != planes * block.expansion\n                or dilation == 2\n                or dilation == 4):\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion, affine=affine_par))\n        for i in downsample._modules['1'].parameters():\n            i.requires_grad = False\n        layers = []\n        layers.append(\n            block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, dilation=dilation))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        _, _, H, W = x.size()\n\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer6(x)\n\n        x = torch.nn.functional.interpolate(x, size=(H, W), mode='bilinear')\n\n        if self.training == True:\n            return x, None, None\n\n        return x\n\n    def get_1x_lr_params_no_scale(self):\n        \"\"\"\n        This generator returns all the parameters of the net except for\n        the last classification layer. Note that for each batchnorm layer,\n        requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n        any batchnorm parameter\n        \"\"\"\n        b = []\n\n        b.append(self.conv1)\n        b.append(self.bn1)\n        b.append(self.layer1)\n        b.append(self.layer2)\n        b.append(self.layer3)\n        b.append(self.layer4)\n\n        for i in range(len(b)):\n            for j in b[i].modules():\n                jj = 0\n                for k in j.parameters():\n                    jj += 1\n                    if k.requires_grad:\n                        yield k\n\n    def get_10x_lr_params(self):\n        \"\"\"\n        This generator returns all the parameters for the last layer of the net,\n        which does the classification of pixel into classes\n        \"\"\"\n        b = []\n        if self.multi_level:\n            b.append(self.layer5.parameters())\n        b.append(self.layer6.parameters())\n\n        for j in range(len(b)):\n            for i in b[j]:\n                yield i\n\n    def optim_parameters(self, lr):\n        return [{'params': self.get_1x_lr_params_no_scale(), 'lr': lr},\n                {'params': self.get_10x_lr_params(), 'lr': 10 * lr}]\n\n\ndef get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='DeepLab_resnet_pretrained_imagenet.pth'):\n    model = ResNetMulti(Bottleneck, [3, 4, 23, 3], num_classes)\n\n    # Pretraining loading\n    if pretrain:\n        print('Deeplab pretraining loading...')\n        saved_state_dict = torch.load(pretrain_model_path)\n\n        new_params = model.state_dict().copy()\n        for i in saved_state_dict:\n            i_parts = i.split('.')\n            new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n        model.load_state_dict(new_params, strict=False)\n\n    return model\n\n# Define the model (DeepLabV2 with ResNet-101 backbone)\npretrain_model_path = '/kaggle/input/model-weight/deeplab_resnet_pretrained_imagenet.pth'\nmodel = get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path=pretrain_model_path).cuda()","metadata":{"id":"sOluxCUSo6TN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715695905826,"user_tz":-120,"elapsed":12513,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"}},"outputId":"18e9c583-19cc-4b94-f206-b30ba08384cb","_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-17T14:06:54.302991Z","iopub.execute_input":"2024-05-17T14:06:54.303244Z","iopub.status.idle":"2024-05-17T14:06:57.455445Z","shell.execute_reply.started":"2024-05-17T14:06:54.303222Z","shell.execute_reply":"2024-05-17T14:06:57.454476Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Deeplab pretraining loading...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2.2 - Bisenet","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:06:57.456755Z","iopub.execute_input":"2024-05-17T14:06:57.457123Z","iopub.status.idle":"2024-05-17T14:06:57.461632Z","shell.execute_reply.started":"2024-05-17T14:06:57.457091Z","shell.execute_reply":"2024-05-17T14:06:57.460777Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class resnet18(torch.nn.Module):\n    def __init__(self, pretrained=True):\n        super().__init__()\n        self.features = models.resnet18(pretrained=pretrained)\n        self.conv1 = self.features.conv1\n        self.bn1 = self.features.bn1\n        self.relu = self.features.relu\n        self.maxpool1 = self.features.maxpool\n        self.layer1 = self.features.layer1\n        self.layer2 = self.features.layer2\n        self.layer3 = self.features.layer3\n        self.layer4 = self.features.layer4\n\n    def forward(self, input):\n        x = self.conv1(input)\n        x = self.relu(self.bn1(x))\n        x = self.maxpool1(x)\n        feature1 = self.layer1(x)  # 1 / 4\n        feature2 = self.layer2(feature1)  # 1 / 8\n        feature3 = self.layer3(feature2)  # 1 / 16\n        feature4 = self.layer4(feature3)  # 1 / 32\n        # global average pooling to build tail\n        tail = torch.mean(feature4, 3, keepdim=True)\n        tail = torch.mean(tail, 2, keepdim=True)\n        return feature3, feature4, tail\n\n\nclass resnet101(torch.nn.Module):\n    def __init__(self, pretrained=True):\n        super().__init__()\n        self.features = models.resnet101(pretrained=pretrained)\n        self.conv1 = self.features.conv1\n        self.bn1 = self.features.bn1\n        self.relu = self.features.relu\n        self.maxpool1 = self.features.maxpool\n        self.layer1 = self.features.layer1\n        self.layer2 = self.features.layer2\n        self.layer3 = self.features.layer3\n        self.layer4 = self.features.layer4\n\n    def forward(self, input):\n        x = self.conv1(input)\n        x = self.relu(self.bn1(x))\n        x = self.maxpool1(x)\n        feature1 = self.layer1(x)  # 1 / 4\n        feature2 = self.layer2(feature1)  # 1 / 8\n        feature3 = self.layer3(feature2)  # 1 / 16\n        feature4 = self.layer4(feature3)  # 1 / 32\n        # global average pooling to build tail\n        tail = torch.mean(feature4, 3, keepdim=True)\n        tail = torch.mean(tail, 2, keepdim=True)\n        return feature3, feature4, tail\n\n\ndef build_contextpath(name):\n    model = {\n        'resnet18': resnet18(pretrained=True),\n        'resnet101': resnet101(pretrained=True)\n    }\n    return model[name]","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:06:57.463042Z","iopub.execute_input":"2024-05-17T14:06:57.463318Z","iopub.status.idle":"2024-05-17T14:06:57.477222Z","shell.execute_reply.started":"2024-05-17T14:06:57.463295Z","shell.execute_reply":"2024-05-17T14:06:57.476373Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class ConvBlock(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n                               stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU()\n\n    def forward(self, input):\n        x = self.conv1(input)\n        return self.relu(self.bn(x))\n\n\nclass Spatial_path(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.convblock1 = ConvBlock(in_channels=3, out_channels=64)\n        self.convblock2 = ConvBlock(in_channels=64, out_channels=128)\n        self.convblock3 = ConvBlock(in_channels=128, out_channels=256)\n\n    def forward(self, input):\n        x = self.convblock1(input)\n        x = self.convblock2(x)\n        x = self.convblock3(x)\n        return x\n\n\nclass AttentionRefinementModule(torch.nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.sigmoid = nn.Sigmoid()\n        self.in_channels = in_channels\n        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n\n    def forward(self, input):\n        # global average pooling\n        x = self.avgpool(input)\n        assert self.in_channels == x.size(1), 'in_channels and out_channels should all be {}'.format(x.size(1))\n        x = self.conv(x)\n        x = self.sigmoid(self.bn(x))\n        # x = self.sigmoid(x)\n        # channels of input and x should be same\n        x = torch.mul(input, x)\n        return x\n\n\nclass FeatureFusionModule(torch.nn.Module):\n    def __init__(self, num_classes, in_channels):\n        super().__init__()\n        # self.in_channels = input_1.channels + input_2.channels\n        # resnet101 3328 = 256(from spatial path) + 1024(from context path) + 2048(from context path)\n        # resnet18  1024 = 256(from spatial path) + 256(from context path) + 512(from context path)\n        self.in_channels = in_channels\n\n        self.convblock = ConvBlock(in_channels=self.in_channels, out_channels=num_classes, stride=1)\n        self.conv1 = nn.Conv2d(num_classes, num_classes, kernel_size=1)\n        self.relu = nn.ReLU()\n        self.conv2 = nn.Conv2d(num_classes, num_classes, kernel_size=1)\n        self.sigmoid = nn.Sigmoid()\n        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n\n    def forward(self, input_1, input_2):\n        x = torch.cat((input_1, input_2), dim=1)\n        assert self.in_channels == x.size(1), 'in_channels of ConvBlock should be {}'.format(x.size(1))\n        feature = self.convblock(x)\n        x = self.avgpool(feature)\n\n        x = self.relu(self.conv1(x))\n        x = self.sigmoid(self.conv2(x))\n        x = torch.mul(feature, x)\n        x = torch.add(x, feature)\n        return x\n\n\nclass BiSeNet(torch.nn.Module):\n    def __init__(self, num_classes, context_path):\n        super().__init__()\n        # build spatial path\n        self.saptial_path = Spatial_path()\n\n        # build context path\n        self.context_path = build_contextpath(name=context_path)\n\n        # build attention refinement module  for resnet 101\n        if context_path == 'resnet101':\n            self.attention_refinement_module1 = AttentionRefinementModule(1024, 1024)\n            self.attention_refinement_module2 = AttentionRefinementModule(2048, 2048)\n            # supervision block\n            self.supervision1 = nn.Conv2d(in_channels=1024, out_channels=num_classes, kernel_size=1)\n            self.supervision2 = nn.Conv2d(in_channels=2048, out_channels=num_classes, kernel_size=1)\n            # build feature fusion module\n            self.feature_fusion_module = FeatureFusionModule(num_classes, 3328)\n\n        elif context_path == 'resnet18':\n            # build attention refinement module  for resnet 18\n            self.attention_refinement_module1 = AttentionRefinementModule(256, 256)\n            self.attention_refinement_module2 = AttentionRefinementModule(512, 512)\n            # supervision block\n            self.supervision1 = nn.Conv2d(in_channels=256, out_channels=num_classes, kernel_size=1)\n            self.supervision2 = nn.Conv2d(in_channels=512, out_channels=num_classes, kernel_size=1)\n            # build feature fusion module\n            self.feature_fusion_module = FeatureFusionModule(num_classes, 1024)\n        else:\n            print('Error: unspport context_path network \\n')\n\n        # build final convolution\n        self.conv = nn.Conv2d(in_channels=num_classes, out_channels=num_classes, kernel_size=1)\n\n        self.init_weight()\n\n        self.mul_lr = []\n        self.mul_lr.append(self.saptial_path)\n        self.mul_lr.append(self.attention_refinement_module1)\n        self.mul_lr.append(self.attention_refinement_module2)\n        self.mul_lr.append(self.supervision1)\n        self.mul_lr.append(self.supervision2)\n        self.mul_lr.append(self.feature_fusion_module)\n        self.mul_lr.append(self.conv)\n\n    def init_weight(self):\n        for name, m in self.named_modules():\n            if 'context_path' not in name:\n                if isinstance(m, nn.Conv2d):\n                    nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n                elif isinstance(m, nn.BatchNorm2d):\n                    m.eps = 1e-5\n                    m.momentum = 0.1\n                    nn.init.constant_(m.weight, 1)\n                    nn.init.constant_(m.bias, 0)\n\n    def forward(self, input):\n        # output of spatial path\n        sx = self.saptial_path(input)\n\n        # output of context path\n        cx1, cx2, tail = self.context_path(input)\n        cx1 = self.attention_refinement_module1(cx1)\n        cx2 = self.attention_refinement_module2(cx2)\n        cx2 = torch.mul(cx2, tail)\n        # upsampling\n        cx1 = torch.nn.functional.interpolate(cx1, size=sx.size()[-2:], mode='bilinear')\n        cx2 = torch.nn.functional.interpolate(cx2, size=sx.size()[-2:], mode='bilinear')\n        cx = torch.cat((cx1, cx2), dim=1)\n\n        if self.training == True:\n            cx1_sup = self.supervision1(cx1)\n            cx2_sup = self.supervision2(cx2)\n            cx1_sup = torch.nn.functional.interpolate(cx1_sup, size=input.size()[-2:], mode='bilinear')\n            cx2_sup = torch.nn.functional.interpolate(cx2_sup, size=input.size()[-2:], mode='bilinear')\n\n        # output of feature fusion module\n        result = self.feature_fusion_module(sx, cx)\n\n        # upsampling\n        result = torch.nn.functional.interpolate(result, scale_factor=8, mode='bilinear')\n        result = self.conv(result)\n\n        if self.training == True:\n            return result, cx1_sup, cx2_sup\n\n        return result","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:06:57.478485Z","iopub.execute_input":"2024-05-17T14:06:57.479024Z","iopub.status.idle":"2024-05-17T14:06:57.511649Z","shell.execute_reply.started":"2024-05-17T14:06:57.478994Z","shell.execute_reply":"2024-05-17T14:06:57.510775Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# 3 - WANDB","metadata":{}},{"cell_type":"markdown","source":"## 3.1 - Install WANDB","metadata":{}},{"cell_type":"code","source":"# WANDB\n!pip install -q wandb\n\n# import the library\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:06:57.512837Z","iopub.execute_input":"2024-05-17T14:06:57.513346Z","iopub.status.idle":"2024-05-17T14:07:10.970905Z","shell.execute_reply.started":"2024-05-17T14:06:57.513315Z","shell.execute_reply":"2024-05-17T14:07:10.969950Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"wandb.login()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:10.973411Z","iopub.execute_input":"2024-05-17T14:07:10.973714Z","iopub.status.idle":"2024-05-17T14:07:33.885568Z","shell.execute_reply.started":"2024-05-17T14:07:10.973689Z","shell.execute_reply":"2024-05-17T14:07:33.884733Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## 3.2 - PIPELINE","metadata":{}},{"cell_type":"code","source":"def model_pipeline(config=None):\n\n    # tell wandb to get started\n    with wandb.init(config=config):\n        # access all HPs through wandb.config, so logging matches execution!\n        config = wandb.config\n\n        # make the model, data, and optimization problem\n        model, train_loader, val_loader, criterion, optimizer = make(config)\n        #print(model)\n\n        # and use them to train the model\n        train(model, train_loader, criterion, optimizer, config)\n\n        # and test its final performance\n        val(model, val_loader)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:41.775576Z","iopub.execute_input":"2024-05-17T14:07:41.776568Z","iopub.status.idle":"2024-05-17T14:07:41.781837Z","shell.execute_reply.started":"2024-05-17T14:07:41.776535Z","shell.execute_reply":"2024-05-17T14:07:41.781012Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def make(config):\n    # Make the data\n    train, test = get_data(train=True), get_data(train=False)\n    train_loader = make_loader(train, batch_size=config.batch_size,train=True)\n    test_loader = make_loader(test, batch_size=config.batch_size,train=False)\n\n    # Make the model (DeepLabV2 with ResNet-101 backbone)\n    pretrain_model_path = '/kaggle/input/model-weight/deeplab_resnet_pretrained_imagenet.pth'\n    model = get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path=pretrain_model_path).cuda()\n\n    # Make the loss and optimizer\n    optimizer = optim.SGD(model.parameters(), \n                          lr=config.learning_rate, \n                          momentum=0.9, \n                          weight_decay=5e-4)\n    \n    criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n    \n    return model, train_loader, test_loader, criterion, optimizer","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:42.056237Z","iopub.execute_input":"2024-05-17T14:07:42.056862Z","iopub.status.idle":"2024-05-17T14:07:42.063382Z","shell.execute_reply.started":"2024-05-17T14:07:42.056830Z","shell.execute_reply":"2024-05-17T14:07:42.062554Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Define transforms for preprocessing\nimage_transform = transforms.Compose([\n        transforms.Resize((256,512)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\nlabel_transform = transforms.Compose([\n        transforms.Resize((256,512)),\n    ])\n\nroot_dir ='/kaggle/input/cityscapes/Cityscapes/Cityspaces'\n\ndef get_data(train=True):\n    if train == True:\n        # train dataset\n        dataset = CityScapes(root_dir=root_dir, split='train', image_transform=image_transform, label_transform=label_transform)\n    else:\n        # test dataset\n        dataset = CityScapes(root_dir=root_dir, split='val', image_transform=image_transform, label_transform=label_transform)\n    \n    return dataset\n\n\ndef make_loader(dataset, batch_size = 8, train=True):\n    if train == True:\n        # train dataloader\n        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n    else:\n        # test dataloader\n        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False,drop_last=True)\n    \n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:42.381829Z","iopub.execute_input":"2024-05-17T14:07:42.382126Z","iopub.status.idle":"2024-05-17T14:07:42.390574Z","shell.execute_reply.started":"2024-05-17T14:07:42.382100Z","shell.execute_reply":"2024-05-17T14:07:42.389766Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train_log(loss, mIOU, epoch):\n    #wandb.log({\"epoch\": epoch, \"loss\": loss, \"mIOU\":mIOU})\n    wandb.log({\"loss\": loss, \"mIOU\":mIOU}, step= epoch)\n    print(f\"----------------------------------\")\n    print(f\"Loss after {epoch+1} epochs: {loss:.3f}\")\n    print(f\"mIOU after {epoch+1} epochs: {mIOU:.3f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:42.666390Z","iopub.execute_input":"2024-05-17T14:07:42.666802Z","iopub.status.idle":"2024-05-17T14:07:42.671635Z","shell.execute_reply.started":"2024-05-17T14:07:42.666773Z","shell.execute_reply":"2024-05-17T14:07:42.670799Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def id_processing(targets):\n    targets = targets.cuda()\n    \n    # Define valid indices\n    valid_indices = torch.tensor(list(range(19)) + [255]).to(targets.device)\n\n    # Replace all IDs not in valid_indices with 255\n    processed_targets = torch.where(torch.isin(targets, valid_indices), targets, torch.tensor(255, device=targets.device))\n\n    return processed_targets.long()","metadata":{"id":"Bp4cfr1Ho3zW","executionInfo":{"status":"ok","timestamp":1715695909918,"user_tz":-120,"elapsed":228,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"}},"execution":{"iopub.status.busy":"2024-05-17T14:07:42.951357Z","iopub.execute_input":"2024-05-17T14:07:42.951675Z","iopub.status.idle":"2024-05-17T14:07:42.957266Z","shell.execute_reply.started":"2024-05-17T14:07:42.951649Z","shell.execute_reply":"2024-05-17T14:07:42.956369Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def fast_hist(a, b, n):\n    \"\"\"\n    a and b are predict and mask respectively\n    n is the number of classes\n    \"\"\"\n    k = (a >= 0) & (a < n) #assign True if the value is in the range between 0 and 18 (class labels)\n    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape((n, n))\n\n\ndef per_class_iou(hist):\n    epsilon = 1e-5\n    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)\n\ndef mean_iou(num_classes, pred, target):\n    mIOU = 0\n    for i in range(len(pred)):\n        hist = fast_hist(target[i].cpu().numpy(),pred[i].cpu().numpy(), num_classes)\n        IOU = per_class_iou(hist)\n        mIOU = mIOU + sum(IOU)/num_classes\n    return mIOU","metadata":{"id":"xS_SVdgSa-KG","executionInfo":{"status":"ok","timestamp":1715695912879,"user_tz":-120,"elapsed":2,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"}},"execution":{"iopub.status.busy":"2024-05-17T14:07:43.284974Z","iopub.execute_input":"2024-05-17T14:07:43.285706Z","iopub.status.idle":"2024-05-17T14:07:43.294052Z","shell.execute_reply.started":"2024-05-17T14:07:43.285673Z","shell.execute_reply":"2024-05-17T14:07:43.293027Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloader, criterion, optimizer, config):\n    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n\n    # Run training and track with wandb\n    total_batches = len(dataloader) * config.epoch\n    total_images = 0  # number of images seen\n    \n    for epoch in range(config.epoch):\n        running_loss = 0.0\n        total_mIOU = 0\n        total_images = 0\n        \n        for batch_id, (inputs, targets) in enumerate(dataloader):\n\n            inputs, targets = inputs.cuda(), id_processing(targets).cuda()\n        \n            outputs = model(inputs)\n\n            loss = criterion(outputs[0], targets)\n\n            # Backprpagation\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            _, predicted = outputs[0].max(1)\n\n            running_mIOU = mean_iou(outputs[0].size()[1], predicted, targets)\n            total_mIOU += running_mIOU.sum().item()\n            total_images += len(predicted)\n                \n        train_loss = running_loss / len(dataloader)\n        mIOU = total_mIOU/total_images\n        \n        train_log(train_loss, mIOU, epoch)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:43.583053Z","iopub.execute_input":"2024-05-17T14:07:43.583753Z","iopub.status.idle":"2024-05-17T14:07:43.591949Z","shell.execute_reply.started":"2024-05-17T14:07:43.583726Z","shell.execute_reply":"2024-05-17T14:07:43.591098Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Validation method\ndef val(model, dataloader):\n    model.eval()\n    total_mIOU = 0\n    total_images = 0\n    latency_list = []\n    FPS_list = []\n    \n    with torch.no_grad():\n        for batch_id, (inputs, targets) in enumerate(dataloader):\n            inputs, targets = inputs.cuda(), id_processing(targets).cuda()\n            \n            start = time.time() # Record start time\n            outputs = model(inputs)\n            end = time.time() # Record end time\n\n            # Calculate latency for this iteration\n            latency_i = end - start\n            latency_list.append(latency_i)\n\n            # Calculate FPS for this iteration\n            FPS_i = 1 / latency_i\n            FPS_list.append(FPS_i)\n\n            _, predicted = outputs.max(1)\n            \n            running_mIOU = mean_iou(outputs.size()[1], predicted, targets)\n            total_mIOU += running_mIOU.sum().item()\n            total_images += len(predicted)\n        \n    mIOU = total_mIOU/total_images\n    latency = np.sum(latency_list) / len(latency_list)\n    test_FPS = np.sum(FPS_list) / len(FPS_list)\n    \n    # compute flops and #param\n    image, _ = next(iter(dataloader))\n    height, width = image.shape[2], image.shape[3]\n    zero_image = torch.zeros((1, 3, height, width))\n    flops = FlopCountAnalysis(model, zero_image.cuda())\n    print(flop_count_table(flops))\n\n    print(f'\\n\\nmIoU: {(mIoU*100):.3f}%, Latency: {latency:.3f}, FPS: {test_FPS:.3f}')\n\n    wandb.log({\"mIOU\":mIOU,\"latency\":latency,\"FPS\":test_FPS})","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:44.254549Z","iopub.execute_input":"2024-05-17T14:07:44.255449Z","iopub.status.idle":"2024-05-17T14:07:44.265233Z","shell.execute_reply.started":"2024-05-17T14:07:44.255417Z","shell.execute_reply":"2024-05-17T14:07:44.264402Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# config = dict(\n#     epochs=5,\n#     classes=19,\n#     batch_size=8,\n#     learning_rate=0.001,\n#     momentum=0.9,\n#     weight_decay=5e-4,\n#     dataset=\"Cityscapes\",\n#     architecture=\"DeepLabV2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:44.613355Z","iopub.execute_input":"2024-05-17T14:07:44.613659Z","iopub.status.idle":"2024-05-17T14:07:44.617530Z","shell.execute_reply.started":"2024-05-17T14:07:44.613635Z","shell.execute_reply":"2024-05-17T14:07:44.616630Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"sweep_config= {\n    'name': 'my-sweep',\n    'metric': {'name': 'loss', 'goal': 'minimize'}, # the goal is maximize the accuracy\n    'method': 'random', # test all possible combinations of the hyperparameters\n    'parameters': {'epoch': {'values': [5, 10]},        \n                   'learning_rate': {'values': [0.1, 0.001, 0.0001]}, # 2 parameters to optimize during the sweep\n                   'batch_size': {'values': [2, 4, 8]}},\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:44.901016Z","iopub.execute_input":"2024-05-17T14:07:44.901291Z","iopub.status.idle":"2024-05-17T14:07:44.906563Z","shell.execute_reply.started":"2024-05-17T14:07:44.901267Z","shell.execute_reply":"2024-05-17T14:07:44.905638Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config, project=\"mldl_step2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:45.249049Z","iopub.execute_input":"2024-05-17T14:07:45.249325Z","iopub.status.idle":"2024-05-17T14:07:45.597294Z","shell.execute_reply.started":"2024-05-17T14:07:45.249302Z","shell.execute_reply":"2024-05-17T14:07:45.596406Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Create sweep with ID: s0l4y5nx\nSweep URL: https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx\n","output_type":"stream"}]},{"cell_type":"code","source":"# Build, train and analyze the model with the pipeline\nwandb.agent(sweep_id, model_pipeline, count=5)\n# model = model_pipeline(config)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:07:46.853609Z","iopub.execute_input":"2024-05-17T14:07:46.853945Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: miw8nw2r with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleonardo-merelli\u001b[0m (\u001b[33mpolito-merelli\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_140748-miw8nw2r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/polito-merelli/mldl_step2/runs/miw8nw2r' target=\"_blank\">robust-sweep-1</a></strong> to <a href='https://wandb.ai/polito-merelli/mldl_step2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/polito-merelli/mldl_step2' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/polito-merelli/mldl_step2/runs/miw8nw2r' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/runs/miw8nw2r</a>"},"metadata":{}},{"name":"stdout","text":"Deeplab pretraining loading...\n----------------------------------\nLoss after 1 epochs: 1.562\nmIOU after 1 epochs: 0.128%\n----------------------------------\nLoss after 2 epochs: 1.026\nmIOU after 2 epochs: 0.167%\n----------------------------------\nLoss after 3 epochs: 0.897\nmIOU after 3 epochs: 0.182%\n----------------------------------\nLoss after 4 epochs: 0.811\nmIOU after 4 epochs: 0.191%\n----------------------------------\nLoss after 5 epochs: 0.750\nmIOU after 5 epochs: 0.199%\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_34/528570164.py\", line 16, in model_pipeline\n    val(model, val_loader)\n  File \"/tmp/ipykernel_34/3220026950.py\", line 40, in val\n    print(flop_count_table(flops))\nNameError: name 'flop_count_table' is not defined\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▃▂▂▁</td></tr><tr><td>mIOU</td><td>▁▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.75024</td></tr><tr><td>mIOU</td><td>0.19851</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">robust-sweep-1</strong> at: <a href='https://wandb.ai/polito-merelli/mldl_step2/runs/miw8nw2r' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/runs/miw8nw2r</a><br/> View project at: <a href='https://wandb.ai/polito-merelli/mldl_step2' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_140748-miw8nw2r/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run miw8nw2r errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/528570164.py\", line 16, in model_pipeline\n    val(model, val_loader)\n  File \"/tmp/ipykernel_34/3220026950.py\", line 40, in val\n    print(flop_count_table(flops))\nNameError: name 'flop_count_table' is not defined\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run miw8nw2r errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/528570164.py\", line 16, in model_pipeline\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     val(model, val_loader)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/3220026950.py\", line 40, in val\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     print(flop_count_table(flops))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'flop_count_table' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7fyfzmjk with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_145131-7fyfzmjk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/polito-merelli/mldl_step2/runs/7fyfzmjk' target=\"_blank\">fancy-sweep-2</a></strong> to <a href='https://wandb.ai/polito-merelli/mldl_step2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/polito-merelli/mldl_step2' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/polito-merelli/mldl_step2/runs/7fyfzmjk' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/runs/7fyfzmjk</a>"},"metadata":{}},{"name":"stdout","text":"Deeplab pretraining loading...\n----------------------------------\nLoss after 1 epochs: 0.723\nmIOU after 1 epochs: 0.212%\n----------------------------------\nLoss after 2 epochs: 0.434\nmIOU after 2 epochs: 0.255%\n----------------------------------\nLoss after 3 epochs: 0.383\nmIOU after 3 epochs: 0.269%\n----------------------------------\nLoss after 4 epochs: 0.354\nmIOU after 4 epochs: 0.280%\n----------------------------------\nLoss after 5 epochs: 0.334\nmIOU after 5 epochs: 0.287%\n----------------------------------\nLoss after 6 epochs: 0.319\nmIOU after 6 epochs: 0.292%\n----------------------------------\nLoss after 7 epochs: 0.308\nmIOU after 7 epochs: 0.298%\n----------------------------------\nLoss after 8 epochs: 0.299\nmIOU after 8 epochs: 0.302%\n----------------------------------\nLoss after 9 epochs: 0.290\nmIOU after 9 epochs: 0.306%\n----------------------------------\nLoss after 10 epochs: 0.283\nmIOU after 10 epochs: 0.309%\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_34/528570164.py\", line 16, in model_pipeline\n    val(model, val_loader)\n  File \"/tmp/ipykernel_34/3220026950.py\", line 40, in val\n    print(flop_count_table(flops))\nNameError: name 'flop_count_table' is not defined\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▃▃▂▂▂▁▁▁▁</td></tr><tr><td>mIOU</td><td>▁▄▅▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.28341</td></tr><tr><td>mIOU</td><td>0.30921</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fancy-sweep-2</strong> at: <a href='https://wandb.ai/polito-merelli/mldl_step2/runs/7fyfzmjk' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/runs/7fyfzmjk</a><br/> View project at: <a href='https://wandb.ai/polito-merelli/mldl_step2' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_145131-7fyfzmjk/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 7fyfzmjk errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/528570164.py\", line 16, in model_pipeline\n    val(model, val_loader)\n  File \"/tmp/ipykernel_34/3220026950.py\", line 40, in val\n    print(flop_count_table(flops))\nNameError: name 'flop_count_table' is not defined\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 7fyfzmjk errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/528570164.py\", line 16, in model_pipeline\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     val(model, val_loader)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/3220026950.py\", line 40, in val\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     print(flop_count_table(flops))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'flop_count_table' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qn3c44hr with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_161523-qn3c44hr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/polito-merelli/mldl_step2/runs/qn3c44hr' target=\"_blank\">light-sweep-3</a></strong> to <a href='https://wandb.ai/polito-merelli/mldl_step2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/polito-merelli/mldl_step2' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/sweeps/s0l4y5nx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/polito-merelli/mldl_step2/runs/qn3c44hr' target=\"_blank\">https://wandb.ai/polito-merelli/mldl_step2/runs/qn3c44hr</a>"},"metadata":{}},{"name":"stdout","text":"Deeplab pretraining loading...\n----------------------------------\nLoss after 1 epochs: 1.134\nmIOU after 1 epochs: 0.162%\n----------------------------------\nLoss after 2 epochs: 0.741\nmIOU after 2 epochs: 0.202%\n----------------------------------\nLoss after 3 epochs: 0.625\nmIOU after 3 epochs: 0.217%\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\naggiungere in config:\n- la scelta del modello (deeplab e bisenet)\n- la scelta dell'optimizer\n- la scelta della loss function ()\n\n#### VEDERE COME FUNZIONA wandb.sweep\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}