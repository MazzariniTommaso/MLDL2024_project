{"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1XNh4ReVvaCnFcvxsLVHahkWxy2OqKrm4","authorship_tag":"ABX9TyOekpKEeKXtTbQhIZpLmV9P"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8403691,"sourceType":"datasetVersion","datasetId":5000492},{"sourceId":47461,"sourceType":"modelInstanceVersion","modelInstanceId":39736}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classic semantic segmentation network\nFor this step, you have to train a classic segmentation network (**DeepLabV2** [2]) on the Cityscapes dataset.\n- Dataset: **Cityscapes** [5]\n- Training epochs: 50\n- Training resolution (Cityscapes): 1024x512\n- Test resolution (Cityscapes): 1024x512\n- Backbone: **R101** (pre-trained on ImageNet) [2]\n- Semantic classes: 19\n- Metrics: Mean Intersection over Union (**mIoU**) [read this to understand the metrics], **latency**, **FLOPs**, number of **parameters**.\n","metadata":{"id":"OAZEiffSoALO"}},{"cell_type":"code","source":"!pip install -U fvcore","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:34:43.364513Z","iopub.execute_input":"2024-05-19T21:34:43.364876Z","iopub.status.idle":"2024-05-19T21:35:02.659091Z","shell.execute_reply.started":"2024-05-19T21:34:43.364848Z","shell.execute_reply":"2024-05-19T21:35:02.657523Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting fvcore\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m880.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore) (1.26.4)\nCollecting yacs>=0.1.6 (from fvcore)\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (6.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fvcore) (4.66.1)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (2.4.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from fvcore) (9.5.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.9.0)\nCollecting iopath>=0.1.7 (from fvcore)\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore) (4.9.0)\nCollecting portalocker (from iopath>=0.1.7->fvcore)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: fvcore, iopath\n  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=f925baa3f0f47c9b8e9dc9e56cf36b9246a32459c0fb49241c84d580c8c6dfe7\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=05907c252bd703aacc7aab3ce4753e37db9bc921fdbb9f9be547bdd603b680c9\n  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\nSuccessfully built fvcore iopath\nInstalling collected packages: yacs, portalocker, iopath, fvcore\nSuccessfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.8.2 yacs-0.1.8\n","output_type":"stream"}]},{"cell_type":"code","source":"# WANDB\n!pip install -q wandb","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:02.661958Z","iopub.execute_input":"2024-05-19T21:35:02.662266Z","iopub.status.idle":"2024-05-19T21:35:15.021137Z","shell.execute_reply.started":"2024-05-19T21:35:02.662238Z","shell.execute_reply":"2024-05-19T21:35:15.020042Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 0 - Import libraries","metadata":{"id":"cNa1Un4uoZ6M"}},{"cell_type":"code","source":"import wandb\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nimport torch.optim as optim\n\nimport os\nimport zipfile\nimport numpy as np\nimport time\nfrom PIL import Image\n\nfrom fvcore.nn import FlopCountAnalysis, flop_count_table\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"id":"mYTc9GfSouYh","executionInfo":{"status":"ok","timestamp":1715695760300,"user_tz":-120,"elapsed":13275,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"}},"execution":{"iopub.status.busy":"2024-05-19T21:35:15.022723Z","iopub.execute_input":"2024-05-19T21:35:15.023080Z","iopub.status.idle":"2024-05-19T21:35:21.417939Z","shell.execute_reply.started":"2024-05-19T21:35:15.023051Z","shell.execute_reply":"2024-05-19T21:35:21.416980Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 1 - Start WanDB","metadata":{}},{"cell_type":"code","source":"wandb.login()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:21.420060Z","iopub.execute_input":"2024-05-19T21:35:21.420487Z","iopub.status.idle":"2024-05-19T21:35:52.435023Z","shell.execute_reply.started":"2024-05-19T21:35:21.420462Z","shell.execute_reply":"2024-05-19T21:35:52.434151Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2 - Model Pipeline","metadata":{}},{"cell_type":"code","source":"def model_pipeline(hyperparameters=None):\n\n    # tell wandb to get started\n    with wandb.init(project=\"MLDL-step2a\", config=hyperparameters):\n        # access all HPs through wandb.config, so logging matches execution!\n        config = wandb.config\n\n        # make the model, data, and optimization problem\n        model, train_loader, val_loader, criterion, optimizer = make(config)\n        #print(model)\n\n        # and use them to train the model\n        train(model, train_loader, criterion, optimizer, config)\n\n        # and test its final performance\n        val(model, val_loader)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:52.436075Z","iopub.execute_input":"2024-05-19T21:35:52.436491Z","iopub.status.idle":"2024-05-19T21:35:52.442564Z","shell.execute_reply.started":"2024-05-19T21:35:52.436466Z","shell.execute_reply":"2024-05-19T21:35:52.441491Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# 3 - CityScapes","metadata":{"id":"sKK0P3Aloi9U"}},{"cell_type":"code","source":"def make(config):\n    # Make the data\n    train, test = get_data(train=True), get_data(train=False)\n    train_loader = make_loader(train, batch_size=config.batch_size,train=True)\n    test_loader = make_loader(test, batch_size=config.batch_size,train=False)\n\n    # Make the model (DeepLabV2 with ResNet-101 backbone)\n    pretrain_model_path = '/kaggle/input/deeplab_v2_model/pytorch/model_weight/1/deeplab_resnet_pretrained_imagenet.pth'\n    model = get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path=pretrain_model_path).cuda()\n\n    # Make the loss and optimizer\n    optimizer = optim.SGD(model.parameters(), \n                          lr=config.learning_rate, \n                          momentum=config.momentum, \n                          weight_decay=config.weight_decay)\n    \n    criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n    \n    return model, train_loader, test_loader, criterion, optimizer","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:52.443683Z","iopub.execute_input":"2024-05-19T21:35:52.443971Z","iopub.status.idle":"2024-05-19T21:35:52.453635Z","shell.execute_reply.started":"2024-05-19T21:35:52.443949Z","shell.execute_reply":"2024-05-19T21:35:52.452805Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define transforms for preprocessing\nimage_transform = transforms.Compose([\n        transforms.Resize((512,1024)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\nlabel_transform = transforms.Compose([\n        transforms.Resize((512,1024)),\n    ])\n\nroot_dir ='/kaggle/input/cityscapes/Cityscapes/Cityspaces'\n\ndef get_data(train=True):\n    if train == True:\n        # train dataset\n        dataset = CityScapes(root_dir=root_dir, split='train', image_transform=image_transform, label_transform=label_transform)\n    else:\n        # test dataset\n        dataset = CityScapes(root_dir=root_dir, split='val', image_transform=image_transform, label_transform=label_transform)\n    \n    return dataset\n\n\ndef make_loader(dataset, batch_size=8, train=True):\n    if train == True:\n        # train dataloader\n        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n    else:\n        # test dataloader\n        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False,drop_last=True)\n    \n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:52.455117Z","iopub.execute_input":"2024-05-19T21:35:52.455374Z","iopub.status.idle":"2024-05-19T21:35:52.464323Z","shell.execute_reply.started":"2024-05-19T21:35:52.455353Z","shell.execute_reply":"2024-05-19T21:35:52.463416Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CityScapes(Dataset):\n    def __init__(self, root_dir, split='train', image_transform=None, label_transform=None):\n        super(CityScapes, self).__init__()\n        \"\"\"\n        Args:\n            root_dir (string): Directory with all the images and annotations.\n            split (string): 'train' or 'val'.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n\n        self.root_dir = root_dir\n        self.split = split\n        self.image_transform = image_transform\n        self.label_transform = label_transform\n\n        # Get the image and label directories\n        self.image_dir = os.path.join(root_dir, 'images', split)\n        self.label_dir = os.path.join(root_dir, 'gtFine', split)\n\n        # Get a list of all image files\n        self.image_files = []\n        for city_dir in os.listdir(self.image_dir):\n            city_image_dir = os.path.join(self.image_dir, city_dir)\n            self.image_files.extend([os.path.join(city_image_dir, f) for f in os.listdir(city_image_dir) if f.endswith('.png')])\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_name = self.image_files[idx]\n\n        # Get the corresponding label image path\n        label_name = img_name.replace('images', 'gtFine').replace('_leftImg8bit', '_gtFine_labelTrainIds')\n\n        # Load image and label\n        image = Image.open(img_name).convert('RGB')\n        label = Image.open(label_name).convert('L')\n\n        #print(np.unique(np.array(label).reshape(np.array(label).shape[0] * np.array(label).shape[1])).size)\n\n        if self.image_transform:\n            image = self.image_transform(image)\n        if self.label_transform:\n            label = self.label_transform(label)\n\n        #print(np.unique(np.array(label).reshape(np.array(label).shape[0] * np.array(label).shape[1])).size)\n\n        label = torch.Tensor(np.array(label))\n\n        return image, label","metadata":{"id":"TE5jHHpwaduG","executionInfo":{"status":"ok","timestamp":1715695833931,"user_tz":-120,"elapsed":3,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"}},"execution":{"iopub.status.busy":"2024-05-19T21:35:52.465438Z","iopub.execute_input":"2024-05-19T21:35:52.465683Z","iopub.status.idle":"2024-05-19T21:35:52.476278Z","shell.execute_reply.started":"2024-05-19T21:35:52.465662Z","shell.execute_reply":"2024-05-19T21:35:52.475563Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# 4 - DeepLabV2","metadata":{"id":"breeFfksou_h"}},{"cell_type":"code","source":"affine_par = True\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par)\n        for i in self.bn1.parameters():\n            i.requires_grad = False\n        padding = dilation\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n                               padding=padding, bias=False, dilation=dilation)\n        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n        for i in self.bn2.parameters():\n            i.requires_grad = False\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n        for i in self.bn3.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n        out = self.bn3(out)\n        if self.downsample is not None:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ClassifierModule(nn.Module):\n    def __init__(self, inplanes, dilation_series, padding_series, num_classes):\n        super(ClassifierModule, self).__init__()\n        self.conv2d_list = nn.ModuleList()\n        for dilation, padding in zip(dilation_series, padding_series):\n            self.conv2d_list.append(\n                nn.Conv2d(inplanes, num_classes, kernel_size=3, stride=1, padding=padding,\n                          dilation=dilation, bias=True))\n\n        for m in self.conv2d_list:\n            m.weight.data.normal_(0, 0.01)\n\n    def forward(self, x):\n        out = self.conv2d_list[0](x)\n        for i in range(len(self.conv2d_list) - 1):\n            out += self.conv2d_list[i + 1](x)\n        return out\n\n\nclass ResNetMulti(nn.Module):\n    def __init__(self, block, layers, num_classes):\n        self.inplanes = 64\n        super(ResNetMulti, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n        for i in self.bn1.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n        self.layer6 = ClassifierModule(2048, [6, 12, 18, 24], [6, 12, 18, 24], num_classes)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                m.weight.data.normal_(0, 0.01)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n        downsample = None\n        if (stride != 1\n                or self.inplanes != planes * block.expansion\n                or dilation == 2\n                or dilation == 4):\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion, affine=affine_par))\n        for i in downsample._modules['1'].parameters():\n            i.requires_grad = False\n        layers = []\n        layers.append(\n            block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, dilation=dilation))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        _, _, H, W = x.size()\n\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer6(x)\n\n        x = torch.nn.functional.interpolate(x, size=(H, W), mode='bilinear')\n\n        if self.training == True:\n            return x, None, None\n\n        return x\n\n    def get_1x_lr_params_no_scale(self):\n        \"\"\"\n        This generator returns all the parameters of the net except for\n        the last classification layer. Note that for each batchnorm layer,\n        requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n        any batchnorm parameter\n        \"\"\"\n        b = []\n\n        b.append(self.conv1)\n        b.append(self.bn1)\n        b.append(self.layer1)\n        b.append(self.layer2)\n        b.append(self.layer3)\n        b.append(self.layer4)\n\n        for i in range(len(b)):\n            for j in b[i].modules():\n                jj = 0\n                for k in j.parameters():\n                    jj += 1\n                    if k.requires_grad:\n                        yield k\n\n    def get_10x_lr_params(self):\n        \"\"\"\n        This generator returns all the parameters for the last layer of the net,\n        which does the classification of pixel into classes\n        \"\"\"\n        b = []\n        if self.multi_level:\n            b.append(self.layer5.parameters())\n        b.append(self.layer6.parameters())\n\n        for j in range(len(b)):\n            for i in b[j]:\n                yield i\n\n    def optim_parameters(self, lr):\n        return [{'params': self.get_1x_lr_params_no_scale(), 'lr': lr},\n                {'params': self.get_10x_lr_params(), 'lr': 10 * lr}]\n\n\ndef get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='DeepLab_resnet_pretrained_imagenet.pth'):\n    model = ResNetMulti(Bottleneck, [3, 4, 23, 3], num_classes)\n\n    # Pretraining loading\n    if pretrain:\n        print('Deeplab pretraining loading...')\n        saved_state_dict = torch.load(pretrain_model_path)\n\n        new_params = model.state_dict().copy()\n        for i in saved_state_dict:\n            i_parts = i.split('.')\n            new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n        model.load_state_dict(new_params, strict=False)\n\n    return model","metadata":{"id":"sOluxCUSo6TN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715695905826,"user_tz":-120,"elapsed":12513,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"}},"outputId":"18e9c583-19cc-4b94-f206-b30ba08384cb","execution":{"iopub.status.busy":"2024-05-19T21:35:52.477406Z","iopub.execute_input":"2024-05-19T21:35:52.477657Z","iopub.status.idle":"2024-05-19T21:35:52.514636Z","shell.execute_reply.started":"2024-05-19T21:35:52.477636Z","shell.execute_reply":"2024-05-19T21:35:52.513547Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# 5 - Training","metadata":{}},{"cell_type":"code","source":"def train(model, dataloader, criterion, optimizer, config):\n    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n    \n    for epoch in range(config.epochs):\n        running_loss = 0.0\n        total_mIOU = 0\n        total_images = 0\n        \n        for _, (inputs, targets) in enumerate(dataloader):\n\n            inputs, targets = inputs.cuda(), id_processing(targets).cuda()\n        \n            outputs = model(inputs)\n\n            loss = criterion(outputs[0], targets)\n\n            # Backprpagation\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            _, predicted = outputs[0].max(1)\n\n            running_mIOU = mean_iou(outputs[0].size()[1], predicted, targets)\n            total_mIOU += running_mIOU.sum().item()\n            total_images += len(predicted)\n                \n        train_loss = running_loss / len(dataloader)\n        mIOU = total_mIOU/total_images\n        \n        train_log(train_loss, mIOU, epoch)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:52.518450Z","iopub.execute_input":"2024-05-19T21:35:52.518800Z","iopub.status.idle":"2024-05-19T21:35:52.527494Z","shell.execute_reply.started":"2024-05-19T21:35:52.518749Z","shell.execute_reply":"2024-05-19T21:35:52.526653Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def id_processing(targets):\n    targets = targets.cuda()\n    \n    # Define valid indices\n    valid_indices = torch.tensor(list(range(19)) + [255]).to(targets.device)\n\n    # Replace all IDs not in valid_indices with 255\n    processed_targets = torch.where(torch.isin(targets, valid_indices), targets, torch.tensor(255, device=targets.device))\n\n    return processed_targets.long()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:52.528688Z","iopub.execute_input":"2024-05-19T21:35:52.529205Z","iopub.status.idle":"2024-05-19T21:35:52.534992Z","shell.execute_reply.started":"2024-05-19T21:35:52.529180Z","shell.execute_reply":"2024-05-19T21:35:52.533992Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def mean_iou(num_classes, pred, target):\n    mIOU = 0\n    for i in range(len(pred)):\n        hist = fast_hist(target[i].cpu().numpy(),pred[i].cpu().numpy(), num_classes)\n        IOU = per_class_iou(hist)\n        mIOU = mIOU + sum(IOU)/num_classes\n    return mIOU\n\ndef fast_hist(a, b, n):\n    \"\"\"\n    a and b are predict and mask respectively\n    n is the number of classes\n    \"\"\"\n    k = (a >= 0) & (a < n) #assign True if the value is in the range between 0 and 18 (class labels)\n    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape((n, n))\n\ndef per_class_iou(hist):\n    epsilon = 1e-5\n    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:52.536170Z","iopub.execute_input":"2024-05-19T21:35:52.536456Z","iopub.status.idle":"2024-05-19T21:35:52.545298Z","shell.execute_reply.started":"2024-05-19T21:35:52.536430Z","shell.execute_reply":"2024-05-19T21:35:52.544291Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train_log(loss, mIOU, epoch):\n    #wandb.log({\"epoch\": epoch, \"loss\": loss, \"mIOU\":mIOU})\n    wandb.log({\"loss\": loss, \"mIOU\":mIOU}, step= epoch)\n    print(f\"----------------------------------\")\n    print(f\"Loss after {epoch} epochs: {loss:.3f}\")\n    print(f\"mIOU after {epoch} epochs: {mIOU:.3f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:52.546607Z","iopub.execute_input":"2024-05-19T21:35:52.547198Z","iopub.status.idle":"2024-05-19T21:35:52.553214Z","shell.execute_reply.started":"2024-05-19T21:35:52.547159Z","shell.execute_reply":"2024-05-19T21:35:52.552301Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# 6 - Validation","metadata":{"id":"vcIkDP8ho8wt"}},{"cell_type":"code","source":"# Validation method\ndef val(model, dataloader):\n    model.eval()\n    total_mIOU = 0\n    total_images = 0\n    latency_list = []\n    FPS_list = []\n    \n    with torch.no_grad():\n        for _, (inputs, targets) in enumerate(dataloader):\n            inputs, targets = inputs.cuda(), id_processing(targets).cuda()\n            \n            start = time.time() # Record start time\n            outputs = model(inputs)\n            end = time.time() # Record end time\n\n            # Calculate latency for this iteration\n            latency_i = end - start\n            latency_list.append(latency_i)\n\n            # Calculate FPS for this iteration\n            FPS_i = 1 / latency_i\n            FPS_list.append(FPS_i)\n\n            _, predicted = outputs.max(1)\n            \n            running_mIOU = mean_iou(outputs.size()[1], predicted, targets)\n            total_mIOU += running_mIOU.sum().item()\n            total_images += len(predicted)\n        \n    mIOU = total_mIOU/total_images\n    latency = np.sum(latency_list) / len(latency_list)\n    test_FPS = np.sum(FPS_list) / len(FPS_list)\n    \n    # compute flops and #param\n    image, _ = next(iter(dataloader))\n    height, width = image.shape[2], image.shape[3]\n    zero_image = torch.zeros((1, 3, height, width))\n    flops = FlopCountAnalysis(model, zero_image.cuda())\n    print(flop_count_table(flops))\n\n    print(f'\\n\\nmIoU: {(mIOU*100):.3f}%, Latency: {latency:.3f}, FPS: {test_FPS:.3f}')\n\n    wandb.log({\"mIOU\":mIOU,\"latency\":latency,\"FPS\":test_FPS})","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:52.554372Z","iopub.execute_input":"2024-05-19T21:35:52.554635Z","iopub.status.idle":"2024-05-19T21:35:52.564887Z","shell.execute_reply.started":"2024-05-19T21:35:52.554613Z","shell.execute_reply":"2024-05-19T21:35:52.563996Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# 7 - Hyperparameter Sweeps using WanDB","metadata":{}},{"cell_type":"code","source":"sweep_config= {\n    'name': 'DeepLabV2-sweep',\n    'metric': {'name': 'loss', 'goal': 'minimize'}, # the goal is maximize the accuracy\n    'method': 'random', # test all possible combinations of the hyperparameters\n    'parameters': {\n        'epochs': {'values': [5]},        \n        'learning_rate': {'values': [0.1, 0.001, 0.0001]}, # 2 parameters to optimize during the sweep\n        'batch_size': {'values': [2, 4, 8]},\n        'momentum': {'values': [0.9]},\n        'weight_decay': {'values': [5e-4]}\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:41:32.900800Z","iopub.execute_input":"2024-05-19T11:41:32.901092Z","iopub.status.idle":"2024-05-19T11:41:32.910872Z","shell.execute_reply.started":"2024-05-19T11:41:32.901067Z","shell.execute_reply":"2024-05-19T11:41:32.909912Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep=sweep_config, project=\"MLDL-step2a\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:41:32.911905Z","iopub.execute_input":"2024-05-19T11:41:32.912253Z","iopub.status.idle":"2024-05-19T11:41:33.263352Z","shell.execute_reply.started":"2024-05-19T11:41:32.912228Z","shell.execute_reply":"2024-05-19T11:41:33.262536Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Create sweep with ID: 0bsj16g0\nSweep URL: https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0\n","output_type":"stream"}]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(\"Start hyperparameter sweeps\\n\")\n    wandb.agent(sweep_id, function=model_pipeline, count=5)\nelse:\n    print(\"CUDA is Not available\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:41:33.264429Z","iopub.execute_input":"2024-05-19T11:41:33.264731Z","iopub.status.idle":"2024-05-19T15:52:16.393627Z","shell.execute_reply.started":"2024-05-19T11:41:33.264708Z","shell.execute_reply":"2024-05-19T15:52:16.392669Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Start hyperparameter sweeps\n\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ebq7xakp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtommasomazzarini2001\u001b[0m (\u001b[33mpolito-tmazzarini\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_114135-ebq7xakp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/ebq7xakp' target=\"_blank\">decent-sweep-1</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/ebq7xakp' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/ebq7xakp</a>"},"metadata":{}},{"name":"stdout","text":"Deeplab pretraining loading...\n----------------------------------\nLoss after 1 epochs: 4.019\nmIOU after 1 epochs: 0.057%\n----------------------------------\nLoss after 2 epochs: 1.624\nmIOU after 2 epochs: 0.073%\n----------------------------------\nLoss after 3 epochs: 1.351\nmIOU after 3 epochs: 0.093%\n----------------------------------\nLoss after 4 epochs: 1.222\nmIOU after 4 epochs: 0.103%\n----------------------------------\nLoss after 5 epochs: 1.140\nmIOU after 5 epochs: 0.113%\n| module                         | #parameters or shape   | #flops     |\n|:-------------------------------|:-----------------------|:-----------|\n| model                          | 43.901M                | 95.816G    |\n|  conv1                         |  9.408K                |  0.308G    |\n|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n|  bn1                           |  0.128K                |  4.194M    |\n|   bn1.weight                   |   (64,)                |            |\n|   bn1.bias                     |   (64,)                |            |\n|  layer1                        |  0.216M                |  1.81G     |\n|   layer1.0                     |   75.008K              |   0.629G   |\n|    layer1.0.conv1              |    4.096K              |    34.345M |\n|    layer1.0.bn1                |    0.128K              |    1.073M  |\n|    layer1.0.conv2              |    36.864K             |    0.309G  |\n|    layer1.0.bn2                |    0.128K              |    1.073M  |\n|    layer1.0.conv3              |    16.384K             |    0.137G  |\n|    layer1.0.bn3                |    0.512K              |    4.293M  |\n|    layer1.0.downsample         |    16.896K             |    0.142G  |\n|   layer1.1                     |   70.4K                |   0.59G    |\n|    layer1.1.conv1              |    16.384K             |    0.137G  |\n|    layer1.1.bn1                |    0.128K              |    1.073M  |\n|    layer1.1.conv2              |    36.864K             |    0.309G  |\n|    layer1.1.bn2                |    0.128K              |    1.073M  |\n|    layer1.1.conv3              |    16.384K             |    0.137G  |\n|    layer1.1.bn3                |    0.512K              |    4.293M  |\n|   layer1.2                     |   70.4K                |   0.59G    |\n|    layer1.2.conv1              |    16.384K             |    0.137G  |\n|    layer1.2.bn1                |    0.128K              |    1.073M  |\n|    layer1.2.conv2              |    36.864K             |    0.309G  |\n|    layer1.2.bn2                |    0.128K              |    1.073M  |\n|    layer1.2.conv3              |    16.384K             |    0.137G  |\n|    layer1.2.bn3                |    0.512K              |    4.293M  |\n|  layer2                        |  1.22M                 |  2.616G    |\n|   layer2.0                     |   0.379M               |   0.814G   |\n|    layer2.0.conv1              |    32.768K             |    70.287M |\n|    layer2.0.bn1                |    0.256K              |    0.549M  |\n|    layer2.0.conv2              |    0.147M              |    0.316G  |\n|    layer2.0.bn2                |    0.256K              |    0.549M  |\n|    layer2.0.conv3              |    65.536K             |    0.141G  |\n|    layer2.0.bn3                |    1.024K              |    2.196M  |\n|    layer2.0.downsample         |    0.132M              |    0.283G  |\n|   layer2.1                     |   0.28M                |   0.601G   |\n|    layer2.1.conv1              |    65.536K             |    0.141G  |\n|    layer2.1.bn1                |    0.256K              |    0.549M  |\n|    layer2.1.conv2              |    0.147M              |    0.316G  |\n|    layer2.1.bn2                |    0.256K              |    0.549M  |\n|    layer2.1.conv3              |    65.536K             |    0.141G  |\n|    layer2.1.bn3                |    1.024K              |    2.196M  |\n|   layer2.2                     |   0.28M                |   0.601G   |\n|    layer2.2.conv1              |    65.536K             |    0.141G  |\n|    layer2.2.bn1                |    0.256K              |    0.549M  |\n|    layer2.2.conv2              |    0.147M              |    0.316G  |\n|    layer2.2.bn2                |    0.256K              |    0.549M  |\n|    layer2.2.conv3              |    65.536K             |    0.141G  |\n|    layer2.2.bn3                |    1.024K              |    2.196M  |\n|   layer2.3                     |   0.28M                |   0.601G   |\n|    layer2.3.conv1              |    65.536K             |    0.141G  |\n|    layer2.3.bn1                |    0.256K              |    0.549M  |\n|    layer2.3.conv2              |    0.147M              |    0.316G  |\n|    layer2.3.bn2                |    0.256K              |    0.549M  |\n|    layer2.3.conv3              |    65.536K             |    0.141G  |\n|    layer2.3.bn3                |    1.024K              |    2.196M  |\n|  layer3                        |  26.09M                |  55.964G   |\n|   layer3.0                     |   1.512M               |   3.244G   |\n|    layer3.0.conv1              |    0.131M              |    0.281G  |\n|    layer3.0.bn1                |    0.512K              |    1.098M  |\n|    layer3.0.conv2              |    0.59M               |    1.265G  |\n|    layer3.0.bn2                |    0.512K              |    1.098M  |\n|    layer3.0.conv3              |    0.262M              |    0.562G  |\n|    layer3.0.bn3                |    2.048K              |    4.393M  |\n|    layer3.0.downsample         |    0.526M              |    1.129G  |\n|   layer3.1                     |   1.117M               |   2.396G   |\n|    layer3.1.conv1              |    0.262M              |    0.562G  |\n|    layer3.1.bn1                |    0.512K              |    1.098M  |\n|    layer3.1.conv2              |    0.59M               |    1.265G  |\n|    layer3.1.bn2                |    0.512K              |    1.098M  |\n|    layer3.1.conv3              |    0.262M              |    0.562G  |\n|    layer3.1.bn3                |    2.048K              |    4.393M  |\n|   layer3.2                     |   1.117M               |   2.396G   |\n|    layer3.2.conv1              |    0.262M              |    0.562G  |\n|    layer3.2.bn1                |    0.512K              |    1.098M  |\n|    layer3.2.conv2              |    0.59M               |    1.265G  |\n|    layer3.2.bn2                |    0.512K              |    1.098M  |\n|    layer3.2.conv3              |    0.262M              |    0.562G  |\n|    layer3.2.bn3                |    2.048K              |    4.393M  |\n|   layer3.3                     |   1.117M               |   2.396G   |\n|    layer3.3.conv1              |    0.262M              |    0.562G  |\n|    layer3.3.bn1                |    0.512K              |    1.098M  |\n|    layer3.3.conv2              |    0.59M               |    1.265G  |\n|    layer3.3.bn2                |    0.512K              |    1.098M  |\n|    layer3.3.conv3              |    0.262M              |    0.562G  |\n|    layer3.3.bn3                |    2.048K              |    4.393M  |\n|   layer3.4                     |   1.117M               |   2.396G   |\n|    layer3.4.conv1              |    0.262M              |    0.562G  |\n|    layer3.4.bn1                |    0.512K              |    1.098M  |\n|    layer3.4.conv2              |    0.59M               |    1.265G  |\n|    layer3.4.bn2                |    0.512K              |    1.098M  |\n|    layer3.4.conv3              |    0.262M              |    0.562G  |\n|    layer3.4.bn3                |    2.048K              |    4.393M  |\n|   layer3.5                     |   1.117M               |   2.396G   |\n|    layer3.5.conv1              |    0.262M              |    0.562G  |\n|    layer3.5.bn1                |    0.512K              |    1.098M  |\n|    layer3.5.conv2              |    0.59M               |    1.265G  |\n|    layer3.5.bn2                |    0.512K              |    1.098M  |\n|    layer3.5.conv3              |    0.262M              |    0.562G  |\n|    layer3.5.bn3                |    2.048K              |    4.393M  |\n|   layer3.6                     |   1.117M               |   2.396G   |\n|    layer3.6.conv1              |    0.262M              |    0.562G  |\n|    layer3.6.bn1                |    0.512K              |    1.098M  |\n|    layer3.6.conv2              |    0.59M               |    1.265G  |\n|    layer3.6.bn2                |    0.512K              |    1.098M  |\n|    layer3.6.conv3              |    0.262M              |    0.562G  |\n|    layer3.6.bn3                |    2.048K              |    4.393M  |\n|   layer3.7                     |   1.117M               |   2.396G   |\n|    layer3.7.conv1              |    0.262M              |    0.562G  |\n|    layer3.7.bn1                |    0.512K              |    1.098M  |\n|    layer3.7.conv2              |    0.59M               |    1.265G  |\n|    layer3.7.bn2                |    0.512K              |    1.098M  |\n|    layer3.7.conv3              |    0.262M              |    0.562G  |\n|    layer3.7.bn3                |    2.048K              |    4.393M  |\n|   layer3.8                     |   1.117M               |   2.396G   |\n|    layer3.8.conv1              |    0.262M              |    0.562G  |\n|    layer3.8.bn1                |    0.512K              |    1.098M  |\n|    layer3.8.conv2              |    0.59M               |    1.265G  |\n|    layer3.8.bn2                |    0.512K              |    1.098M  |\n|    layer3.8.conv3              |    0.262M              |    0.562G  |\n|    layer3.8.bn3                |    2.048K              |    4.393M  |\n|   layer3.9                     |   1.117M               |   2.396G   |\n|    layer3.9.conv1              |    0.262M              |    0.562G  |\n|    layer3.9.bn1                |    0.512K              |    1.098M  |\n|    layer3.9.conv2              |    0.59M               |    1.265G  |\n|    layer3.9.bn2                |    0.512K              |    1.098M  |\n|    layer3.9.conv3              |    0.262M              |    0.562G  |\n|    layer3.9.bn3                |    2.048K              |    4.393M  |\n|   layer3.10                    |   1.117M               |   2.396G   |\n|    layer3.10.conv1             |    0.262M              |    0.562G  |\n|    layer3.10.bn1               |    0.512K              |    1.098M  |\n|    layer3.10.conv2             |    0.59M               |    1.265G  |\n|    layer3.10.bn2               |    0.512K              |    1.098M  |\n|    layer3.10.conv3             |    0.262M              |    0.562G  |\n|    layer3.10.bn3               |    2.048K              |    4.393M  |\n|   layer3.11                    |   1.117M               |   2.396G   |\n|    layer3.11.conv1             |    0.262M              |    0.562G  |\n|    layer3.11.bn1               |    0.512K              |    1.098M  |\n|    layer3.11.conv2             |    0.59M               |    1.265G  |\n|    layer3.11.bn2               |    0.512K              |    1.098M  |\n|    layer3.11.conv3             |    0.262M              |    0.562G  |\n|    layer3.11.bn3               |    2.048K              |    4.393M  |\n|   layer3.12                    |   1.117M               |   2.396G   |\n|    layer3.12.conv1             |    0.262M              |    0.562G  |\n|    layer3.12.bn1               |    0.512K              |    1.098M  |\n|    layer3.12.conv2             |    0.59M               |    1.265G  |\n|    layer3.12.bn2               |    0.512K              |    1.098M  |\n|    layer3.12.conv3             |    0.262M              |    0.562G  |\n|    layer3.12.bn3               |    2.048K              |    4.393M  |\n|   layer3.13                    |   1.117M               |   2.396G   |\n|    layer3.13.conv1             |    0.262M              |    0.562G  |\n|    layer3.13.bn1               |    0.512K              |    1.098M  |\n|    layer3.13.conv2             |    0.59M               |    1.265G  |\n|    layer3.13.bn2               |    0.512K              |    1.098M  |\n|    layer3.13.conv3             |    0.262M              |    0.562G  |\n|    layer3.13.bn3               |    2.048K              |    4.393M  |\n|   layer3.14                    |   1.117M               |   2.396G   |\n|    layer3.14.conv1             |    0.262M              |    0.562G  |\n|    layer3.14.bn1               |    0.512K              |    1.098M  |\n|    layer3.14.conv2             |    0.59M               |    1.265G  |\n|    layer3.14.bn2               |    0.512K              |    1.098M  |\n|    layer3.14.conv3             |    0.262M              |    0.562G  |\n|    layer3.14.bn3               |    2.048K              |    4.393M  |\n|   layer3.15                    |   1.117M               |   2.396G   |\n|    layer3.15.conv1             |    0.262M              |    0.562G  |\n|    layer3.15.bn1               |    0.512K              |    1.098M  |\n|    layer3.15.conv2             |    0.59M               |    1.265G  |\n|    layer3.15.bn2               |    0.512K              |    1.098M  |\n|    layer3.15.conv3             |    0.262M              |    0.562G  |\n|    layer3.15.bn3               |    2.048K              |    4.393M  |\n|   layer3.16                    |   1.117M               |   2.396G   |\n|    layer3.16.conv1             |    0.262M              |    0.562G  |\n|    layer3.16.bn1               |    0.512K              |    1.098M  |\n|    layer3.16.conv2             |    0.59M               |    1.265G  |\n|    layer3.16.bn2               |    0.512K              |    1.098M  |\n|    layer3.16.conv3             |    0.262M              |    0.562G  |\n|    layer3.16.bn3               |    2.048K              |    4.393M  |\n|   layer3.17                    |   1.117M               |   2.396G   |\n|    layer3.17.conv1             |    0.262M              |    0.562G  |\n|    layer3.17.bn1               |    0.512K              |    1.098M  |\n|    layer3.17.conv2             |    0.59M               |    1.265G  |\n|    layer3.17.bn2               |    0.512K              |    1.098M  |\n|    layer3.17.conv3             |    0.262M              |    0.562G  |\n|    layer3.17.bn3               |    2.048K              |    4.393M  |\n|   layer3.18                    |   1.117M               |   2.396G   |\n|    layer3.18.conv1             |    0.262M              |    0.562G  |\n|    layer3.18.bn1               |    0.512K              |    1.098M  |\n|    layer3.18.conv2             |    0.59M               |    1.265G  |\n|    layer3.18.bn2               |    0.512K              |    1.098M  |\n|    layer3.18.conv3             |    0.262M              |    0.562G  |\n|    layer3.18.bn3               |    2.048K              |    4.393M  |\n|   layer3.19                    |   1.117M               |   2.396G   |\n|    layer3.19.conv1             |    0.262M              |    0.562G  |\n|    layer3.19.bn1               |    0.512K              |    1.098M  |\n|    layer3.19.conv2             |    0.59M               |    1.265G  |\n|    layer3.19.bn2               |    0.512K              |    1.098M  |\n|    layer3.19.conv3             |    0.262M              |    0.562G  |\n|    layer3.19.bn3               |    2.048K              |    4.393M  |\n|   layer3.20                    |   1.117M               |   2.396G   |\n|    layer3.20.conv1             |    0.262M              |    0.562G  |\n|    layer3.20.bn1               |    0.512K              |    1.098M  |\n|    layer3.20.conv2             |    0.59M               |    1.265G  |\n|    layer3.20.bn2               |    0.512K              |    1.098M  |\n|    layer3.20.conv3             |    0.262M              |    0.562G  |\n|    layer3.20.bn3               |    2.048K              |    4.393M  |\n|   layer3.21                    |   1.117M               |   2.396G   |\n|    layer3.21.conv1             |    0.262M              |    0.562G  |\n|    layer3.21.bn1               |    0.512K              |    1.098M  |\n|    layer3.21.conv2             |    0.59M               |    1.265G  |\n|    layer3.21.bn2               |    0.512K              |    1.098M  |\n|    layer3.21.conv3             |    0.262M              |    0.562G  |\n|    layer3.21.bn3               |    2.048K              |    4.393M  |\n|   layer3.22                    |   1.117M               |   2.396G   |\n|    layer3.22.conv1             |    0.262M              |    0.562G  |\n|    layer3.22.bn1               |    0.512K              |    1.098M  |\n|    layer3.22.conv2             |    0.59M               |    1.265G  |\n|    layer3.22.bn2               |    0.512K              |    1.098M  |\n|    layer3.22.conv3             |    0.262M              |    0.562G  |\n|    layer3.22.bn3               |    2.048K              |    4.393M  |\n|  layer4                        |  14.965M               |  32.099G   |\n|   layer4.0                     |   6.04M                |   12.955G  |\n|    layer4.0.conv1              |    0.524M              |    1.125G  |\n|    layer4.0.bn1                |    1.024K              |    2.196M  |\n|    layer4.0.conv2              |    2.359M              |    5.061G  |\n|    layer4.0.bn2                |    1.024K              |    2.196M  |\n|    layer4.0.conv3              |    1.049M              |    2.249G  |\n|    layer4.0.bn3                |    4.096K              |    8.786M  |\n|    layer4.0.downsample         |    2.101M              |    4.507G  |\n|   layer4.1                     |   4.463M               |   9.572G   |\n|    layer4.1.conv1              |    1.049M              |    2.249G  |\n|    layer4.1.bn1                |    1.024K              |    2.196M  |\n|    layer4.1.conv2              |    2.359M              |    5.061G  |\n|    layer4.1.bn2                |    1.024K              |    2.196M  |\n|    layer4.1.conv3              |    1.049M              |    2.249G  |\n|    layer4.1.bn3                |    4.096K              |    8.786M  |\n|   layer4.2                     |   4.463M               |   9.572G   |\n|    layer4.2.conv1              |    1.049M              |    2.249G  |\n|    layer4.2.bn1                |    1.024K              |    2.196M  |\n|    layer4.2.conv2              |    2.359M              |    5.061G  |\n|    layer4.2.bn2                |    1.024K              |    2.196M  |\n|    layer4.2.conv3              |    1.049M              |    2.249G  |\n|    layer4.2.bn3                |    4.096K              |    8.786M  |\n|  layer6.conv2d_list            |  1.401M                |  3.005G    |\n|   layer6.conv2d_list.0         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n|   layer6.conv2d_list.1         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n|   layer6.conv2d_list.2         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n|   layer6.conv2d_list.3         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n\n\nmIoU: 8.854%, Latency: 0.140, FPS: 63.340\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>▁</td></tr><tr><td>latency</td><td>▁</td></tr><tr><td>loss</td><td>█▂▂▁▁</td></tr><tr><td>mIOU</td><td>▁▃▆█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>63.34041</td></tr><tr><td>latency</td><td>0.13987</td></tr><tr><td>loss</td><td>1.14011</td></tr><tr><td>mIOU</td><td>0.08854</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">decent-sweep-1</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/ebq7xakp' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/ebq7xakp</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240519_114135-ebq7xakp/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1of7cgqi with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_123113-1of7cgqi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/1of7cgqi' target=\"_blank\">smooth-sweep-2</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/1of7cgqi' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/1of7cgqi</a>"},"metadata":{}},{"name":"stdout","text":"Deeplab pretraining loading...\n----------------------------------\nLoss after 1 epochs: 1.149\nmIOU after 1 epochs: 0.160%\n----------------------------------\nLoss after 2 epochs: 0.749\nmIOU after 2 epochs: 0.200%\n----------------------------------\nLoss after 3 epochs: 0.634\nmIOU after 3 epochs: 0.215%\n----------------------------------\nLoss after 4 epochs: 0.571\nmIOU after 4 epochs: 0.225%\n----------------------------------\nLoss after 5 epochs: 0.533\nmIOU after 5 epochs: 0.233%\n| module                         | #parameters or shape   | #flops     |\n|:-------------------------------|:-----------------------|:-----------|\n| model                          | 43.901M                | 95.816G    |\n|  conv1                         |  9.408K                |  0.308G    |\n|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n|  bn1                           |  0.128K                |  4.194M    |\n|   bn1.weight                   |   (64,)                |            |\n|   bn1.bias                     |   (64,)                |            |\n|  layer1                        |  0.216M                |  1.81G     |\n|   layer1.0                     |   75.008K              |   0.629G   |\n|    layer1.0.conv1              |    4.096K              |    34.345M |\n|    layer1.0.bn1                |    0.128K              |    1.073M  |\n|    layer1.0.conv2              |    36.864K             |    0.309G  |\n|    layer1.0.bn2                |    0.128K              |    1.073M  |\n|    layer1.0.conv3              |    16.384K             |    0.137G  |\n|    layer1.0.bn3                |    0.512K              |    4.293M  |\n|    layer1.0.downsample         |    16.896K             |    0.142G  |\n|   layer1.1                     |   70.4K                |   0.59G    |\n|    layer1.1.conv1              |    16.384K             |    0.137G  |\n|    layer1.1.bn1                |    0.128K              |    1.073M  |\n|    layer1.1.conv2              |    36.864K             |    0.309G  |\n|    layer1.1.bn2                |    0.128K              |    1.073M  |\n|    layer1.1.conv3              |    16.384K             |    0.137G  |\n|    layer1.1.bn3                |    0.512K              |    4.293M  |\n|   layer1.2                     |   70.4K                |   0.59G    |\n|    layer1.2.conv1              |    16.384K             |    0.137G  |\n|    layer1.2.bn1                |    0.128K              |    1.073M  |\n|    layer1.2.conv2              |    36.864K             |    0.309G  |\n|    layer1.2.bn2                |    0.128K              |    1.073M  |\n|    layer1.2.conv3              |    16.384K             |    0.137G  |\n|    layer1.2.bn3                |    0.512K              |    4.293M  |\n|  layer2                        |  1.22M                 |  2.616G    |\n|   layer2.0                     |   0.379M               |   0.814G   |\n|    layer2.0.conv1              |    32.768K             |    70.287M |\n|    layer2.0.bn1                |    0.256K              |    0.549M  |\n|    layer2.0.conv2              |    0.147M              |    0.316G  |\n|    layer2.0.bn2                |    0.256K              |    0.549M  |\n|    layer2.0.conv3              |    65.536K             |    0.141G  |\n|    layer2.0.bn3                |    1.024K              |    2.196M  |\n|    layer2.0.downsample         |    0.132M              |    0.283G  |\n|   layer2.1                     |   0.28M                |   0.601G   |\n|    layer2.1.conv1              |    65.536K             |    0.141G  |\n|    layer2.1.bn1                |    0.256K              |    0.549M  |\n|    layer2.1.conv2              |    0.147M              |    0.316G  |\n|    layer2.1.bn2                |    0.256K              |    0.549M  |\n|    layer2.1.conv3              |    65.536K             |    0.141G  |\n|    layer2.1.bn3                |    1.024K              |    2.196M  |\n|   layer2.2                     |   0.28M                |   0.601G   |\n|    layer2.2.conv1              |    65.536K             |    0.141G  |\n|    layer2.2.bn1                |    0.256K              |    0.549M  |\n|    layer2.2.conv2              |    0.147M              |    0.316G  |\n|    layer2.2.bn2                |    0.256K              |    0.549M  |\n|    layer2.2.conv3              |    65.536K             |    0.141G  |\n|    layer2.2.bn3                |    1.024K              |    2.196M  |\n|   layer2.3                     |   0.28M                |   0.601G   |\n|    layer2.3.conv1              |    65.536K             |    0.141G  |\n|    layer2.3.bn1                |    0.256K              |    0.549M  |\n|    layer2.3.conv2              |    0.147M              |    0.316G  |\n|    layer2.3.bn2                |    0.256K              |    0.549M  |\n|    layer2.3.conv3              |    65.536K             |    0.141G  |\n|    layer2.3.bn3                |    1.024K              |    2.196M  |\n|  layer3                        |  26.09M                |  55.964G   |\n|   layer3.0                     |   1.512M               |   3.244G   |\n|    layer3.0.conv1              |    0.131M              |    0.281G  |\n|    layer3.0.bn1                |    0.512K              |    1.098M  |\n|    layer3.0.conv2              |    0.59M               |    1.265G  |\n|    layer3.0.bn2                |    0.512K              |    1.098M  |\n|    layer3.0.conv3              |    0.262M              |    0.562G  |\n|    layer3.0.bn3                |    2.048K              |    4.393M  |\n|    layer3.0.downsample         |    0.526M              |    1.129G  |\n|   layer3.1                     |   1.117M               |   2.396G   |\n|    layer3.1.conv1              |    0.262M              |    0.562G  |\n|    layer3.1.bn1                |    0.512K              |    1.098M  |\n|    layer3.1.conv2              |    0.59M               |    1.265G  |\n|    layer3.1.bn2                |    0.512K              |    1.098M  |\n|    layer3.1.conv3              |    0.262M              |    0.562G  |\n|    layer3.1.bn3                |    2.048K              |    4.393M  |\n|   layer3.2                     |   1.117M               |   2.396G   |\n|    layer3.2.conv1              |    0.262M              |    0.562G  |\n|    layer3.2.bn1                |    0.512K              |    1.098M  |\n|    layer3.2.conv2              |    0.59M               |    1.265G  |\n|    layer3.2.bn2                |    0.512K              |    1.098M  |\n|    layer3.2.conv3              |    0.262M              |    0.562G  |\n|    layer3.2.bn3                |    2.048K              |    4.393M  |\n|   layer3.3                     |   1.117M               |   2.396G   |\n|    layer3.3.conv1              |    0.262M              |    0.562G  |\n|    layer3.3.bn1                |    0.512K              |    1.098M  |\n|    layer3.3.conv2              |    0.59M               |    1.265G  |\n|    layer3.3.bn2                |    0.512K              |    1.098M  |\n|    layer3.3.conv3              |    0.262M              |    0.562G  |\n|    layer3.3.bn3                |    2.048K              |    4.393M  |\n|   layer3.4                     |   1.117M               |   2.396G   |\n|    layer3.4.conv1              |    0.262M              |    0.562G  |\n|    layer3.4.bn1                |    0.512K              |    1.098M  |\n|    layer3.4.conv2              |    0.59M               |    1.265G  |\n|    layer3.4.bn2                |    0.512K              |    1.098M  |\n|    layer3.4.conv3              |    0.262M              |    0.562G  |\n|    layer3.4.bn3                |    2.048K              |    4.393M  |\n|   layer3.5                     |   1.117M               |   2.396G   |\n|    layer3.5.conv1              |    0.262M              |    0.562G  |\n|    layer3.5.bn1                |    0.512K              |    1.098M  |\n|    layer3.5.conv2              |    0.59M               |    1.265G  |\n|    layer3.5.bn2                |    0.512K              |    1.098M  |\n|    layer3.5.conv3              |    0.262M              |    0.562G  |\n|    layer3.5.bn3                |    2.048K              |    4.393M  |\n|   layer3.6                     |   1.117M               |   2.396G   |\n|    layer3.6.conv1              |    0.262M              |    0.562G  |\n|    layer3.6.bn1                |    0.512K              |    1.098M  |\n|    layer3.6.conv2              |    0.59M               |    1.265G  |\n|    layer3.6.bn2                |    0.512K              |    1.098M  |\n|    layer3.6.conv3              |    0.262M              |    0.562G  |\n|    layer3.6.bn3                |    2.048K              |    4.393M  |\n|   layer3.7                     |   1.117M               |   2.396G   |\n|    layer3.7.conv1              |    0.262M              |    0.562G  |\n|    layer3.7.bn1                |    0.512K              |    1.098M  |\n|    layer3.7.conv2              |    0.59M               |    1.265G  |\n|    layer3.7.bn2                |    0.512K              |    1.098M  |\n|    layer3.7.conv3              |    0.262M              |    0.562G  |\n|    layer3.7.bn3                |    2.048K              |    4.393M  |\n|   layer3.8                     |   1.117M               |   2.396G   |\n|    layer3.8.conv1              |    0.262M              |    0.562G  |\n|    layer3.8.bn1                |    0.512K              |    1.098M  |\n|    layer3.8.conv2              |    0.59M               |    1.265G  |\n|    layer3.8.bn2                |    0.512K              |    1.098M  |\n|    layer3.8.conv3              |    0.262M              |    0.562G  |\n|    layer3.8.bn3                |    2.048K              |    4.393M  |\n|   layer3.9                     |   1.117M               |   2.396G   |\n|    layer3.9.conv1              |    0.262M              |    0.562G  |\n|    layer3.9.bn1                |    0.512K              |    1.098M  |\n|    layer3.9.conv2              |    0.59M               |    1.265G  |\n|    layer3.9.bn2                |    0.512K              |    1.098M  |\n|    layer3.9.conv3              |    0.262M              |    0.562G  |\n|    layer3.9.bn3                |    2.048K              |    4.393M  |\n|   layer3.10                    |   1.117M               |   2.396G   |\n|    layer3.10.conv1             |    0.262M              |    0.562G  |\n|    layer3.10.bn1               |    0.512K              |    1.098M  |\n|    layer3.10.conv2             |    0.59M               |    1.265G  |\n|    layer3.10.bn2               |    0.512K              |    1.098M  |\n|    layer3.10.conv3             |    0.262M              |    0.562G  |\n|    layer3.10.bn3               |    2.048K              |    4.393M  |\n|   layer3.11                    |   1.117M               |   2.396G   |\n|    layer3.11.conv1             |    0.262M              |    0.562G  |\n|    layer3.11.bn1               |    0.512K              |    1.098M  |\n|    layer3.11.conv2             |    0.59M               |    1.265G  |\n|    layer3.11.bn2               |    0.512K              |    1.098M  |\n|    layer3.11.conv3             |    0.262M              |    0.562G  |\n|    layer3.11.bn3               |    2.048K              |    4.393M  |\n|   layer3.12                    |   1.117M               |   2.396G   |\n|    layer3.12.conv1             |    0.262M              |    0.562G  |\n|    layer3.12.bn1               |    0.512K              |    1.098M  |\n|    layer3.12.conv2             |    0.59M               |    1.265G  |\n|    layer3.12.bn2               |    0.512K              |    1.098M  |\n|    layer3.12.conv3             |    0.262M              |    0.562G  |\n|    layer3.12.bn3               |    2.048K              |    4.393M  |\n|   layer3.13                    |   1.117M               |   2.396G   |\n|    layer3.13.conv1             |    0.262M              |    0.562G  |\n|    layer3.13.bn1               |    0.512K              |    1.098M  |\n|    layer3.13.conv2             |    0.59M               |    1.265G  |\n|    layer3.13.bn2               |    0.512K              |    1.098M  |\n|    layer3.13.conv3             |    0.262M              |    0.562G  |\n|    layer3.13.bn3               |    2.048K              |    4.393M  |\n|   layer3.14                    |   1.117M               |   2.396G   |\n|    layer3.14.conv1             |    0.262M              |    0.562G  |\n|    layer3.14.bn1               |    0.512K              |    1.098M  |\n|    layer3.14.conv2             |    0.59M               |    1.265G  |\n|    layer3.14.bn2               |    0.512K              |    1.098M  |\n|    layer3.14.conv3             |    0.262M              |    0.562G  |\n|    layer3.14.bn3               |    2.048K              |    4.393M  |\n|   layer3.15                    |   1.117M               |   2.396G   |\n|    layer3.15.conv1             |    0.262M              |    0.562G  |\n|    layer3.15.bn1               |    0.512K              |    1.098M  |\n|    layer3.15.conv2             |    0.59M               |    1.265G  |\n|    layer3.15.bn2               |    0.512K              |    1.098M  |\n|    layer3.15.conv3             |    0.262M              |    0.562G  |\n|    layer3.15.bn3               |    2.048K              |    4.393M  |\n|   layer3.16                    |   1.117M               |   2.396G   |\n|    layer3.16.conv1             |    0.262M              |    0.562G  |\n|    layer3.16.bn1               |    0.512K              |    1.098M  |\n|    layer3.16.conv2             |    0.59M               |    1.265G  |\n|    layer3.16.bn2               |    0.512K              |    1.098M  |\n|    layer3.16.conv3             |    0.262M              |    0.562G  |\n|    layer3.16.bn3               |    2.048K              |    4.393M  |\n|   layer3.17                    |   1.117M               |   2.396G   |\n|    layer3.17.conv1             |    0.262M              |    0.562G  |\n|    layer3.17.bn1               |    0.512K              |    1.098M  |\n|    layer3.17.conv2             |    0.59M               |    1.265G  |\n|    layer3.17.bn2               |    0.512K              |    1.098M  |\n|    layer3.17.conv3             |    0.262M              |    0.562G  |\n|    layer3.17.bn3               |    2.048K              |    4.393M  |\n|   layer3.18                    |   1.117M               |   2.396G   |\n|    layer3.18.conv1             |    0.262M              |    0.562G  |\n|    layer3.18.bn1               |    0.512K              |    1.098M  |\n|    layer3.18.conv2             |    0.59M               |    1.265G  |\n|    layer3.18.bn2               |    0.512K              |    1.098M  |\n|    layer3.18.conv3             |    0.262M              |    0.562G  |\n|    layer3.18.bn3               |    2.048K              |    4.393M  |\n|   layer3.19                    |   1.117M               |   2.396G   |\n|    layer3.19.conv1             |    0.262M              |    0.562G  |\n|    layer3.19.bn1               |    0.512K              |    1.098M  |\n|    layer3.19.conv2             |    0.59M               |    1.265G  |\n|    layer3.19.bn2               |    0.512K              |    1.098M  |\n|    layer3.19.conv3             |    0.262M              |    0.562G  |\n|    layer3.19.bn3               |    2.048K              |    4.393M  |\n|   layer3.20                    |   1.117M               |   2.396G   |\n|    layer3.20.conv1             |    0.262M              |    0.562G  |\n|    layer3.20.bn1               |    0.512K              |    1.098M  |\n|    layer3.20.conv2             |    0.59M               |    1.265G  |\n|    layer3.20.bn2               |    0.512K              |    1.098M  |\n|    layer3.20.conv3             |    0.262M              |    0.562G  |\n|    layer3.20.bn3               |    2.048K              |    4.393M  |\n|   layer3.21                    |   1.117M               |   2.396G   |\n|    layer3.21.conv1             |    0.262M              |    0.562G  |\n|    layer3.21.bn1               |    0.512K              |    1.098M  |\n|    layer3.21.conv2             |    0.59M               |    1.265G  |\n|    layer3.21.bn2               |    0.512K              |    1.098M  |\n|    layer3.21.conv3             |    0.262M              |    0.562G  |\n|    layer3.21.bn3               |    2.048K              |    4.393M  |\n|   layer3.22                    |   1.117M               |   2.396G   |\n|    layer3.22.conv1             |    0.262M              |    0.562G  |\n|    layer3.22.bn1               |    0.512K              |    1.098M  |\n|    layer3.22.conv2             |    0.59M               |    1.265G  |\n|    layer3.22.bn2               |    0.512K              |    1.098M  |\n|    layer3.22.conv3             |    0.262M              |    0.562G  |\n|    layer3.22.bn3               |    2.048K              |    4.393M  |\n|  layer4                        |  14.965M               |  32.099G   |\n|   layer4.0                     |   6.04M                |   12.955G  |\n|    layer4.0.conv1              |    0.524M              |    1.125G  |\n|    layer4.0.bn1                |    1.024K              |    2.196M  |\n|    layer4.0.conv2              |    2.359M              |    5.061G  |\n|    layer4.0.bn2                |    1.024K              |    2.196M  |\n|    layer4.0.conv3              |    1.049M              |    2.249G  |\n|    layer4.0.bn3                |    4.096K              |    8.786M  |\n|    layer4.0.downsample         |    2.101M              |    4.507G  |\n|   layer4.1                     |   4.463M               |   9.572G   |\n|    layer4.1.conv1              |    1.049M              |    2.249G  |\n|    layer4.1.bn1                |    1.024K              |    2.196M  |\n|    layer4.1.conv2              |    2.359M              |    5.061G  |\n|    layer4.1.bn2                |    1.024K              |    2.196M  |\n|    layer4.1.conv3              |    1.049M              |    2.249G  |\n|    layer4.1.bn3                |    4.096K              |    8.786M  |\n|   layer4.2                     |   4.463M               |   9.572G   |\n|    layer4.2.conv1              |    1.049M              |    2.249G  |\n|    layer4.2.bn1                |    1.024K              |    2.196M  |\n|    layer4.2.conv2              |    2.359M              |    5.061G  |\n|    layer4.2.bn2                |    1.024K              |    2.196M  |\n|    layer4.2.conv3              |    1.049M              |    2.249G  |\n|    layer4.2.bn3                |    4.096K              |    8.786M  |\n|  layer6.conv2d_list            |  1.401M                |  3.005G    |\n|   layer6.conv2d_list.0         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n|   layer6.conv2d_list.1         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n|   layer6.conv2d_list.2         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n|   layer6.conv2d_list.3         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n\n\nmIoU: 21.439%, Latency: 0.116, FPS: 65.389\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>▁</td></tr><tr><td>latency</td><td>▁</td></tr><tr><td>loss</td><td>█▃▂▁▁</td></tr><tr><td>mIOU</td><td>▁▅▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>65.38925</td></tr><tr><td>latency</td><td>0.11648</td></tr><tr><td>loss</td><td>0.53347</td></tr><tr><td>mIOU</td><td>0.21439</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">smooth-sweep-2</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/1of7cgqi' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/1of7cgqi</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240519_123113-1of7cgqi/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xjb1rfba with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_132306-xjb1rfba</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/xjb1rfba' target=\"_blank\">genial-sweep-3</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/xjb1rfba' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/xjb1rfba</a>"},"metadata":{}},{"name":"stdout","text":"Deeplab pretraining loading...\n----------------------------------\nLoss after 1 epochs: 1.144\nmIOU after 1 epochs: 0.160%\n----------------------------------\nLoss after 2 epochs: 0.760\nmIOU after 2 epochs: 0.199%\n----------------------------------\nLoss after 3 epochs: 0.641\nmIOU after 3 epochs: 0.215%\n----------------------------------\nLoss after 4 epochs: 0.575\nmIOU after 4 epochs: 0.225%\n----------------------------------\nLoss after 5 epochs: 0.536\nmIOU after 5 epochs: 0.232%\n| module                         | #parameters or shape   | #flops     |\n|:-------------------------------|:-----------------------|:-----------|\n| model                          | 43.901M                | 95.816G    |\n|  conv1                         |  9.408K                |  0.308G    |\n|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n|  bn1                           |  0.128K                |  4.194M    |\n|   bn1.weight                   |   (64,)                |            |\n|   bn1.bias                     |   (64,)                |            |\n|  layer1                        |  0.216M                |  1.81G     |\n|   layer1.0                     |   75.008K              |   0.629G   |\n|    layer1.0.conv1              |    4.096K              |    34.345M |\n|    layer1.0.bn1                |    0.128K              |    1.073M  |\n|    layer1.0.conv2              |    36.864K             |    0.309G  |\n|    layer1.0.bn2                |    0.128K              |    1.073M  |\n|    layer1.0.conv3              |    16.384K             |    0.137G  |\n|    layer1.0.bn3                |    0.512K              |    4.293M  |\n|    layer1.0.downsample         |    16.896K             |    0.142G  |\n|   layer1.1                     |   70.4K                |   0.59G    |\n|    layer1.1.conv1              |    16.384K             |    0.137G  |\n|    layer1.1.bn1                |    0.128K              |    1.073M  |\n|    layer1.1.conv2              |    36.864K             |    0.309G  |\n|    layer1.1.bn2                |    0.128K              |    1.073M  |\n|    layer1.1.conv3              |    16.384K             |    0.137G  |\n|    layer1.1.bn3                |    0.512K              |    4.293M  |\n|   layer1.2                     |   70.4K                |   0.59G    |\n|    layer1.2.conv1              |    16.384K             |    0.137G  |\n|    layer1.2.bn1                |    0.128K              |    1.073M  |\n|    layer1.2.conv2              |    36.864K             |    0.309G  |\n|    layer1.2.bn2                |    0.128K              |    1.073M  |\n|    layer1.2.conv3              |    16.384K             |    0.137G  |\n|    layer1.2.bn3                |    0.512K              |    4.293M  |\n|  layer2                        |  1.22M                 |  2.616G    |\n|   layer2.0                     |   0.379M               |   0.814G   |\n|    layer2.0.conv1              |    32.768K             |    70.287M |\n|    layer2.0.bn1                |    0.256K              |    0.549M  |\n|    layer2.0.conv2              |    0.147M              |    0.316G  |\n|    layer2.0.bn2                |    0.256K              |    0.549M  |\n|    layer2.0.conv3              |    65.536K             |    0.141G  |\n|    layer2.0.bn3                |    1.024K              |    2.196M  |\n|    layer2.0.downsample         |    0.132M              |    0.283G  |\n|   layer2.1                     |   0.28M                |   0.601G   |\n|    layer2.1.conv1              |    65.536K             |    0.141G  |\n|    layer2.1.bn1                |    0.256K              |    0.549M  |\n|    layer2.1.conv2              |    0.147M              |    0.316G  |\n|    layer2.1.bn2                |    0.256K              |    0.549M  |\n|    layer2.1.conv3              |    65.536K             |    0.141G  |\n|    layer2.1.bn3                |    1.024K              |    2.196M  |\n|   layer2.2                     |   0.28M                |   0.601G   |\n|    layer2.2.conv1              |    65.536K             |    0.141G  |\n|    layer2.2.bn1                |    0.256K              |    0.549M  |\n|    layer2.2.conv2              |    0.147M              |    0.316G  |\n|    layer2.2.bn2                |    0.256K              |    0.549M  |\n|    layer2.2.conv3              |    65.536K             |    0.141G  |\n|    layer2.2.bn3                |    1.024K              |    2.196M  |\n|   layer2.3                     |   0.28M                |   0.601G   |\n|    layer2.3.conv1              |    65.536K             |    0.141G  |\n|    layer2.3.bn1                |    0.256K              |    0.549M  |\n|    layer2.3.conv2              |    0.147M              |    0.316G  |\n|    layer2.3.bn2                |    0.256K              |    0.549M  |\n|    layer2.3.conv3              |    65.536K             |    0.141G  |\n|    layer2.3.bn3                |    1.024K              |    2.196M  |\n|  layer3                        |  26.09M                |  55.964G   |\n|   layer3.0                     |   1.512M               |   3.244G   |\n|    layer3.0.conv1              |    0.131M              |    0.281G  |\n|    layer3.0.bn1                |    0.512K              |    1.098M  |\n|    layer3.0.conv2              |    0.59M               |    1.265G  |\n|    layer3.0.bn2                |    0.512K              |    1.098M  |\n|    layer3.0.conv3              |    0.262M              |    0.562G  |\n|    layer3.0.bn3                |    2.048K              |    4.393M  |\n|    layer3.0.downsample         |    0.526M              |    1.129G  |\n|   layer3.1                     |   1.117M               |   2.396G   |\n|    layer3.1.conv1              |    0.262M              |    0.562G  |\n|    layer3.1.bn1                |    0.512K              |    1.098M  |\n|    layer3.1.conv2              |    0.59M               |    1.265G  |\n|    layer3.1.bn2                |    0.512K              |    1.098M  |\n|    layer3.1.conv3              |    0.262M              |    0.562G  |\n|    layer3.1.bn3                |    2.048K              |    4.393M  |\n|   layer3.2                     |   1.117M               |   2.396G   |\n|    layer3.2.conv1              |    0.262M              |    0.562G  |\n|    layer3.2.bn1                |    0.512K              |    1.098M  |\n|    layer3.2.conv2              |    0.59M               |    1.265G  |\n|    layer3.2.bn2                |    0.512K              |    1.098M  |\n|    layer3.2.conv3              |    0.262M              |    0.562G  |\n|    layer3.2.bn3                |    2.048K              |    4.393M  |\n|   layer3.3                     |   1.117M               |   2.396G   |\n|    layer3.3.conv1              |    0.262M              |    0.562G  |\n|    layer3.3.bn1                |    0.512K              |    1.098M  |\n|    layer3.3.conv2              |    0.59M               |    1.265G  |\n|    layer3.3.bn2                |    0.512K              |    1.098M  |\n|    layer3.3.conv3              |    0.262M              |    0.562G  |\n|    layer3.3.bn3                |    2.048K              |    4.393M  |\n|   layer3.4                     |   1.117M               |   2.396G   |\n|    layer3.4.conv1              |    0.262M              |    0.562G  |\n|    layer3.4.bn1                |    0.512K              |    1.098M  |\n|    layer3.4.conv2              |    0.59M               |    1.265G  |\n|    layer3.4.bn2                |    0.512K              |    1.098M  |\n|    layer3.4.conv3              |    0.262M              |    0.562G  |\n|    layer3.4.bn3                |    2.048K              |    4.393M  |\n|   layer3.5                     |   1.117M               |   2.396G   |\n|    layer3.5.conv1              |    0.262M              |    0.562G  |\n|    layer3.5.bn1                |    0.512K              |    1.098M  |\n|    layer3.5.conv2              |    0.59M               |    1.265G  |\n|    layer3.5.bn2                |    0.512K              |    1.098M  |\n|    layer3.5.conv3              |    0.262M              |    0.562G  |\n|    layer3.5.bn3                |    2.048K              |    4.393M  |\n|   layer3.6                     |   1.117M               |   2.396G   |\n|    layer3.6.conv1              |    0.262M              |    0.562G  |\n|    layer3.6.bn1                |    0.512K              |    1.098M  |\n|    layer3.6.conv2              |    0.59M               |    1.265G  |\n|    layer3.6.bn2                |    0.512K              |    1.098M  |\n|    layer3.6.conv3              |    0.262M              |    0.562G  |\n|    layer3.6.bn3                |    2.048K              |    4.393M  |\n|   layer3.7                     |   1.117M               |   2.396G   |\n|    layer3.7.conv1              |    0.262M              |    0.562G  |\n|    layer3.7.bn1                |    0.512K              |    1.098M  |\n|    layer3.7.conv2              |    0.59M               |    1.265G  |\n|    layer3.7.bn2                |    0.512K              |    1.098M  |\n|    layer3.7.conv3              |    0.262M              |    0.562G  |\n|    layer3.7.bn3                |    2.048K              |    4.393M  |\n|   layer3.8                     |   1.117M               |   2.396G   |\n|    layer3.8.conv1              |    0.262M              |    0.562G  |\n|    layer3.8.bn1                |    0.512K              |    1.098M  |\n|    layer3.8.conv2              |    0.59M               |    1.265G  |\n|    layer3.8.bn2                |    0.512K              |    1.098M  |\n|    layer3.8.conv3              |    0.262M              |    0.562G  |\n|    layer3.8.bn3                |    2.048K              |    4.393M  |\n|   layer3.9                     |   1.117M               |   2.396G   |\n|    layer3.9.conv1              |    0.262M              |    0.562G  |\n|    layer3.9.bn1                |    0.512K              |    1.098M  |\n|    layer3.9.conv2              |    0.59M               |    1.265G  |\n|    layer3.9.bn2                |    0.512K              |    1.098M  |\n|    layer3.9.conv3              |    0.262M              |    0.562G  |\n|    layer3.9.bn3                |    2.048K              |    4.393M  |\n|   layer3.10                    |   1.117M               |   2.396G   |\n|    layer3.10.conv1             |    0.262M              |    0.562G  |\n|    layer3.10.bn1               |    0.512K              |    1.098M  |\n|    layer3.10.conv2             |    0.59M               |    1.265G  |\n|    layer3.10.bn2               |    0.512K              |    1.098M  |\n|    layer3.10.conv3             |    0.262M              |    0.562G  |\n|    layer3.10.bn3               |    2.048K              |    4.393M  |\n|   layer3.11                    |   1.117M               |   2.396G   |\n|    layer3.11.conv1             |    0.262M              |    0.562G  |\n|    layer3.11.bn1               |    0.512K              |    1.098M  |\n|    layer3.11.conv2             |    0.59M               |    1.265G  |\n|    layer3.11.bn2               |    0.512K              |    1.098M  |\n|    layer3.11.conv3             |    0.262M              |    0.562G  |\n|    layer3.11.bn3               |    2.048K              |    4.393M  |\n|   layer3.12                    |   1.117M               |   2.396G   |\n|    layer3.12.conv1             |    0.262M              |    0.562G  |\n|    layer3.12.bn1               |    0.512K              |    1.098M  |\n|    layer3.12.conv2             |    0.59M               |    1.265G  |\n|    layer3.12.bn2               |    0.512K              |    1.098M  |\n|    layer3.12.conv3             |    0.262M              |    0.562G  |\n|    layer3.12.bn3               |    2.048K              |    4.393M  |\n|   layer3.13                    |   1.117M               |   2.396G   |\n|    layer3.13.conv1             |    0.262M              |    0.562G  |\n|    layer3.13.bn1               |    0.512K              |    1.098M  |\n|    layer3.13.conv2             |    0.59M               |    1.265G  |\n|    layer3.13.bn2               |    0.512K              |    1.098M  |\n|    layer3.13.conv3             |    0.262M              |    0.562G  |\n|    layer3.13.bn3               |    2.048K              |    4.393M  |\n|   layer3.14                    |   1.117M               |   2.396G   |\n|    layer3.14.conv1             |    0.262M              |    0.562G  |\n|    layer3.14.bn1               |    0.512K              |    1.098M  |\n|    layer3.14.conv2             |    0.59M               |    1.265G  |\n|    layer3.14.bn2               |    0.512K              |    1.098M  |\n|    layer3.14.conv3             |    0.262M              |    0.562G  |\n|    layer3.14.bn3               |    2.048K              |    4.393M  |\n|   layer3.15                    |   1.117M               |   2.396G   |\n|    layer3.15.conv1             |    0.262M              |    0.562G  |\n|    layer3.15.bn1               |    0.512K              |    1.098M  |\n|    layer3.15.conv2             |    0.59M               |    1.265G  |\n|    layer3.15.bn2               |    0.512K              |    1.098M  |\n|    layer3.15.conv3             |    0.262M              |    0.562G  |\n|    layer3.15.bn3               |    2.048K              |    4.393M  |\n|   layer3.16                    |   1.117M               |   2.396G   |\n|    layer3.16.conv1             |    0.262M              |    0.562G  |\n|    layer3.16.bn1               |    0.512K              |    1.098M  |\n|    layer3.16.conv2             |    0.59M               |    1.265G  |\n|    layer3.16.bn2               |    0.512K              |    1.098M  |\n|    layer3.16.conv3             |    0.262M              |    0.562G  |\n|    layer3.16.bn3               |    2.048K              |    4.393M  |\n|   layer3.17                    |   1.117M               |   2.396G   |\n|    layer3.17.conv1             |    0.262M              |    0.562G  |\n|    layer3.17.bn1               |    0.512K              |    1.098M  |\n|    layer3.17.conv2             |    0.59M               |    1.265G  |\n|    layer3.17.bn2               |    0.512K              |    1.098M  |\n|    layer3.17.conv3             |    0.262M              |    0.562G  |\n|    layer3.17.bn3               |    2.048K              |    4.393M  |\n|   layer3.18                    |   1.117M               |   2.396G   |\n|    layer3.18.conv1             |    0.262M              |    0.562G  |\n|    layer3.18.bn1               |    0.512K              |    1.098M  |\n|    layer3.18.conv2             |    0.59M               |    1.265G  |\n|    layer3.18.bn2               |    0.512K              |    1.098M  |\n|    layer3.18.conv3             |    0.262M              |    0.562G  |\n|    layer3.18.bn3               |    2.048K              |    4.393M  |\n|   layer3.19                    |   1.117M               |   2.396G   |\n|    layer3.19.conv1             |    0.262M              |    0.562G  |\n|    layer3.19.bn1               |    0.512K              |    1.098M  |\n|    layer3.19.conv2             |    0.59M               |    1.265G  |\n|    layer3.19.bn2               |    0.512K              |    1.098M  |\n|    layer3.19.conv3             |    0.262M              |    0.562G  |\n|    layer3.19.bn3               |    2.048K              |    4.393M  |\n|   layer3.20                    |   1.117M               |   2.396G   |\n|    layer3.20.conv1             |    0.262M              |    0.562G  |\n|    layer3.20.bn1               |    0.512K              |    1.098M  |\n|    layer3.20.conv2             |    0.59M               |    1.265G  |\n|    layer3.20.bn2               |    0.512K              |    1.098M  |\n|    layer3.20.conv3             |    0.262M              |    0.562G  |\n|    layer3.20.bn3               |    2.048K              |    4.393M  |\n|   layer3.21                    |   1.117M               |   2.396G   |\n|    layer3.21.conv1             |    0.262M              |    0.562G  |\n|    layer3.21.bn1               |    0.512K              |    1.098M  |\n|    layer3.21.conv2             |    0.59M               |    1.265G  |\n|    layer3.21.bn2               |    0.512K              |    1.098M  |\n|    layer3.21.conv3             |    0.262M              |    0.562G  |\n|    layer3.21.bn3               |    2.048K              |    4.393M  |\n|   layer3.22                    |   1.117M               |   2.396G   |\n|    layer3.22.conv1             |    0.262M              |    0.562G  |\n|    layer3.22.bn1               |    0.512K              |    1.098M  |\n|    layer3.22.conv2             |    0.59M               |    1.265G  |\n|    layer3.22.bn2               |    0.512K              |    1.098M  |\n|    layer3.22.conv3             |    0.262M              |    0.562G  |\n|    layer3.22.bn3               |    2.048K              |    4.393M  |\n|  layer4                        |  14.965M               |  32.099G   |\n|   layer4.0                     |   6.04M                |   12.955G  |\n|    layer4.0.conv1              |    0.524M              |    1.125G  |\n|    layer4.0.bn1                |    1.024K              |    2.196M  |\n|    layer4.0.conv2              |    2.359M              |    5.061G  |\n|    layer4.0.bn2                |    1.024K              |    2.196M  |\n|    layer4.0.conv3              |    1.049M              |    2.249G  |\n|    layer4.0.bn3                |    4.096K              |    8.786M  |\n|    layer4.0.downsample         |    2.101M              |    4.507G  |\n|   layer4.1                     |   4.463M               |   9.572G   |\n|    layer4.1.conv1              |    1.049M              |    2.249G  |\n|    layer4.1.bn1                |    1.024K              |    2.196M  |\n|    layer4.1.conv2              |    2.359M              |    5.061G  |\n|    layer4.1.bn2                |    1.024K              |    2.196M  |\n|    layer4.1.conv3              |    1.049M              |    2.249G  |\n|    layer4.1.bn3                |    4.096K              |    8.786M  |\n|   layer4.2                     |   4.463M               |   9.572G   |\n|    layer4.2.conv1              |    1.049M              |    2.249G  |\n|    layer4.2.bn1                |    1.024K              |    2.196M  |\n|    layer4.2.conv2              |    2.359M              |    5.061G  |\n|    layer4.2.bn2                |    1.024K              |    2.196M  |\n|    layer4.2.conv3              |    1.049M              |    2.249G  |\n|    layer4.2.bn3                |    4.096K              |    8.786M  |\n|  layer6.conv2d_list            |  1.401M                |  3.005G    |\n|   layer6.conv2d_list.0         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n|   layer6.conv2d_list.1         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n|   layer6.conv2d_list.2         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n|   layer6.conv2d_list.3         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n\n\nmIoU: 21.426%, Latency: 0.118, FPS: 64.448\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>▁</td></tr><tr><td>latency</td><td>▁</td></tr><tr><td>loss</td><td>█▄▂▁▁</td></tr><tr><td>mIOU</td><td>▁▅▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>64.44818</td></tr><tr><td>latency</td><td>0.1177</td></tr><tr><td>loss</td><td>0.53576</td></tr><tr><td>mIOU</td><td>0.21426</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">genial-sweep-3</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/xjb1rfba' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/xjb1rfba</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240519_132306-xjb1rfba/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wa0tsz5z with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_141506-wa0tsz5z</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/wa0tsz5z' target=\"_blank\">lunar-sweep-4</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/wa0tsz5z' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/wa0tsz5z</a>"},"metadata":{}},{"name":"stdout","text":"Deeplab pretraining loading...\n----------------------------------\nLoss after 1 epochs: 1.316\nmIOU after 1 epochs: 0.146%\n----------------------------------\nLoss after 2 epochs: 0.877\nmIOU after 2 epochs: 0.184%\n----------------------------------\nLoss after 3 epochs: 0.748\nmIOU after 3 epochs: 0.199%\n----------------------------------\nLoss after 4 epochs: 0.666\nmIOU after 4 epochs: 0.210%\n----------------------------------\nLoss after 5 epochs: 0.616\nmIOU after 5 epochs: 0.216%\n| module                         | #parameters or shape   | #flops     |\n|:-------------------------------|:-----------------------|:-----------|\n| model                          | 43.901M                | 95.816G    |\n|  conv1                         |  9.408K                |  0.308G    |\n|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n|  bn1                           |  0.128K                |  4.194M    |\n|   bn1.weight                   |   (64,)                |            |\n|   bn1.bias                     |   (64,)                |            |\n|  layer1                        |  0.216M                |  1.81G     |\n|   layer1.0                     |   75.008K              |   0.629G   |\n|    layer1.0.conv1              |    4.096K              |    34.345M |\n|    layer1.0.bn1                |    0.128K              |    1.073M  |\n|    layer1.0.conv2              |    36.864K             |    0.309G  |\n|    layer1.0.bn2                |    0.128K              |    1.073M  |\n|    layer1.0.conv3              |    16.384K             |    0.137G  |\n|    layer1.0.bn3                |    0.512K              |    4.293M  |\n|    layer1.0.downsample         |    16.896K             |    0.142G  |\n|   layer1.1                     |   70.4K                |   0.59G    |\n|    layer1.1.conv1              |    16.384K             |    0.137G  |\n|    layer1.1.bn1                |    0.128K              |    1.073M  |\n|    layer1.1.conv2              |    36.864K             |    0.309G  |\n|    layer1.1.bn2                |    0.128K              |    1.073M  |\n|    layer1.1.conv3              |    16.384K             |    0.137G  |\n|    layer1.1.bn3                |    0.512K              |    4.293M  |\n|   layer1.2                     |   70.4K                |   0.59G    |\n|    layer1.2.conv1              |    16.384K             |    0.137G  |\n|    layer1.2.bn1                |    0.128K              |    1.073M  |\n|    layer1.2.conv2              |    36.864K             |    0.309G  |\n|    layer1.2.bn2                |    0.128K              |    1.073M  |\n|    layer1.2.conv3              |    16.384K             |    0.137G  |\n|    layer1.2.bn3                |    0.512K              |    4.293M  |\n|  layer2                        |  1.22M                 |  2.616G    |\n|   layer2.0                     |   0.379M               |   0.814G   |\n|    layer2.0.conv1              |    32.768K             |    70.287M |\n|    layer2.0.bn1                |    0.256K              |    0.549M  |\n|    layer2.0.conv2              |    0.147M              |    0.316G  |\n|    layer2.0.bn2                |    0.256K              |    0.549M  |\n|    layer2.0.conv3              |    65.536K             |    0.141G  |\n|    layer2.0.bn3                |    1.024K              |    2.196M  |\n|    layer2.0.downsample         |    0.132M              |    0.283G  |\n|   layer2.1                     |   0.28M                |   0.601G   |\n|    layer2.1.conv1              |    65.536K             |    0.141G  |\n|    layer2.1.bn1                |    0.256K              |    0.549M  |\n|    layer2.1.conv2              |    0.147M              |    0.316G  |\n|    layer2.1.bn2                |    0.256K              |    0.549M  |\n|    layer2.1.conv3              |    65.536K             |    0.141G  |\n|    layer2.1.bn3                |    1.024K              |    2.196M  |\n|   layer2.2                     |   0.28M                |   0.601G   |\n|    layer2.2.conv1              |    65.536K             |    0.141G  |\n|    layer2.2.bn1                |    0.256K              |    0.549M  |\n|    layer2.2.conv2              |    0.147M              |    0.316G  |\n|    layer2.2.bn2                |    0.256K              |    0.549M  |\n|    layer2.2.conv3              |    65.536K             |    0.141G  |\n|    layer2.2.bn3                |    1.024K              |    2.196M  |\n|   layer2.3                     |   0.28M                |   0.601G   |\n|    layer2.3.conv1              |    65.536K             |    0.141G  |\n|    layer2.3.bn1                |    0.256K              |    0.549M  |\n|    layer2.3.conv2              |    0.147M              |    0.316G  |\n|    layer2.3.bn2                |    0.256K              |    0.549M  |\n|    layer2.3.conv3              |    65.536K             |    0.141G  |\n|    layer2.3.bn3                |    1.024K              |    2.196M  |\n|  layer3                        |  26.09M                |  55.964G   |\n|   layer3.0                     |   1.512M               |   3.244G   |\n|    layer3.0.conv1              |    0.131M              |    0.281G  |\n|    layer3.0.bn1                |    0.512K              |    1.098M  |\n|    layer3.0.conv2              |    0.59M               |    1.265G  |\n|    layer3.0.bn2                |    0.512K              |    1.098M  |\n|    layer3.0.conv3              |    0.262M              |    0.562G  |\n|    layer3.0.bn3                |    2.048K              |    4.393M  |\n|    layer3.0.downsample         |    0.526M              |    1.129G  |\n|   layer3.1                     |   1.117M               |   2.396G   |\n|    layer3.1.conv1              |    0.262M              |    0.562G  |\n|    layer3.1.bn1                |    0.512K              |    1.098M  |\n|    layer3.1.conv2              |    0.59M               |    1.265G  |\n|    layer3.1.bn2                |    0.512K              |    1.098M  |\n|    layer3.1.conv3              |    0.262M              |    0.562G  |\n|    layer3.1.bn3                |    2.048K              |    4.393M  |\n|   layer3.2                     |   1.117M               |   2.396G   |\n|    layer3.2.conv1              |    0.262M              |    0.562G  |\n|    layer3.2.bn1                |    0.512K              |    1.098M  |\n|    layer3.2.conv2              |    0.59M               |    1.265G  |\n|    layer3.2.bn2                |    0.512K              |    1.098M  |\n|    layer3.2.conv3              |    0.262M              |    0.562G  |\n|    layer3.2.bn3                |    2.048K              |    4.393M  |\n|   layer3.3                     |   1.117M               |   2.396G   |\n|    layer3.3.conv1              |    0.262M              |    0.562G  |\n|    layer3.3.bn1                |    0.512K              |    1.098M  |\n|    layer3.3.conv2              |    0.59M               |    1.265G  |\n|    layer3.3.bn2                |    0.512K              |    1.098M  |\n|    layer3.3.conv3              |    0.262M              |    0.562G  |\n|    layer3.3.bn3                |    2.048K              |    4.393M  |\n|   layer3.4                     |   1.117M               |   2.396G   |\n|    layer3.4.conv1              |    0.262M              |    0.562G  |\n|    layer3.4.bn1                |    0.512K              |    1.098M  |\n|    layer3.4.conv2              |    0.59M               |    1.265G  |\n|    layer3.4.bn2                |    0.512K              |    1.098M  |\n|    layer3.4.conv3              |    0.262M              |    0.562G  |\n|    layer3.4.bn3                |    2.048K              |    4.393M  |\n|   layer3.5                     |   1.117M               |   2.396G   |\n|    layer3.5.conv1              |    0.262M              |    0.562G  |\n|    layer3.5.bn1                |    0.512K              |    1.098M  |\n|    layer3.5.conv2              |    0.59M               |    1.265G  |\n|    layer3.5.bn2                |    0.512K              |    1.098M  |\n|    layer3.5.conv3              |    0.262M              |    0.562G  |\n|    layer3.5.bn3                |    2.048K              |    4.393M  |\n|   layer3.6                     |   1.117M               |   2.396G   |\n|    layer3.6.conv1              |    0.262M              |    0.562G  |\n|    layer3.6.bn1                |    0.512K              |    1.098M  |\n|    layer3.6.conv2              |    0.59M               |    1.265G  |\n|    layer3.6.bn2                |    0.512K              |    1.098M  |\n|    layer3.6.conv3              |    0.262M              |    0.562G  |\n|    layer3.6.bn3                |    2.048K              |    4.393M  |\n|   layer3.7                     |   1.117M               |   2.396G   |\n|    layer3.7.conv1              |    0.262M              |    0.562G  |\n|    layer3.7.bn1                |    0.512K              |    1.098M  |\n|    layer3.7.conv2              |    0.59M               |    1.265G  |\n|    layer3.7.bn2                |    0.512K              |    1.098M  |\n|    layer3.7.conv3              |    0.262M              |    0.562G  |\n|    layer3.7.bn3                |    2.048K              |    4.393M  |\n|   layer3.8                     |   1.117M               |   2.396G   |\n|    layer3.8.conv1              |    0.262M              |    0.562G  |\n|    layer3.8.bn1                |    0.512K              |    1.098M  |\n|    layer3.8.conv2              |    0.59M               |    1.265G  |\n|    layer3.8.bn2                |    0.512K              |    1.098M  |\n|    layer3.8.conv3              |    0.262M              |    0.562G  |\n|    layer3.8.bn3                |    2.048K              |    4.393M  |\n|   layer3.9                     |   1.117M               |   2.396G   |\n|    layer3.9.conv1              |    0.262M              |    0.562G  |\n|    layer3.9.bn1                |    0.512K              |    1.098M  |\n|    layer3.9.conv2              |    0.59M               |    1.265G  |\n|    layer3.9.bn2                |    0.512K              |    1.098M  |\n|    layer3.9.conv3              |    0.262M              |    0.562G  |\n|    layer3.9.bn3                |    2.048K              |    4.393M  |\n|   layer3.10                    |   1.117M               |   2.396G   |\n|    layer3.10.conv1             |    0.262M              |    0.562G  |\n|    layer3.10.bn1               |    0.512K              |    1.098M  |\n|    layer3.10.conv2             |    0.59M               |    1.265G  |\n|    layer3.10.bn2               |    0.512K              |    1.098M  |\n|    layer3.10.conv3             |    0.262M              |    0.562G  |\n|    layer3.10.bn3               |    2.048K              |    4.393M  |\n|   layer3.11                    |   1.117M               |   2.396G   |\n|    layer3.11.conv1             |    0.262M              |    0.562G  |\n|    layer3.11.bn1               |    0.512K              |    1.098M  |\n|    layer3.11.conv2             |    0.59M               |    1.265G  |\n|    layer3.11.bn2               |    0.512K              |    1.098M  |\n|    layer3.11.conv3             |    0.262M              |    0.562G  |\n|    layer3.11.bn3               |    2.048K              |    4.393M  |\n|   layer3.12                    |   1.117M               |   2.396G   |\n|    layer3.12.conv1             |    0.262M              |    0.562G  |\n|    layer3.12.bn1               |    0.512K              |    1.098M  |\n|    layer3.12.conv2             |    0.59M               |    1.265G  |\n|    layer3.12.bn2               |    0.512K              |    1.098M  |\n|    layer3.12.conv3             |    0.262M              |    0.562G  |\n|    layer3.12.bn3               |    2.048K              |    4.393M  |\n|   layer3.13                    |   1.117M               |   2.396G   |\n|    layer3.13.conv1             |    0.262M              |    0.562G  |\n|    layer3.13.bn1               |    0.512K              |    1.098M  |\n|    layer3.13.conv2             |    0.59M               |    1.265G  |\n|    layer3.13.bn2               |    0.512K              |    1.098M  |\n|    layer3.13.conv3             |    0.262M              |    0.562G  |\n|    layer3.13.bn3               |    2.048K              |    4.393M  |\n|   layer3.14                    |   1.117M               |   2.396G   |\n|    layer3.14.conv1             |    0.262M              |    0.562G  |\n|    layer3.14.bn1               |    0.512K              |    1.098M  |\n|    layer3.14.conv2             |    0.59M               |    1.265G  |\n|    layer3.14.bn2               |    0.512K              |    1.098M  |\n|    layer3.14.conv3             |    0.262M              |    0.562G  |\n|    layer3.14.bn3               |    2.048K              |    4.393M  |\n|   layer3.15                    |   1.117M               |   2.396G   |\n|    layer3.15.conv1             |    0.262M              |    0.562G  |\n|    layer3.15.bn1               |    0.512K              |    1.098M  |\n|    layer3.15.conv2             |    0.59M               |    1.265G  |\n|    layer3.15.bn2               |    0.512K              |    1.098M  |\n|    layer3.15.conv3             |    0.262M              |    0.562G  |\n|    layer3.15.bn3               |    2.048K              |    4.393M  |\n|   layer3.16                    |   1.117M               |   2.396G   |\n|    layer3.16.conv1             |    0.262M              |    0.562G  |\n|    layer3.16.bn1               |    0.512K              |    1.098M  |\n|    layer3.16.conv2             |    0.59M               |    1.265G  |\n|    layer3.16.bn2               |    0.512K              |    1.098M  |\n|    layer3.16.conv3             |    0.262M              |    0.562G  |\n|    layer3.16.bn3               |    2.048K              |    4.393M  |\n|   layer3.17                    |   1.117M               |   2.396G   |\n|    layer3.17.conv1             |    0.262M              |    0.562G  |\n|    layer3.17.bn1               |    0.512K              |    1.098M  |\n|    layer3.17.conv2             |    0.59M               |    1.265G  |\n|    layer3.17.bn2               |    0.512K              |    1.098M  |\n|    layer3.17.conv3             |    0.262M              |    0.562G  |\n|    layer3.17.bn3               |    2.048K              |    4.393M  |\n|   layer3.18                    |   1.117M               |   2.396G   |\n|    layer3.18.conv1             |    0.262M              |    0.562G  |\n|    layer3.18.bn1               |    0.512K              |    1.098M  |\n|    layer3.18.conv2             |    0.59M               |    1.265G  |\n|    layer3.18.bn2               |    0.512K              |    1.098M  |\n|    layer3.18.conv3             |    0.262M              |    0.562G  |\n|    layer3.18.bn3               |    2.048K              |    4.393M  |\n|   layer3.19                    |   1.117M               |   2.396G   |\n|    layer3.19.conv1             |    0.262M              |    0.562G  |\n|    layer3.19.bn1               |    0.512K              |    1.098M  |\n|    layer3.19.conv2             |    0.59M               |    1.265G  |\n|    layer3.19.bn2               |    0.512K              |    1.098M  |\n|    layer3.19.conv3             |    0.262M              |    0.562G  |\n|    layer3.19.bn3               |    2.048K              |    4.393M  |\n|   layer3.20                    |   1.117M               |   2.396G   |\n|    layer3.20.conv1             |    0.262M              |    0.562G  |\n|    layer3.20.bn1               |    0.512K              |    1.098M  |\n|    layer3.20.conv2             |    0.59M               |    1.265G  |\n|    layer3.20.bn2               |    0.512K              |    1.098M  |\n|    layer3.20.conv3             |    0.262M              |    0.562G  |\n|    layer3.20.bn3               |    2.048K              |    4.393M  |\n|   layer3.21                    |   1.117M               |   2.396G   |\n|    layer3.21.conv1             |    0.262M              |    0.562G  |\n|    layer3.21.bn1               |    0.512K              |    1.098M  |\n|    layer3.21.conv2             |    0.59M               |    1.265G  |\n|    layer3.21.bn2               |    0.512K              |    1.098M  |\n|    layer3.21.conv3             |    0.262M              |    0.562G  |\n|    layer3.21.bn3               |    2.048K              |    4.393M  |\n|   layer3.22                    |   1.117M               |   2.396G   |\n|    layer3.22.conv1             |    0.262M              |    0.562G  |\n|    layer3.22.bn1               |    0.512K              |    1.098M  |\n|    layer3.22.conv2             |    0.59M               |    1.265G  |\n|    layer3.22.bn2               |    0.512K              |    1.098M  |\n|    layer3.22.conv3             |    0.262M              |    0.562G  |\n|    layer3.22.bn3               |    2.048K              |    4.393M  |\n|  layer4                        |  14.965M               |  32.099G   |\n|   layer4.0                     |   6.04M                |   12.955G  |\n|    layer4.0.conv1              |    0.524M              |    1.125G  |\n|    layer4.0.bn1                |    1.024K              |    2.196M  |\n|    layer4.0.conv2              |    2.359M              |    5.061G  |\n|    layer4.0.bn2                |    1.024K              |    2.196M  |\n|    layer4.0.conv3              |    1.049M              |    2.249G  |\n|    layer4.0.bn3                |    4.096K              |    8.786M  |\n|    layer4.0.downsample         |    2.101M              |    4.507G  |\n|   layer4.1                     |   4.463M               |   9.572G   |\n|    layer4.1.conv1              |    1.049M              |    2.249G  |\n|    layer4.1.bn1                |    1.024K              |    2.196M  |\n|    layer4.1.conv2              |    2.359M              |    5.061G  |\n|    layer4.1.bn2                |    1.024K              |    2.196M  |\n|    layer4.1.conv3              |    1.049M              |    2.249G  |\n|    layer4.1.bn3                |    4.096K              |    8.786M  |\n|   layer4.2                     |   4.463M               |   9.572G   |\n|    layer4.2.conv1              |    1.049M              |    2.249G  |\n|    layer4.2.bn1                |    1.024K              |    2.196M  |\n|    layer4.2.conv2              |    2.359M              |    5.061G  |\n|    layer4.2.bn2                |    1.024K              |    2.196M  |\n|    layer4.2.conv3              |    1.049M              |    2.249G  |\n|    layer4.2.bn3                |    4.096K              |    8.786M  |\n|  layer6.conv2d_list            |  1.401M                |  3.005G    |\n|   layer6.conv2d_list.0         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n|   layer6.conv2d_list.1         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n|   layer6.conv2d_list.2         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n|   layer6.conv2d_list.3         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n\n\nmIoU: 20.096%, Latency: 0.137, FPS: 62.711\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>▁</td></tr><tr><td>latency</td><td>▁</td></tr><tr><td>loss</td><td>█▄▂▁▁</td></tr><tr><td>mIOU</td><td>▁▅▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>62.71103</td></tr><tr><td>latency</td><td>0.13693</td></tr><tr><td>loss</td><td>0.61631</td></tr><tr><td>mIOU</td><td>0.20096</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lunar-sweep-4</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/wa0tsz5z' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/wa0tsz5z</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240519_141506-wa0tsz5z/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v24cez3b with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_150529-v24cez3b</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/v24cez3b' target=\"_blank\">autumn-sweep-5</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/v24cez3b' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/v24cez3b</a>"},"metadata":{}},{"name":"stdout","text":"Deeplab pretraining loading...\n----------------------------------\nLoss after 1 epochs: 0.982\nmIOU after 1 epochs: 0.184%\n----------------------------------\nLoss after 2 epochs: 0.542\nmIOU after 2 epochs: 0.230%\n----------------------------------\nLoss after 3 epochs: 0.472\nmIOU after 3 epochs: 0.245%\n----------------------------------\nLoss after 4 epochs: 0.433\nmIOU after 4 epochs: 0.254%\n----------------------------------\nLoss after 5 epochs: 0.408\nmIOU after 5 epochs: 0.261%\n| module                         | #parameters or shape   | #flops     |\n|:-------------------------------|:-----------------------|:-----------|\n| model                          | 43.901M                | 95.816G    |\n|  conv1                         |  9.408K                |  0.308G    |\n|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n|  bn1                           |  0.128K                |  4.194M    |\n|   bn1.weight                   |   (64,)                |            |\n|   bn1.bias                     |   (64,)                |            |\n|  layer1                        |  0.216M                |  1.81G     |\n|   layer1.0                     |   75.008K              |   0.629G   |\n|    layer1.0.conv1              |    4.096K              |    34.345M |\n|    layer1.0.bn1                |    0.128K              |    1.073M  |\n|    layer1.0.conv2              |    36.864K             |    0.309G  |\n|    layer1.0.bn2                |    0.128K              |    1.073M  |\n|    layer1.0.conv3              |    16.384K             |    0.137G  |\n|    layer1.0.bn3                |    0.512K              |    4.293M  |\n|    layer1.0.downsample         |    16.896K             |    0.142G  |\n|   layer1.1                     |   70.4K                |   0.59G    |\n|    layer1.1.conv1              |    16.384K             |    0.137G  |\n|    layer1.1.bn1                |    0.128K              |    1.073M  |\n|    layer1.1.conv2              |    36.864K             |    0.309G  |\n|    layer1.1.bn2                |    0.128K              |    1.073M  |\n|    layer1.1.conv3              |    16.384K             |    0.137G  |\n|    layer1.1.bn3                |    0.512K              |    4.293M  |\n|   layer1.2                     |   70.4K                |   0.59G    |\n|    layer1.2.conv1              |    16.384K             |    0.137G  |\n|    layer1.2.bn1                |    0.128K              |    1.073M  |\n|    layer1.2.conv2              |    36.864K             |    0.309G  |\n|    layer1.2.bn2                |    0.128K              |    1.073M  |\n|    layer1.2.conv3              |    16.384K             |    0.137G  |\n|    layer1.2.bn3                |    0.512K              |    4.293M  |\n|  layer2                        |  1.22M                 |  2.616G    |\n|   layer2.0                     |   0.379M               |   0.814G   |\n|    layer2.0.conv1              |    32.768K             |    70.287M |\n|    layer2.0.bn1                |    0.256K              |    0.549M  |\n|    layer2.0.conv2              |    0.147M              |    0.316G  |\n|    layer2.0.bn2                |    0.256K              |    0.549M  |\n|    layer2.0.conv3              |    65.536K             |    0.141G  |\n|    layer2.0.bn3                |    1.024K              |    2.196M  |\n|    layer2.0.downsample         |    0.132M              |    0.283G  |\n|   layer2.1                     |   0.28M                |   0.601G   |\n|    layer2.1.conv1              |    65.536K             |    0.141G  |\n|    layer2.1.bn1                |    0.256K              |    0.549M  |\n|    layer2.1.conv2              |    0.147M              |    0.316G  |\n|    layer2.1.bn2                |    0.256K              |    0.549M  |\n|    layer2.1.conv3              |    65.536K             |    0.141G  |\n|    layer2.1.bn3                |    1.024K              |    2.196M  |\n|   layer2.2                     |   0.28M                |   0.601G   |\n|    layer2.2.conv1              |    65.536K             |    0.141G  |\n|    layer2.2.bn1                |    0.256K              |    0.549M  |\n|    layer2.2.conv2              |    0.147M              |    0.316G  |\n|    layer2.2.bn2                |    0.256K              |    0.549M  |\n|    layer2.2.conv3              |    65.536K             |    0.141G  |\n|    layer2.2.bn3                |    1.024K              |    2.196M  |\n|   layer2.3                     |   0.28M                |   0.601G   |\n|    layer2.3.conv1              |    65.536K             |    0.141G  |\n|    layer2.3.bn1                |    0.256K              |    0.549M  |\n|    layer2.3.conv2              |    0.147M              |    0.316G  |\n|    layer2.3.bn2                |    0.256K              |    0.549M  |\n|    layer2.3.conv3              |    65.536K             |    0.141G  |\n|    layer2.3.bn3                |    1.024K              |    2.196M  |\n|  layer3                        |  26.09M                |  55.964G   |\n|   layer3.0                     |   1.512M               |   3.244G   |\n|    layer3.0.conv1              |    0.131M              |    0.281G  |\n|    layer3.0.bn1                |    0.512K              |    1.098M  |\n|    layer3.0.conv2              |    0.59M               |    1.265G  |\n|    layer3.0.bn2                |    0.512K              |    1.098M  |\n|    layer3.0.conv3              |    0.262M              |    0.562G  |\n|    layer3.0.bn3                |    2.048K              |    4.393M  |\n|    layer3.0.downsample         |    0.526M              |    1.129G  |\n|   layer3.1                     |   1.117M               |   2.396G   |\n|    layer3.1.conv1              |    0.262M              |    0.562G  |\n|    layer3.1.bn1                |    0.512K              |    1.098M  |\n|    layer3.1.conv2              |    0.59M               |    1.265G  |\n|    layer3.1.bn2                |    0.512K              |    1.098M  |\n|    layer3.1.conv3              |    0.262M              |    0.562G  |\n|    layer3.1.bn3                |    2.048K              |    4.393M  |\n|   layer3.2                     |   1.117M               |   2.396G   |\n|    layer3.2.conv1              |    0.262M              |    0.562G  |\n|    layer3.2.bn1                |    0.512K              |    1.098M  |\n|    layer3.2.conv2              |    0.59M               |    1.265G  |\n|    layer3.2.bn2                |    0.512K              |    1.098M  |\n|    layer3.2.conv3              |    0.262M              |    0.562G  |\n|    layer3.2.bn3                |    2.048K              |    4.393M  |\n|   layer3.3                     |   1.117M               |   2.396G   |\n|    layer3.3.conv1              |    0.262M              |    0.562G  |\n|    layer3.3.bn1                |    0.512K              |    1.098M  |\n|    layer3.3.conv2              |    0.59M               |    1.265G  |\n|    layer3.3.bn2                |    0.512K              |    1.098M  |\n|    layer3.3.conv3              |    0.262M              |    0.562G  |\n|    layer3.3.bn3                |    2.048K              |    4.393M  |\n|   layer3.4                     |   1.117M               |   2.396G   |\n|    layer3.4.conv1              |    0.262M              |    0.562G  |\n|    layer3.4.bn1                |    0.512K              |    1.098M  |\n|    layer3.4.conv2              |    0.59M               |    1.265G  |\n|    layer3.4.bn2                |    0.512K              |    1.098M  |\n|    layer3.4.conv3              |    0.262M              |    0.562G  |\n|    layer3.4.bn3                |    2.048K              |    4.393M  |\n|   layer3.5                     |   1.117M               |   2.396G   |\n|    layer3.5.conv1              |    0.262M              |    0.562G  |\n|    layer3.5.bn1                |    0.512K              |    1.098M  |\n|    layer3.5.conv2              |    0.59M               |    1.265G  |\n|    layer3.5.bn2                |    0.512K              |    1.098M  |\n|    layer3.5.conv3              |    0.262M              |    0.562G  |\n|    layer3.5.bn3                |    2.048K              |    4.393M  |\n|   layer3.6                     |   1.117M               |   2.396G   |\n|    layer3.6.conv1              |    0.262M              |    0.562G  |\n|    layer3.6.bn1                |    0.512K              |    1.098M  |\n|    layer3.6.conv2              |    0.59M               |    1.265G  |\n|    layer3.6.bn2                |    0.512K              |    1.098M  |\n|    layer3.6.conv3              |    0.262M              |    0.562G  |\n|    layer3.6.bn3                |    2.048K              |    4.393M  |\n|   layer3.7                     |   1.117M               |   2.396G   |\n|    layer3.7.conv1              |    0.262M              |    0.562G  |\n|    layer3.7.bn1                |    0.512K              |    1.098M  |\n|    layer3.7.conv2              |    0.59M               |    1.265G  |\n|    layer3.7.bn2                |    0.512K              |    1.098M  |\n|    layer3.7.conv3              |    0.262M              |    0.562G  |\n|    layer3.7.bn3                |    2.048K              |    4.393M  |\n|   layer3.8                     |   1.117M               |   2.396G   |\n|    layer3.8.conv1              |    0.262M              |    0.562G  |\n|    layer3.8.bn1                |    0.512K              |    1.098M  |\n|    layer3.8.conv2              |    0.59M               |    1.265G  |\n|    layer3.8.bn2                |    0.512K              |    1.098M  |\n|    layer3.8.conv3              |    0.262M              |    0.562G  |\n|    layer3.8.bn3                |    2.048K              |    4.393M  |\n|   layer3.9                     |   1.117M               |   2.396G   |\n|    layer3.9.conv1              |    0.262M              |    0.562G  |\n|    layer3.9.bn1                |    0.512K              |    1.098M  |\n|    layer3.9.conv2              |    0.59M               |    1.265G  |\n|    layer3.9.bn2                |    0.512K              |    1.098M  |\n|    layer3.9.conv3              |    0.262M              |    0.562G  |\n|    layer3.9.bn3                |    2.048K              |    4.393M  |\n|   layer3.10                    |   1.117M               |   2.396G   |\n|    layer3.10.conv1             |    0.262M              |    0.562G  |\n|    layer3.10.bn1               |    0.512K              |    1.098M  |\n|    layer3.10.conv2             |    0.59M               |    1.265G  |\n|    layer3.10.bn2               |    0.512K              |    1.098M  |\n|    layer3.10.conv3             |    0.262M              |    0.562G  |\n|    layer3.10.bn3               |    2.048K              |    4.393M  |\n|   layer3.11                    |   1.117M               |   2.396G   |\n|    layer3.11.conv1             |    0.262M              |    0.562G  |\n|    layer3.11.bn1               |    0.512K              |    1.098M  |\n|    layer3.11.conv2             |    0.59M               |    1.265G  |\n|    layer3.11.bn2               |    0.512K              |    1.098M  |\n|    layer3.11.conv3             |    0.262M              |    0.562G  |\n|    layer3.11.bn3               |    2.048K              |    4.393M  |\n|   layer3.12                    |   1.117M               |   2.396G   |\n|    layer3.12.conv1             |    0.262M              |    0.562G  |\n|    layer3.12.bn1               |    0.512K              |    1.098M  |\n|    layer3.12.conv2             |    0.59M               |    1.265G  |\n|    layer3.12.bn2               |    0.512K              |    1.098M  |\n|    layer3.12.conv3             |    0.262M              |    0.562G  |\n|    layer3.12.bn3               |    2.048K              |    4.393M  |\n|   layer3.13                    |   1.117M               |   2.396G   |\n|    layer3.13.conv1             |    0.262M              |    0.562G  |\n|    layer3.13.bn1               |    0.512K              |    1.098M  |\n|    layer3.13.conv2             |    0.59M               |    1.265G  |\n|    layer3.13.bn2               |    0.512K              |    1.098M  |\n|    layer3.13.conv3             |    0.262M              |    0.562G  |\n|    layer3.13.bn3               |    2.048K              |    4.393M  |\n|   layer3.14                    |   1.117M               |   2.396G   |\n|    layer3.14.conv1             |    0.262M              |    0.562G  |\n|    layer3.14.bn1               |    0.512K              |    1.098M  |\n|    layer3.14.conv2             |    0.59M               |    1.265G  |\n|    layer3.14.bn2               |    0.512K              |    1.098M  |\n|    layer3.14.conv3             |    0.262M              |    0.562G  |\n|    layer3.14.bn3               |    2.048K              |    4.393M  |\n|   layer3.15                    |   1.117M               |   2.396G   |\n|    layer3.15.conv1             |    0.262M              |    0.562G  |\n|    layer3.15.bn1               |    0.512K              |    1.098M  |\n|    layer3.15.conv2             |    0.59M               |    1.265G  |\n|    layer3.15.bn2               |    0.512K              |    1.098M  |\n|    layer3.15.conv3             |    0.262M              |    0.562G  |\n|    layer3.15.bn3               |    2.048K              |    4.393M  |\n|   layer3.16                    |   1.117M               |   2.396G   |\n|    layer3.16.conv1             |    0.262M              |    0.562G  |\n|    layer3.16.bn1               |    0.512K              |    1.098M  |\n|    layer3.16.conv2             |    0.59M               |    1.265G  |\n|    layer3.16.bn2               |    0.512K              |    1.098M  |\n|    layer3.16.conv3             |    0.262M              |    0.562G  |\n|    layer3.16.bn3               |    2.048K              |    4.393M  |\n|   layer3.17                    |   1.117M               |   2.396G   |\n|    layer3.17.conv1             |    0.262M              |    0.562G  |\n|    layer3.17.bn1               |    0.512K              |    1.098M  |\n|    layer3.17.conv2             |    0.59M               |    1.265G  |\n|    layer3.17.bn2               |    0.512K              |    1.098M  |\n|    layer3.17.conv3             |    0.262M              |    0.562G  |\n|    layer3.17.bn3               |    2.048K              |    4.393M  |\n|   layer3.18                    |   1.117M               |   2.396G   |\n|    layer3.18.conv1             |    0.262M              |    0.562G  |\n|    layer3.18.bn1               |    0.512K              |    1.098M  |\n|    layer3.18.conv2             |    0.59M               |    1.265G  |\n|    layer3.18.bn2               |    0.512K              |    1.098M  |\n|    layer3.18.conv3             |    0.262M              |    0.562G  |\n|    layer3.18.bn3               |    2.048K              |    4.393M  |\n|   layer3.19                    |   1.117M               |   2.396G   |\n|    layer3.19.conv1             |    0.262M              |    0.562G  |\n|    layer3.19.bn1               |    0.512K              |    1.098M  |\n|    layer3.19.conv2             |    0.59M               |    1.265G  |\n|    layer3.19.bn2               |    0.512K              |    1.098M  |\n|    layer3.19.conv3             |    0.262M              |    0.562G  |\n|    layer3.19.bn3               |    2.048K              |    4.393M  |\n|   layer3.20                    |   1.117M               |   2.396G   |\n|    layer3.20.conv1             |    0.262M              |    0.562G  |\n|    layer3.20.bn1               |    0.512K              |    1.098M  |\n|    layer3.20.conv2             |    0.59M               |    1.265G  |\n|    layer3.20.bn2               |    0.512K              |    1.098M  |\n|    layer3.20.conv3             |    0.262M              |    0.562G  |\n|    layer3.20.bn3               |    2.048K              |    4.393M  |\n|   layer3.21                    |   1.117M               |   2.396G   |\n|    layer3.21.conv1             |    0.262M              |    0.562G  |\n|    layer3.21.bn1               |    0.512K              |    1.098M  |\n|    layer3.21.conv2             |    0.59M               |    1.265G  |\n|    layer3.21.bn2               |    0.512K              |    1.098M  |\n|    layer3.21.conv3             |    0.262M              |    0.562G  |\n|    layer3.21.bn3               |    2.048K              |    4.393M  |\n|   layer3.22                    |   1.117M               |   2.396G   |\n|    layer3.22.conv1             |    0.262M              |    0.562G  |\n|    layer3.22.bn1               |    0.512K              |    1.098M  |\n|    layer3.22.conv2             |    0.59M               |    1.265G  |\n|    layer3.22.bn2               |    0.512K              |    1.098M  |\n|    layer3.22.conv3             |    0.262M              |    0.562G  |\n|    layer3.22.bn3               |    2.048K              |    4.393M  |\n|  layer4                        |  14.965M               |  32.099G   |\n|   layer4.0                     |   6.04M                |   12.955G  |\n|    layer4.0.conv1              |    0.524M              |    1.125G  |\n|    layer4.0.bn1                |    1.024K              |    2.196M  |\n|    layer4.0.conv2              |    2.359M              |    5.061G  |\n|    layer4.0.bn2                |    1.024K              |    2.196M  |\n|    layer4.0.conv3              |    1.049M              |    2.249G  |\n|    layer4.0.bn3                |    4.096K              |    8.786M  |\n|    layer4.0.downsample         |    2.101M              |    4.507G  |\n|   layer4.1                     |   4.463M               |   9.572G   |\n|    layer4.1.conv1              |    1.049M              |    2.249G  |\n|    layer4.1.bn1                |    1.024K              |    2.196M  |\n|    layer4.1.conv2              |    2.359M              |    5.061G  |\n|    layer4.1.bn2                |    1.024K              |    2.196M  |\n|    layer4.1.conv3              |    1.049M              |    2.249G  |\n|    layer4.1.bn3                |    4.096K              |    8.786M  |\n|   layer4.2                     |   4.463M               |   9.572G   |\n|    layer4.2.conv1              |    1.049M              |    2.249G  |\n|    layer4.2.bn1                |    1.024K              |    2.196M  |\n|    layer4.2.conv2              |    2.359M              |    5.061G  |\n|    layer4.2.bn2                |    1.024K              |    2.196M  |\n|    layer4.2.conv3              |    1.049M              |    2.249G  |\n|    layer4.2.bn3                |    4.096K              |    8.786M  |\n|  layer6.conv2d_list            |  1.401M                |  3.005G    |\n|   layer6.conv2d_list.0         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n|   layer6.conv2d_list.1         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n|   layer6.conv2d_list.2         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n|   layer6.conv2d_list.3         |   0.35M                |   0.751G   |\n|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n\n\nmIoU: 23.719%, Latency: 0.148, FPS: 64.528\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>▁</td></tr><tr><td>latency</td><td>▁</td></tr><tr><td>loss</td><td>█▃▂▁▁</td></tr><tr><td>mIOU</td><td>▁▆▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>64.52771</td></tr><tr><td>latency</td><td>0.14766</td></tr><tr><td>loss</td><td>0.40814</td></tr><tr><td>mIOU</td><td>0.23719</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">autumn-sweep-5</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/v24cez3b' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/v24cez3b</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240519_150529-v24cez3b/logs</code>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 8 - Build final model","metadata":{}},{"cell_type":"code","source":"# best configuration (TO CONFIGURE)\nconfig = dict(\n    epochs=50,\n    batch_size=2,\n    learning_rate=0.001,\n    momentum=0.9,\n    weight_decay=5e-4,\n    architecture=\"DeepLabV2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:52.566045Z","iopub.execute_input":"2024-05-19T21:35:52.566372Z","iopub.status.idle":"2024-05-19T21:35:52.575109Z","shell.execute_reply.started":"2024-05-19T21:35:52.566342Z","shell.execute_reply":"2024-05-19T21:35:52.574199Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(\"Building the model with the best configuration\")\n    # Build, train and analyze the model with the pipeline\n    model = model_pipeline(config)\nelse:\n    print(\"CUDA is Not available\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T21:35:52.576126Z","iopub.execute_input":"2024-05-19T21:35:52.576407Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtommasomazzarini2001\u001b[0m (\u001b[33mpolito-tmazzarini\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"name":"stdout","text":"Building the model with the best configuration\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_213552-sn89puah</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/sn89puah' target=\"_blank\">graceful-breeze-9</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/sn89puah' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/sn89puah</a>"},"metadata":{}},{"name":"stdout","text":"Deeplab pretraining loading...\n----------------------------------\nLoss after 0 epochs: 0.557\nmIOU after 0 epochs: 0.255%\n----------------------------------\nLoss after 1 epochs: 0.314\nmIOU after 1 epochs: 0.303%\n----------------------------------\nLoss after 2 epochs: 0.271\nmIOU after 2 epochs: 0.318%\n----------------------------------\nLoss after 3 epochs: 0.247\nmIOU after 3 epochs: 0.327%\n----------------------------------\nLoss after 4 epochs: 0.231\nmIOU after 4 epochs: 0.335%\n----------------------------------\nLoss after 5 epochs: 0.220\nmIOU after 5 epochs: 0.340%\n----------------------------------\nLoss after 6 epochs: 0.210\nmIOU after 6 epochs: 0.345%\n----------------------------------\nLoss after 7 epochs: 0.202\nmIOU after 7 epochs: 0.350%\n----------------------------------\nLoss after 8 epochs: 0.197\nmIOU after 8 epochs: 0.353%\n----------------------------------\nLoss after 9 epochs: 0.191\nmIOU after 9 epochs: 0.357%\n----------------------------------\nLoss after 10 epochs: 0.186\nmIOU after 10 epochs: 0.359%\n----------------------------------\nLoss after 11 epochs: 0.182\nmIOU after 11 epochs: 0.362%\n----------------------------------\nLoss after 12 epochs: 0.179\nmIOU after 12 epochs: 0.364%\n----------------------------------\nLoss after 13 epochs: 0.175\nmIOU after 13 epochs: 0.367%\n----------------------------------\nLoss after 14 epochs: 0.172\nmIOU after 14 epochs: 0.368%\n----------------------------------\nLoss after 15 epochs: 0.169\nmIOU after 15 epochs: 0.370%\n----------------------------------\nLoss after 16 epochs: 0.166\nmIOU after 16 epochs: 0.373%\n----------------------------------\nLoss after 17 epochs: 0.164\nmIOU after 17 epochs: 0.374%\n----------------------------------\nLoss after 18 epochs: 0.162\nmIOU after 18 epochs: 0.376%\n----------------------------------\nLoss after 19 epochs: 0.159\nmIOU after 19 epochs: 0.378%\n----------------------------------\nLoss after 20 epochs: 0.158\nmIOU after 20 epochs: 0.379%\n----------------------------------\nLoss after 21 epochs: 0.156\nmIOU after 21 epochs: 0.381%\n----------------------------------\nLoss after 22 epochs: 0.154\nmIOU after 22 epochs: 0.382%\n----------------------------------\nLoss after 23 epochs: 0.152\nmIOU after 23 epochs: 0.384%\n----------------------------------\nLoss after 24 epochs: 0.151\nmIOU after 24 epochs: 0.385%\n----------------------------------\nLoss after 25 epochs: 0.149\nmIOU after 25 epochs: 0.386%\n","output_type":"stream"}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-20T09:28:39.297868Z","iopub.execute_input":"2024-05-20T09:28:39.298125Z","iopub.status.idle":"2024-05-20T09:28:39.630730Z","shell.execute_reply.started":"2024-05-20T09:28:39.298102Z","shell.execute_reply":"2024-05-20T09:28:39.629598Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39mfinish()\n","\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"],"ename":"NameError","evalue":"name 'wandb' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}