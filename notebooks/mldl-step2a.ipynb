{"cells":[{"cell_type":"markdown","metadata":{"id":"OAZEiffSoALO"},"source":["# Classic semantic segmentation network\n","For this step, you have to train a classic segmentation network (**DeepLabV2** [2]) on the Cityscapes dataset.\n","- Dataset: **Cityscapes** [5]\n","- Training epochs: 50\n","- Training resolution (Cityscapes): 1024x512\n","- Test resolution (Cityscapes): 1024x512\n","- Backbone: **R101** (pre-trained on ImageNet) [2]\n","- Semantic classes: 19\n","- Metrics: Mean Intersection over Union (**mIoU**) [read this to understand the metrics], **latency**, **FLOPs**, number of **parameters**.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:42:31.085909Z","iopub.status.busy":"2024-05-25T16:42:31.085540Z","iopub.status.idle":"2024-05-25T16:42:43.389563Z","shell.execute_reply":"2024-05-25T16:42:43.388575Z","shell.execute_reply.started":"2024-05-25T16:42:31.085882Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: fvcore in /opt/conda/lib/python3.10/site-packages (0.1.5.post20221221)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore) (1.26.4)\n","Requirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.1.8)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (6.0.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fvcore) (4.66.1)\n","Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (2.4.0)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from fvcore) (9.5.0)\n","Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.9.0)\n","Requirement already satisfied: iopath>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.1.10)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore) (4.9.0)\n","Requirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore) (2.8.2)\n"]}],"source":["!pip install -U fvcore"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:42:43.391804Z","iopub.status.busy":"2024-05-25T16:42:43.391488Z","iopub.status.idle":"2024-05-25T16:42:55.615476Z","shell.execute_reply":"2024-05-25T16:42:55.614119Z","shell.execute_reply.started":"2024-05-25T16:42:43.391777Z"},"trusted":true},"outputs":[],"source":["# WANDB\n","!pip install -q wandb"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T17:18:03.118980Z","iopub.status.busy":"2024-05-25T17:18:03.118618Z","iopub.status.idle":"2024-05-25T17:18:04.147034Z","shell.execute_reply":"2024-05-25T17:18:04.145780Z","shell.execute_reply.started":"2024-05-25T17:18:03.118949Z"},"trusted":true},"outputs":[],"source":["# If you run the model for the first time remove all the previus checkpoints\n","# NON RUNNARE SE NON E' LA PRIMA VOLTAAAAAAAAAAAAAAAAAAAAAAAAA, MANDI A FANCULO TUTTO\n","! rm -r checkpoints/"]},{"cell_type":"markdown","metadata":{"id":"cNa1Un4uoZ6M"},"source":["# 0 - Import libraries"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:42:55.617999Z","iopub.status.busy":"2024-05-25T16:42:55.617607Z","iopub.status.idle":"2024-05-25T16:42:55.624762Z","shell.execute_reply":"2024-05-25T16:42:55.623807Z","shell.execute_reply.started":"2024-05-25T16:42:55.617968Z"},"executionInfo":{"elapsed":13275,"status":"ok","timestamp":1715695760300,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"},"user_tz":-120},"id":"mYTc9GfSouYh","trusted":true},"outputs":[],"source":["import wandb\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","import torch.optim as optim\n","\n","import os\n","import zipfile\n","import numpy as np\n","import time\n","from PIL import Image\n","\n","from fvcore.nn import FlopCountAnalysis, flop_count_table\n","\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"markdown","metadata":{},"source":["# 1 - Start WanDB"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:42:55.628410Z","iopub.status.busy":"2024-05-25T16:42:55.627875Z","iopub.status.idle":"2024-05-25T16:43:08.946508Z","shell.execute_reply":"2024-05-25T16:43:08.945612Z","shell.execute_reply.started":"2024-05-25T16:42:55.628377Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  \n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"markdown","metadata":{},"source":["# 2 - Model Pipeline"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:43:08.947789Z","iopub.status.busy":"2024-05-25T16:43:08.947504Z","iopub.status.idle":"2024-05-25T16:43:08.953788Z","shell.execute_reply":"2024-05-25T16:43:08.952704Z","shell.execute_reply.started":"2024-05-25T16:43:08.947765Z"},"trusted":true},"outputs":[],"source":["def model_pipeline(hyperparameters=None):\n","\n","    # tell wandb to get started\n","    with wandb.init(project=\"MLDL-step2a\", config=hyperparameters):\n","        # access all HPs through wandb.config, so logging matches execution!\n","        config = wandb.config\n","\n","        # make the model, data, and optimization problem\n","        model, train_loader, val_loader, criterion, optimizer, start_epoch = make(config)\n","        \n","        # and use them to train the model\n","        train(model, train_loader, criterion, optimizer, config, start_epoch)\n","\n","        # and test its final performance\n","        val(model, val_loader)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"sKK0P3Aloi9U"},"source":["# 3 - CityScapes"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:43:08.955061Z","iopub.status.busy":"2024-05-25T16:43:08.954793Z","iopub.status.idle":"2024-05-25T16:43:08.964403Z","shell.execute_reply":"2024-05-25T16:43:08.963708Z","shell.execute_reply.started":"2024-05-25T16:43:08.955038Z"},"trusted":true},"outputs":[],"source":["def make(config):\n","    # Load the data\n","    train, test = get_data(train=True), get_data(train=False)\n","    train_loader = make_loader(train, batch_size=config.batch_size,train=True)\n","    test_loader = make_loader(test, batch_size=config.batch_size,train=False)\n","    \n","    # Create the model (get_model)\n","    pretrain_model_path = '/kaggle/input/deeplab_v2_model/pytorch/model_weight/1/deeplab_resnet_pretrained_imagenet.pth'\n","    model = get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path=pretrain_model_path).cuda()\n","    \n","    # Make the loss and optimizer\n","    optimizer = optim.SGD(model.parameters(), \n","                          lr=config.learning_rate, \n","                          momentum=config.momentum, \n","                          weight_decay=config.weight_decay)\n","    \n","    criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n","    \n","    # Load the last checkpoint\n","    start_epoch = load_checkpoint(config, model, optimizer)\n","    \n","    return model, train_loader, test_loader, criterion, optimizer, start_epoch"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:43:08.965745Z","iopub.status.busy":"2024-05-25T16:43:08.965449Z","iopub.status.idle":"2024-05-25T16:43:08.977549Z","shell.execute_reply":"2024-05-25T16:43:08.976724Z","shell.execute_reply.started":"2024-05-25T16:43:08.965718Z"},"trusted":true},"outputs":[],"source":["# Define transforms for preprocessing\n","image_transform = transforms.Compose([\n","        transforms.Resize((512,1024)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","label_transform = transforms.Compose([\n","        transforms.Resize((512,1024)),\n","    ])\n","\n","root_dir ='/kaggle/input/cityscapes/Cityscapes/Cityspaces'\n","\n","def get_data(train=True):\n","    if train == True:\n","        # train dataset\n","        dataset = CityScapes(root_dir=root_dir, split='train', image_transform=image_transform, label_transform=label_transform)\n","    else:\n","        # test dataset\n","        dataset = CityScapes(root_dir=root_dir, split='val', image_transform=image_transform, label_transform=label_transform)\n","    \n","    return dataset\n","\n","\n","def make_loader(dataset, batch_size=8, train=True):\n","    if train == True:\n","        # train dataloader\n","        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n","    else:\n","        # test dataloader\n","        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False,drop_last=True)\n","    \n","    return dataloader"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:43:08.979018Z","iopub.status.busy":"2024-05-25T16:43:08.978700Z","iopub.status.idle":"2024-05-25T16:43:08.990071Z","shell.execute_reply":"2024-05-25T16:43:08.989228Z","shell.execute_reply.started":"2024-05-25T16:43:08.978987Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715695833931,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"},"user_tz":-120},"id":"TE5jHHpwaduG","trusted":true},"outputs":[],"source":["class CityScapes(Dataset):\n","    def __init__(self, root_dir, split='train', image_transform=None, label_transform=None):\n","        super(CityScapes, self).__init__()\n","        \"\"\"\n","        Args:\n","            root_dir (string): Directory with all the images and annotations.\n","            split (string): 'train' or 'val'.\n","            transform (callable, optional): Optional transform to be applied on a sample.\n","        \"\"\"\n","\n","        self.root_dir = root_dir\n","        self.split = split\n","        self.image_transform = image_transform\n","        self.label_transform = label_transform\n","\n","        # Get the image and label directories\n","        self.image_dir = os.path.join(root_dir, 'images', split)\n","        self.label_dir = os.path.join(root_dir, 'gtFine', split)\n","\n","        # Get a list of all image files\n","        self.image_files = []\n","        for city_dir in os.listdir(self.image_dir):\n","            city_image_dir = os.path.join(self.image_dir, city_dir)\n","            self.image_files.extend([os.path.join(city_image_dir, f) for f in os.listdir(city_image_dir) if f.endswith('.png')])\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.image_files[idx]\n","\n","        # Get the corresponding label image path\n","        label_name = img_name.replace('images', 'gtFine').replace('_leftImg8bit', '_gtFine_labelTrainIds')\n","\n","        # Load image and label\n","        image = Image.open(img_name).convert('RGB')\n","        label = Image.open(label_name).convert('L')\n","\n","        if self.image_transform:\n","            image = self.image_transform(image)\n","        if self.label_transform:\n","            label = self.label_transform(label)\n","\n","        label = torch.Tensor(np.array(label))\n","\n","        return image, label"]},{"cell_type":"markdown","metadata":{"id":"breeFfksou_h"},"source":["# 4 - DeepLabV2"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-25T16:43:08.991890Z","iopub.status.busy":"2024-05-25T16:43:08.991589Z","iopub.status.idle":"2024-05-25T16:43:09.028782Z","shell.execute_reply":"2024-05-25T16:43:09.027808Z","shell.execute_reply.started":"2024-05-25T16:43:08.991869Z"},"executionInfo":{"elapsed":12513,"status":"ok","timestamp":1715695905826,"user":{"displayName":"Tommaso Mazzarini","userId":"16046308562458308219"},"user_tz":-120},"id":"sOluxCUSo6TN","outputId":"18e9c583-19cc-4b94-f206-b30ba08384cb","trusted":true},"outputs":[],"source":["affine_par = True\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par)\n","        for i in self.bn1.parameters():\n","            i.requires_grad = False\n","        padding = dilation\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n","                               padding=padding, bias=False, dilation=dilation)\n","        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n","        for i in self.bn2.parameters():\n","            i.requires_grad = False\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n","        for i in self.bn3.parameters():\n","            i.requires_grad = False\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ClassifierModule(nn.Module):\n","    def __init__(self, inplanes, dilation_series, padding_series, num_classes):\n","        super(ClassifierModule, self).__init__()\n","        self.conv2d_list = nn.ModuleList()\n","        for dilation, padding in zip(dilation_series, padding_series):\n","            self.conv2d_list.append(\n","                nn.Conv2d(inplanes, num_classes, kernel_size=3, stride=1, padding=padding,\n","                          dilation=dilation, bias=True))\n","\n","        for m in self.conv2d_list:\n","            m.weight.data.normal_(0, 0.01)\n","\n","    def forward(self, x):\n","        out = self.conv2d_list[0](x)\n","        for i in range(len(self.conv2d_list) - 1):\n","            out += self.conv2d_list[i + 1](x)\n","        return out\n","\n","\n","class ResNetMulti(nn.Module):\n","    def __init__(self, block, layers, num_classes):\n","        self.inplanes = 64\n","        super(ResNetMulti, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n","        for i in self.bn1.parameters():\n","            i.requires_grad = False\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n","        self.layer6 = ClassifierModule(2048, [6, 12, 18, 24], [6, 12, 18, 24], num_classes)\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                m.weight.data.normal_(0, 0.01)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n","        downsample = None\n","        if (stride != 1\n","                or self.inplanes != planes * block.expansion\n","                or dilation == 2\n","                or dilation == 4):\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion, affine=affine_par))\n","        for i in downsample._modules['1'].parameters():\n","            i.requires_grad = False\n","        layers = []\n","        layers.append(\n","            block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, dilation=dilation))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        _, _, H, W = x.size()\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer6(x)\n","\n","        x = torch.nn.functional.interpolate(x, size=(H, W), mode='bilinear')\n","\n","        if self.training == True:\n","            return x, None, None\n","\n","        return x\n","\n","    def get_1x_lr_params_no_scale(self):\n","        \"\"\"\n","        This generator returns all the parameters of the net except for\n","        the last classification layer. Note that for each batchnorm layer,\n","        requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n","        any batchnorm parameter\n","        \"\"\"\n","        b = []\n","\n","        b.append(self.conv1)\n","        b.append(self.bn1)\n","        b.append(self.layer1)\n","        b.append(self.layer2)\n","        b.append(self.layer3)\n","        b.append(self.layer4)\n","\n","        for i in range(len(b)):\n","            for j in b[i].modules():\n","                jj = 0\n","                for k in j.parameters():\n","                    jj += 1\n","                    if k.requires_grad:\n","                        yield k\n","\n","    def get_10x_lr_params(self):\n","        \"\"\"\n","        This generator returns all the parameters for the last layer of the net,\n","        which does the classification of pixel into classes\n","        \"\"\"\n","        b = []\n","        if self.multi_level:\n","            b.append(self.layer5.parameters())\n","        b.append(self.layer6.parameters())\n","\n","        for j in range(len(b)):\n","            for i in b[j]:\n","                yield i\n","\n","    def optim_parameters(self, lr):\n","        return [{'params': self.get_1x_lr_params_no_scale(), 'lr': lr},\n","                {'params': self.get_10x_lr_params(), 'lr': 10 * lr}]\n","\n","\n","def get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='DeepLab_resnet_pretrained_imagenet.pth'):\n","    model = ResNetMulti(Bottleneck, [3, 4, 23, 3], num_classes)\n","\n","    # Pretraining loading\n","    if pretrain:\n","        print('Deeplab pretraining loading...')\n","        saved_state_dict = torch.load(pretrain_model_path)\n","\n","        new_params = model.state_dict().copy()\n","        for i in saved_state_dict:\n","            i_parts = i.split('.')\n","            new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n","        model.load_state_dict(new_params, strict=False)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["# 5 - Training"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:56:00.499894Z","iopub.status.busy":"2024-05-25T16:56:00.499476Z","iopub.status.idle":"2024-05-25T16:56:00.509275Z","shell.execute_reply":"2024-05-25T16:56:00.508258Z","shell.execute_reply.started":"2024-05-25T16:56:00.499860Z"},"trusted":true},"outputs":[],"source":["def train(model, dataloader, criterion, optimizer, config, start_epoch):\n","    \n","    for epoch in range(start_epoch, config.epochs):\n","        running_loss = 0.0\n","        total_mIOU = 0\n","        total_images = 0\n","        \n","        for _, (inputs, targets) in enumerate(dataloader):\n","\n","            inputs, targets = inputs.cuda(), id_processing(targets).cuda()\n","        \n","            outputs = model(inputs)\n","\n","            loss = criterion(outputs[0], targets)\n","\n","            # Backprpagation\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            _, predicted = outputs[0].max(1)\n","\n","            running_mIOU = mean_iou(outputs[0].size()[1], predicted, targets)\n","            total_mIOU += running_mIOU.sum().item()\n","            total_images += len(predicted)\n","\n","            poly_lr_scheduler(optimizer, config.learning_rate, iter=epoch, max_iter=config.epochs)\n","                \n","        train_loss = running_loss / len(dataloader)\n","        mIOU = total_mIOU/total_images\n","        \n","        # Save the train metrics by using wandb\n","        train_log(train_loss, mIOU, epoch)\n","        \n","        # Save checkpoint (overwrite)\n","        save_checkpoint(config, model, optimizer, train_loss, mIOU, epoch)\n","        "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:43:09.042561Z","iopub.status.busy":"2024-05-25T16:43:09.042302Z","iopub.status.idle":"2024-05-25T16:43:09.049589Z","shell.execute_reply":"2024-05-25T16:43:09.048733Z","shell.execute_reply.started":"2024-05-25T16:43:09.042539Z"},"trusted":true},"outputs":[],"source":["def id_processing(targets):\n","    targets = targets.cuda()\n","    \n","    # Define valid indices\n","    valid_indices = torch.tensor(list(range(19)) + [255]).to(targets.device)\n","\n","    # Replace all IDs not in valid_indices with 255\n","    processed_targets = torch.where(torch.isin(targets, valid_indices), targets, torch.tensor(255, device=targets.device))\n","\n","    return processed_targets.long()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:43:09.051006Z","iopub.status.busy":"2024-05-25T16:43:09.050738Z","iopub.status.idle":"2024-05-25T16:43:09.061267Z","shell.execute_reply":"2024-05-25T16:43:09.060530Z","shell.execute_reply.started":"2024-05-25T16:43:09.050985Z"},"trusted":true},"outputs":[],"source":["def poly_lr_scheduler(optimizer, init_lr, iter, lr_decay_iter=1,\n","                      max_iter=300, power=0.9):\n","    \"\"\"Polynomial decay of learning rate\n","            :param init_lr is base learning rate\n","            :param iter is a current iteration\n","            :param lr_decay_iter how frequently decay occurs, default is 1\n","            :param max_iter is number of maximum iterations\n","            :param power is a polymomial power\n","\n","    \"\"\"\n","    # if iter % lr_decay_iter or iter > max_iter:\n","    # \treturn optimizer\n","\n","    lr = init_lr*(1 - iter/max_iter)**power\n","    optimizer.param_groups[0]['lr'] = lr\n","    return lr\n","    # return lr\n","    \n","def mean_iou(num_classes, pred, target):\n","    mIOU = 0\n","    for i in range(len(pred)):\n","        hist = fast_hist(target[i].cpu().numpy(),pred[i].cpu().numpy(), num_classes)\n","        IOU = per_class_iou(hist)\n","        mIOU = mIOU + sum(IOU)/num_classes\n","    return mIOU\n","\n","def fast_hist(a, b, n):\n","    \"\"\"\n","    a and b are predict and mask respectively\n","    n is the number of classes\n","    \"\"\"\n","    k = (a >= 0) & (a < n) #assign True if the value is in the range between 0 and 18 (class labels)\n","    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape((n, n))\n","\n","def per_class_iou(hist):\n","    epsilon = 1e-5\n","    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:43:09.062715Z","iopub.status.busy":"2024-05-25T16:43:09.062376Z","iopub.status.idle":"2024-05-25T16:43:09.070534Z","shell.execute_reply":"2024-05-25T16:43:09.069727Z","shell.execute_reply.started":"2024-05-25T16:43:09.062663Z"},"trusted":true},"outputs":[],"source":["def train_log(loss, mIOU, epoch):\n","    #wandb.log({\"epoch\": epoch, \"loss\": loss, \"mIOU\":mIOU})\n","    wandb.log({\"loss\": loss, \"mIOU\":mIOU}, step= epoch)\n","    print(f\"----------------------------------\")\n","    print(f\"Loss after {epoch} epochs: {loss:.3f}\")\n","    print(f\"mIOU after {epoch} epochs: {mIOU:.3f}%\")"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T17:09:12.833809Z","iopub.status.busy":"2024-05-25T17:09:12.833377Z","iopub.status.idle":"2024-05-25T17:09:12.841842Z","shell.execute_reply":"2024-05-25T17:09:12.840933Z","shell.execute_reply.started":"2024-05-25T17:09:12.833777Z"},"trusted":true},"outputs":[],"source":["def save_checkpoint(config, model, optimizer, train_loss, mIOU, epoch):\n","    checkpoint_path = os.path.join(config.checkpoint_dir, \"checkpoint.pth\")\n","    torch.save({\n","        'epoch': epoch + 1,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': train_loss,\n","        'mIOU': mIOU\n","    }, checkpoint_path)\n","    print(f\"Checkpoint saved in {checkpoint_path} | Epoch: {epoch}\")\n","    \n","    \n","def load_checkpoint(config, model, optimizer):\n","    if os.path.exists(config.checkpoint_dir):\n","        checkpoint = torch.load(config.checkpoint_dir + \"/checkpoint.pth\")\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        start_epoch = checkpoint['epoch']\n","        print(f\"Checkpoint found. Resuming from epoch {start_epoch}.\")\n","        return start_epoch\n","    else:\n","        os.mkdir(config.checkpoint_dir) # divide the directory wrt the model (eg. checkpoints/DeepLabV2, checkpoints/BiSeNet)\n","        print(\"No checkpoint found. Starting from scratch.\")\n","        return 0"]},{"cell_type":"markdown","metadata":{"id":"vcIkDP8ho8wt"},"source":["# 6 - Validation"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:43:09.081268Z","iopub.status.busy":"2024-05-25T16:43:09.081000Z","iopub.status.idle":"2024-05-25T16:43:09.092164Z","shell.execute_reply":"2024-05-25T16:43:09.091434Z","shell.execute_reply.started":"2024-05-25T16:43:09.081246Z"},"trusted":true},"outputs":[],"source":["# Validation method\n","def val(model, dataloader):\n","    model.eval()\n","    total_mIOU = 0\n","    total_images = 0\n","    latency_list = []\n","    FPS_list = []\n","    \n","    with torch.no_grad():\n","        for _, (inputs, targets) in enumerate(dataloader):\n","            inputs, targets = inputs.cuda(), id_processing(targets).cuda()\n","            \n","            start = time.time() # Record start time\n","            outputs = model(inputs)\n","            end = time.time() # Record end time\n","\n","            # Calculate latency for this iteration\n","            latency_i = end - start\n","            latency_list.append(latency_i)\n","\n","            # Calculate FPS for this iteration\n","            FPS_i = 1 / latency_i\n","            FPS_list.append(FPS_i)\n","\n","            _, predicted = outputs.max(1)\n","            \n","            running_mIOU = mean_iou(outputs.size()[1], predicted, targets)\n","            total_mIOU += running_mIOU.sum().item()\n","            total_images += len(predicted)\n","        \n","    mIOU = total_mIOU/total_images\n","    latency = np.sum(latency_list) / len(latency_list)\n","    test_FPS = np.sum(FPS_list) / len(FPS_list)\n","    \n","    # compute flops and #param\n","    image, _ = next(iter(dataloader))\n","    height, width = image.shape[2], image.shape[3]\n","    zero_image = torch.zeros((1, 3, height, width))\n","    flops = FlopCountAnalysis(model, zero_image.cuda())\n","    print(flop_count_table(flops))\n","\n","    print(f'\\n\\nmIoU: {(mIOU*100):.3f}%, Latency: {latency:.3f}, FPS: {test_FPS:.3f}')\n","\n","    wandb.log({\"mIOU\":mIOU,\"latency\":latency,\"FPS\":test_FPS})"]},{"cell_type":"markdown","metadata":{},"source":["# 7 - Hyperparameter Sweeps using WanDB"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T11:41:32.901092Z","iopub.status.busy":"2024-05-19T11:41:32.900800Z","iopub.status.idle":"2024-05-19T11:41:32.910872Z","shell.execute_reply":"2024-05-19T11:41:32.909912Z","shell.execute_reply.started":"2024-05-19T11:41:32.901067Z"},"trusted":true},"outputs":[],"source":["sweep_config= {\n","    'name': 'DeepLabV2-sweep',\n","    'metric': {'name': 'loss', 'goal': 'minimize'}, # the goal is maximize the accuracy\n","    'method': 'random', # test all possible combinations of the hyperparameters\n","    'parameters': {\n","        'epochs': {'values': [5]},        \n","        'learning_rate': {'values': [0.1, 0.001, 0.0001]}, # 2 parameters to optimize during the sweep\n","        'batch_size': {'values': [2, 4, 8]},\n","        'momentum': {'values': [0.9]},\n","        'weight_decay': {'values': [5e-4]}\n","    }\n","}"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T11:41:32.912253Z","iopub.status.busy":"2024-05-19T11:41:32.911905Z","iopub.status.idle":"2024-05-19T11:41:33.263352Z","shell.execute_reply":"2024-05-19T11:41:33.262536Z","shell.execute_reply.started":"2024-05-19T11:41:32.912228Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Create sweep with ID: 0bsj16g0\n","Sweep URL: https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0\n"]}],"source":["sweep_id = wandb.sweep(sweep=sweep_config, project=\"MLDL-step2a\")"]},{"cell_type":"code","execution_count":23,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-19T11:41:33.264731Z","iopub.status.busy":"2024-05-19T11:41:33.264429Z","iopub.status.idle":"2024-05-19T15:52:16.393627Z","shell.execute_reply":"2024-05-19T15:52:16.392669Z","shell.execute_reply.started":"2024-05-19T11:41:33.264708Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Start hyperparameter sweeps\n","\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ebq7xakp with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtommasomazzarini2001\u001b[0m (\u001b[33mpolito-tmazzarini\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_114135-ebq7xakp</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/ebq7xakp' target=\"_blank\">decent-sweep-1</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/ebq7xakp' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/ebq7xakp</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Deeplab pretraining loading...\n","----------------------------------\n","Loss after 1 epochs: 4.019\n","mIOU after 1 epochs: 0.057%\n","----------------------------------\n","Loss after 2 epochs: 1.624\n","mIOU after 2 epochs: 0.073%\n","----------------------------------\n","Loss after 3 epochs: 1.351\n","mIOU after 3 epochs: 0.093%\n","----------------------------------\n","Loss after 4 epochs: 1.222\n","mIOU after 4 epochs: 0.103%\n","----------------------------------\n","Loss after 5 epochs: 1.140\n","mIOU after 5 epochs: 0.113%\n","| module                         | #parameters or shape   | #flops     |\n","|:-------------------------------|:-----------------------|:-----------|\n","| model                          | 43.901M                | 95.816G    |\n","|  conv1                         |  9.408K                |  0.308G    |\n","|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n","|  bn1                           |  0.128K                |  4.194M    |\n","|   bn1.weight                   |   (64,)                |            |\n","|   bn1.bias                     |   (64,)                |            |\n","|  layer1                        |  0.216M                |  1.81G     |\n","|   layer1.0                     |   75.008K              |   0.629G   |\n","|    layer1.0.conv1              |    4.096K              |    34.345M |\n","|    layer1.0.bn1                |    0.128K              |    1.073M  |\n","|    layer1.0.conv2              |    36.864K             |    0.309G  |\n","|    layer1.0.bn2                |    0.128K              |    1.073M  |\n","|    layer1.0.conv3              |    16.384K             |    0.137G  |\n","|    layer1.0.bn3                |    0.512K              |    4.293M  |\n","|    layer1.0.downsample         |    16.896K             |    0.142G  |\n","|   layer1.1                     |   70.4K                |   0.59G    |\n","|    layer1.1.conv1              |    16.384K             |    0.137G  |\n","|    layer1.1.bn1                |    0.128K              |    1.073M  |\n","|    layer1.1.conv2              |    36.864K             |    0.309G  |\n","|    layer1.1.bn2                |    0.128K              |    1.073M  |\n","|    layer1.1.conv3              |    16.384K             |    0.137G  |\n","|    layer1.1.bn3                |    0.512K              |    4.293M  |\n","|   layer1.2                     |   70.4K                |   0.59G    |\n","|    layer1.2.conv1              |    16.384K             |    0.137G  |\n","|    layer1.2.bn1                |    0.128K              |    1.073M  |\n","|    layer1.2.conv2              |    36.864K             |    0.309G  |\n","|    layer1.2.bn2                |    0.128K              |    1.073M  |\n","|    layer1.2.conv3              |    16.384K             |    0.137G  |\n","|    layer1.2.bn3                |    0.512K              |    4.293M  |\n","|  layer2                        |  1.22M                 |  2.616G    |\n","|   layer2.0                     |   0.379M               |   0.814G   |\n","|    layer2.0.conv1              |    32.768K             |    70.287M |\n","|    layer2.0.bn1                |    0.256K              |    0.549M  |\n","|    layer2.0.conv2              |    0.147M              |    0.316G  |\n","|    layer2.0.bn2                |    0.256K              |    0.549M  |\n","|    layer2.0.conv3              |    65.536K             |    0.141G  |\n","|    layer2.0.bn3                |    1.024K              |    2.196M  |\n","|    layer2.0.downsample         |    0.132M              |    0.283G  |\n","|   layer2.1                     |   0.28M                |   0.601G   |\n","|    layer2.1.conv1              |    65.536K             |    0.141G  |\n","|    layer2.1.bn1                |    0.256K              |    0.549M  |\n","|    layer2.1.conv2              |    0.147M              |    0.316G  |\n","|    layer2.1.bn2                |    0.256K              |    0.549M  |\n","|    layer2.1.conv3              |    65.536K             |    0.141G  |\n","|    layer2.1.bn3                |    1.024K              |    2.196M  |\n","|   layer2.2                     |   0.28M                |   0.601G   |\n","|    layer2.2.conv1              |    65.536K             |    0.141G  |\n","|    layer2.2.bn1                |    0.256K              |    0.549M  |\n","|    layer2.2.conv2              |    0.147M              |    0.316G  |\n","|    layer2.2.bn2                |    0.256K              |    0.549M  |\n","|    layer2.2.conv3              |    65.536K             |    0.141G  |\n","|    layer2.2.bn3                |    1.024K              |    2.196M  |\n","|   layer2.3                     |   0.28M                |   0.601G   |\n","|    layer2.3.conv1              |    65.536K             |    0.141G  |\n","|    layer2.3.bn1                |    0.256K              |    0.549M  |\n","|    layer2.3.conv2              |    0.147M              |    0.316G  |\n","|    layer2.3.bn2                |    0.256K              |    0.549M  |\n","|    layer2.3.conv3              |    65.536K             |    0.141G  |\n","|    layer2.3.bn3                |    1.024K              |    2.196M  |\n","|  layer3                        |  26.09M                |  55.964G   |\n","|   layer3.0                     |   1.512M               |   3.244G   |\n","|    layer3.0.conv1              |    0.131M              |    0.281G  |\n","|    layer3.0.bn1                |    0.512K              |    1.098M  |\n","|    layer3.0.conv2              |    0.59M               |    1.265G  |\n","|    layer3.0.bn2                |    0.512K              |    1.098M  |\n","|    layer3.0.conv3              |    0.262M              |    0.562G  |\n","|    layer3.0.bn3                |    2.048K              |    4.393M  |\n","|    layer3.0.downsample         |    0.526M              |    1.129G  |\n","|   layer3.1                     |   1.117M               |   2.396G   |\n","|    layer3.1.conv1              |    0.262M              |    0.562G  |\n","|    layer3.1.bn1                |    0.512K              |    1.098M  |\n","|    layer3.1.conv2              |    0.59M               |    1.265G  |\n","|    layer3.1.bn2                |    0.512K              |    1.098M  |\n","|    layer3.1.conv3              |    0.262M              |    0.562G  |\n","|    layer3.1.bn3                |    2.048K              |    4.393M  |\n","|   layer3.2                     |   1.117M               |   2.396G   |\n","|    layer3.2.conv1              |    0.262M              |    0.562G  |\n","|    layer3.2.bn1                |    0.512K              |    1.098M  |\n","|    layer3.2.conv2              |    0.59M               |    1.265G  |\n","|    layer3.2.bn2                |    0.512K              |    1.098M  |\n","|    layer3.2.conv3              |    0.262M              |    0.562G  |\n","|    layer3.2.bn3                |    2.048K              |    4.393M  |\n","|   layer3.3                     |   1.117M               |   2.396G   |\n","|    layer3.3.conv1              |    0.262M              |    0.562G  |\n","|    layer3.3.bn1                |    0.512K              |    1.098M  |\n","|    layer3.3.conv2              |    0.59M               |    1.265G  |\n","|    layer3.3.bn2                |    0.512K              |    1.098M  |\n","|    layer3.3.conv3              |    0.262M              |    0.562G  |\n","|    layer3.3.bn3                |    2.048K              |    4.393M  |\n","|   layer3.4                     |   1.117M               |   2.396G   |\n","|    layer3.4.conv1              |    0.262M              |    0.562G  |\n","|    layer3.4.bn1                |    0.512K              |    1.098M  |\n","|    layer3.4.conv2              |    0.59M               |    1.265G  |\n","|    layer3.4.bn2                |    0.512K              |    1.098M  |\n","|    layer3.4.conv3              |    0.262M              |    0.562G  |\n","|    layer3.4.bn3                |    2.048K              |    4.393M  |\n","|   layer3.5                     |   1.117M               |   2.396G   |\n","|    layer3.5.conv1              |    0.262M              |    0.562G  |\n","|    layer3.5.bn1                |    0.512K              |    1.098M  |\n","|    layer3.5.conv2              |    0.59M               |    1.265G  |\n","|    layer3.5.bn2                |    0.512K              |    1.098M  |\n","|    layer3.5.conv3              |    0.262M              |    0.562G  |\n","|    layer3.5.bn3                |    2.048K              |    4.393M  |\n","|   layer3.6                     |   1.117M               |   2.396G   |\n","|    layer3.6.conv1              |    0.262M              |    0.562G  |\n","|    layer3.6.bn1                |    0.512K              |    1.098M  |\n","|    layer3.6.conv2              |    0.59M               |    1.265G  |\n","|    layer3.6.bn2                |    0.512K              |    1.098M  |\n","|    layer3.6.conv3              |    0.262M              |    0.562G  |\n","|    layer3.6.bn3                |    2.048K              |    4.393M  |\n","|   layer3.7                     |   1.117M               |   2.396G   |\n","|    layer3.7.conv1              |    0.262M              |    0.562G  |\n","|    layer3.7.bn1                |    0.512K              |    1.098M  |\n","|    layer3.7.conv2              |    0.59M               |    1.265G  |\n","|    layer3.7.bn2                |    0.512K              |    1.098M  |\n","|    layer3.7.conv3              |    0.262M              |    0.562G  |\n","|    layer3.7.bn3                |    2.048K              |    4.393M  |\n","|   layer3.8                     |   1.117M               |   2.396G   |\n","|    layer3.8.conv1              |    0.262M              |    0.562G  |\n","|    layer3.8.bn1                |    0.512K              |    1.098M  |\n","|    layer3.8.conv2              |    0.59M               |    1.265G  |\n","|    layer3.8.bn2                |    0.512K              |    1.098M  |\n","|    layer3.8.conv3              |    0.262M              |    0.562G  |\n","|    layer3.8.bn3                |    2.048K              |    4.393M  |\n","|   layer3.9                     |   1.117M               |   2.396G   |\n","|    layer3.9.conv1              |    0.262M              |    0.562G  |\n","|    layer3.9.bn1                |    0.512K              |    1.098M  |\n","|    layer3.9.conv2              |    0.59M               |    1.265G  |\n","|    layer3.9.bn2                |    0.512K              |    1.098M  |\n","|    layer3.9.conv3              |    0.262M              |    0.562G  |\n","|    layer3.9.bn3                |    2.048K              |    4.393M  |\n","|   layer3.10                    |   1.117M               |   2.396G   |\n","|    layer3.10.conv1             |    0.262M              |    0.562G  |\n","|    layer3.10.bn1               |    0.512K              |    1.098M  |\n","|    layer3.10.conv2             |    0.59M               |    1.265G  |\n","|    layer3.10.bn2               |    0.512K              |    1.098M  |\n","|    layer3.10.conv3             |    0.262M              |    0.562G  |\n","|    layer3.10.bn3               |    2.048K              |    4.393M  |\n","|   layer3.11                    |   1.117M               |   2.396G   |\n","|    layer3.11.conv1             |    0.262M              |    0.562G  |\n","|    layer3.11.bn1               |    0.512K              |    1.098M  |\n","|    layer3.11.conv2             |    0.59M               |    1.265G  |\n","|    layer3.11.bn2               |    0.512K              |    1.098M  |\n","|    layer3.11.conv3             |    0.262M              |    0.562G  |\n","|    layer3.11.bn3               |    2.048K              |    4.393M  |\n","|   layer3.12                    |   1.117M               |   2.396G   |\n","|    layer3.12.conv1             |    0.262M              |    0.562G  |\n","|    layer3.12.bn1               |    0.512K              |    1.098M  |\n","|    layer3.12.conv2             |    0.59M               |    1.265G  |\n","|    layer3.12.bn2               |    0.512K              |    1.098M  |\n","|    layer3.12.conv3             |    0.262M              |    0.562G  |\n","|    layer3.12.bn3               |    2.048K              |    4.393M  |\n","|   layer3.13                    |   1.117M               |   2.396G   |\n","|    layer3.13.conv1             |    0.262M              |    0.562G  |\n","|    layer3.13.bn1               |    0.512K              |    1.098M  |\n","|    layer3.13.conv2             |    0.59M               |    1.265G  |\n","|    layer3.13.bn2               |    0.512K              |    1.098M  |\n","|    layer3.13.conv3             |    0.262M              |    0.562G  |\n","|    layer3.13.bn3               |    2.048K              |    4.393M  |\n","|   layer3.14                    |   1.117M               |   2.396G   |\n","|    layer3.14.conv1             |    0.262M              |    0.562G  |\n","|    layer3.14.bn1               |    0.512K              |    1.098M  |\n","|    layer3.14.conv2             |    0.59M               |    1.265G  |\n","|    layer3.14.bn2               |    0.512K              |    1.098M  |\n","|    layer3.14.conv3             |    0.262M              |    0.562G  |\n","|    layer3.14.bn3               |    2.048K              |    4.393M  |\n","|   layer3.15                    |   1.117M               |   2.396G   |\n","|    layer3.15.conv1             |    0.262M              |    0.562G  |\n","|    layer3.15.bn1               |    0.512K              |    1.098M  |\n","|    layer3.15.conv2             |    0.59M               |    1.265G  |\n","|    layer3.15.bn2               |    0.512K              |    1.098M  |\n","|    layer3.15.conv3             |    0.262M              |    0.562G  |\n","|    layer3.15.bn3               |    2.048K              |    4.393M  |\n","|   layer3.16                    |   1.117M               |   2.396G   |\n","|    layer3.16.conv1             |    0.262M              |    0.562G  |\n","|    layer3.16.bn1               |    0.512K              |    1.098M  |\n","|    layer3.16.conv2             |    0.59M               |    1.265G  |\n","|    layer3.16.bn2               |    0.512K              |    1.098M  |\n","|    layer3.16.conv3             |    0.262M              |    0.562G  |\n","|    layer3.16.bn3               |    2.048K              |    4.393M  |\n","|   layer3.17                    |   1.117M               |   2.396G   |\n","|    layer3.17.conv1             |    0.262M              |    0.562G  |\n","|    layer3.17.bn1               |    0.512K              |    1.098M  |\n","|    layer3.17.conv2             |    0.59M               |    1.265G  |\n","|    layer3.17.bn2               |    0.512K              |    1.098M  |\n","|    layer3.17.conv3             |    0.262M              |    0.562G  |\n","|    layer3.17.bn3               |    2.048K              |    4.393M  |\n","|   layer3.18                    |   1.117M               |   2.396G   |\n","|    layer3.18.conv1             |    0.262M              |    0.562G  |\n","|    layer3.18.bn1               |    0.512K              |    1.098M  |\n","|    layer3.18.conv2             |    0.59M               |    1.265G  |\n","|    layer3.18.bn2               |    0.512K              |    1.098M  |\n","|    layer3.18.conv3             |    0.262M              |    0.562G  |\n","|    layer3.18.bn3               |    2.048K              |    4.393M  |\n","|   layer3.19                    |   1.117M               |   2.396G   |\n","|    layer3.19.conv1             |    0.262M              |    0.562G  |\n","|    layer3.19.bn1               |    0.512K              |    1.098M  |\n","|    layer3.19.conv2             |    0.59M               |    1.265G  |\n","|    layer3.19.bn2               |    0.512K              |    1.098M  |\n","|    layer3.19.conv3             |    0.262M              |    0.562G  |\n","|    layer3.19.bn3               |    2.048K              |    4.393M  |\n","|   layer3.20                    |   1.117M               |   2.396G   |\n","|    layer3.20.conv1             |    0.262M              |    0.562G  |\n","|    layer3.20.bn1               |    0.512K              |    1.098M  |\n","|    layer3.20.conv2             |    0.59M               |    1.265G  |\n","|    layer3.20.bn2               |    0.512K              |    1.098M  |\n","|    layer3.20.conv3             |    0.262M              |    0.562G  |\n","|    layer3.20.bn3               |    2.048K              |    4.393M  |\n","|   layer3.21                    |   1.117M               |   2.396G   |\n","|    layer3.21.conv1             |    0.262M              |    0.562G  |\n","|    layer3.21.bn1               |    0.512K              |    1.098M  |\n","|    layer3.21.conv2             |    0.59M               |    1.265G  |\n","|    layer3.21.bn2               |    0.512K              |    1.098M  |\n","|    layer3.21.conv3             |    0.262M              |    0.562G  |\n","|    layer3.21.bn3               |    2.048K              |    4.393M  |\n","|   layer3.22                    |   1.117M               |   2.396G   |\n","|    layer3.22.conv1             |    0.262M              |    0.562G  |\n","|    layer3.22.bn1               |    0.512K              |    1.098M  |\n","|    layer3.22.conv2             |    0.59M               |    1.265G  |\n","|    layer3.22.bn2               |    0.512K              |    1.098M  |\n","|    layer3.22.conv3             |    0.262M              |    0.562G  |\n","|    layer3.22.bn3               |    2.048K              |    4.393M  |\n","|  layer4                        |  14.965M               |  32.099G   |\n","|   layer4.0                     |   6.04M                |   12.955G  |\n","|    layer4.0.conv1              |    0.524M              |    1.125G  |\n","|    layer4.0.bn1                |    1.024K              |    2.196M  |\n","|    layer4.0.conv2              |    2.359M              |    5.061G  |\n","|    layer4.0.bn2                |    1.024K              |    2.196M  |\n","|    layer4.0.conv3              |    1.049M              |    2.249G  |\n","|    layer4.0.bn3                |    4.096K              |    8.786M  |\n","|    layer4.0.downsample         |    2.101M              |    4.507G  |\n","|   layer4.1                     |   4.463M               |   9.572G   |\n","|    layer4.1.conv1              |    1.049M              |    2.249G  |\n","|    layer4.1.bn1                |    1.024K              |    2.196M  |\n","|    layer4.1.conv2              |    2.359M              |    5.061G  |\n","|    layer4.1.bn2                |    1.024K              |    2.196M  |\n","|    layer4.1.conv3              |    1.049M              |    2.249G  |\n","|    layer4.1.bn3                |    4.096K              |    8.786M  |\n","|   layer4.2                     |   4.463M               |   9.572G   |\n","|    layer4.2.conv1              |    1.049M              |    2.249G  |\n","|    layer4.2.bn1                |    1.024K              |    2.196M  |\n","|    layer4.2.conv2              |    2.359M              |    5.061G  |\n","|    layer4.2.bn2                |    1.024K              |    2.196M  |\n","|    layer4.2.conv3              |    1.049M              |    2.249G  |\n","|    layer4.2.bn3                |    4.096K              |    8.786M  |\n","|  layer6.conv2d_list            |  1.401M                |  3.005G    |\n","|   layer6.conv2d_list.0         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.1         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.2         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.3         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n","\n","\n","mIoU: 8.854%, Latency: 0.140, FPS: 63.340\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>▁</td></tr><tr><td>latency</td><td>▁</td></tr><tr><td>loss</td><td>█▂▂▁▁</td></tr><tr><td>mIOU</td><td>▁▃▆█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>63.34041</td></tr><tr><td>latency</td><td>0.13987</td></tr><tr><td>loss</td><td>1.14011</td></tr><tr><td>mIOU</td><td>0.08854</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">decent-sweep-1</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/ebq7xakp' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/ebq7xakp</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240519_114135-ebq7xakp/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1of7cgqi with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_123113-1of7cgqi</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/1of7cgqi' target=\"_blank\">smooth-sweep-2</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/1of7cgqi' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/1of7cgqi</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Deeplab pretraining loading...\n","----------------------------------\n","Loss after 1 epochs: 1.149\n","mIOU after 1 epochs: 0.160%\n","----------------------------------\n","Loss after 2 epochs: 0.749\n","mIOU after 2 epochs: 0.200%\n","----------------------------------\n","Loss after 3 epochs: 0.634\n","mIOU after 3 epochs: 0.215%\n","----------------------------------\n","Loss after 4 epochs: 0.571\n","mIOU after 4 epochs: 0.225%\n","----------------------------------\n","Loss after 5 epochs: 0.533\n","mIOU after 5 epochs: 0.233%\n","| module                         | #parameters or shape   | #flops     |\n","|:-------------------------------|:-----------------------|:-----------|\n","| model                          | 43.901M                | 95.816G    |\n","|  conv1                         |  9.408K                |  0.308G    |\n","|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n","|  bn1                           |  0.128K                |  4.194M    |\n","|   bn1.weight                   |   (64,)                |            |\n","|   bn1.bias                     |   (64,)                |            |\n","|  layer1                        |  0.216M                |  1.81G     |\n","|   layer1.0                     |   75.008K              |   0.629G   |\n","|    layer1.0.conv1              |    4.096K              |    34.345M |\n","|    layer1.0.bn1                |    0.128K              |    1.073M  |\n","|    layer1.0.conv2              |    36.864K             |    0.309G  |\n","|    layer1.0.bn2                |    0.128K              |    1.073M  |\n","|    layer1.0.conv3              |    16.384K             |    0.137G  |\n","|    layer1.0.bn3                |    0.512K              |    4.293M  |\n","|    layer1.0.downsample         |    16.896K             |    0.142G  |\n","|   layer1.1                     |   70.4K                |   0.59G    |\n","|    layer1.1.conv1              |    16.384K             |    0.137G  |\n","|    layer1.1.bn1                |    0.128K              |    1.073M  |\n","|    layer1.1.conv2              |    36.864K             |    0.309G  |\n","|    layer1.1.bn2                |    0.128K              |    1.073M  |\n","|    layer1.1.conv3              |    16.384K             |    0.137G  |\n","|    layer1.1.bn3                |    0.512K              |    4.293M  |\n","|   layer1.2                     |   70.4K                |   0.59G    |\n","|    layer1.2.conv1              |    16.384K             |    0.137G  |\n","|    layer1.2.bn1                |    0.128K              |    1.073M  |\n","|    layer1.2.conv2              |    36.864K             |    0.309G  |\n","|    layer1.2.bn2                |    0.128K              |    1.073M  |\n","|    layer1.2.conv3              |    16.384K             |    0.137G  |\n","|    layer1.2.bn3                |    0.512K              |    4.293M  |\n","|  layer2                        |  1.22M                 |  2.616G    |\n","|   layer2.0                     |   0.379M               |   0.814G   |\n","|    layer2.0.conv1              |    32.768K             |    70.287M |\n","|    layer2.0.bn1                |    0.256K              |    0.549M  |\n","|    layer2.0.conv2              |    0.147M              |    0.316G  |\n","|    layer2.0.bn2                |    0.256K              |    0.549M  |\n","|    layer2.0.conv3              |    65.536K             |    0.141G  |\n","|    layer2.0.bn3                |    1.024K              |    2.196M  |\n","|    layer2.0.downsample         |    0.132M              |    0.283G  |\n","|   layer2.1                     |   0.28M                |   0.601G   |\n","|    layer2.1.conv1              |    65.536K             |    0.141G  |\n","|    layer2.1.bn1                |    0.256K              |    0.549M  |\n","|    layer2.1.conv2              |    0.147M              |    0.316G  |\n","|    layer2.1.bn2                |    0.256K              |    0.549M  |\n","|    layer2.1.conv3              |    65.536K             |    0.141G  |\n","|    layer2.1.bn3                |    1.024K              |    2.196M  |\n","|   layer2.2                     |   0.28M                |   0.601G   |\n","|    layer2.2.conv1              |    65.536K             |    0.141G  |\n","|    layer2.2.bn1                |    0.256K              |    0.549M  |\n","|    layer2.2.conv2              |    0.147M              |    0.316G  |\n","|    layer2.2.bn2                |    0.256K              |    0.549M  |\n","|    layer2.2.conv3              |    65.536K             |    0.141G  |\n","|    layer2.2.bn3                |    1.024K              |    2.196M  |\n","|   layer2.3                     |   0.28M                |   0.601G   |\n","|    layer2.3.conv1              |    65.536K             |    0.141G  |\n","|    layer2.3.bn1                |    0.256K              |    0.549M  |\n","|    layer2.3.conv2              |    0.147M              |    0.316G  |\n","|    layer2.3.bn2                |    0.256K              |    0.549M  |\n","|    layer2.3.conv3              |    65.536K             |    0.141G  |\n","|    layer2.3.bn3                |    1.024K              |    2.196M  |\n","|  layer3                        |  26.09M                |  55.964G   |\n","|   layer3.0                     |   1.512M               |   3.244G   |\n","|    layer3.0.conv1              |    0.131M              |    0.281G  |\n","|    layer3.0.bn1                |    0.512K              |    1.098M  |\n","|    layer3.0.conv2              |    0.59M               |    1.265G  |\n","|    layer3.0.bn2                |    0.512K              |    1.098M  |\n","|    layer3.0.conv3              |    0.262M              |    0.562G  |\n","|    layer3.0.bn3                |    2.048K              |    4.393M  |\n","|    layer3.0.downsample         |    0.526M              |    1.129G  |\n","|   layer3.1                     |   1.117M               |   2.396G   |\n","|    layer3.1.conv1              |    0.262M              |    0.562G  |\n","|    layer3.1.bn1                |    0.512K              |    1.098M  |\n","|    layer3.1.conv2              |    0.59M               |    1.265G  |\n","|    layer3.1.bn2                |    0.512K              |    1.098M  |\n","|    layer3.1.conv3              |    0.262M              |    0.562G  |\n","|    layer3.1.bn3                |    2.048K              |    4.393M  |\n","|   layer3.2                     |   1.117M               |   2.396G   |\n","|    layer3.2.conv1              |    0.262M              |    0.562G  |\n","|    layer3.2.bn1                |    0.512K              |    1.098M  |\n","|    layer3.2.conv2              |    0.59M               |    1.265G  |\n","|    layer3.2.bn2                |    0.512K              |    1.098M  |\n","|    layer3.2.conv3              |    0.262M              |    0.562G  |\n","|    layer3.2.bn3                |    2.048K              |    4.393M  |\n","|   layer3.3                     |   1.117M               |   2.396G   |\n","|    layer3.3.conv1              |    0.262M              |    0.562G  |\n","|    layer3.3.bn1                |    0.512K              |    1.098M  |\n","|    layer3.3.conv2              |    0.59M               |    1.265G  |\n","|    layer3.3.bn2                |    0.512K              |    1.098M  |\n","|    layer3.3.conv3              |    0.262M              |    0.562G  |\n","|    layer3.3.bn3                |    2.048K              |    4.393M  |\n","|   layer3.4                     |   1.117M               |   2.396G   |\n","|    layer3.4.conv1              |    0.262M              |    0.562G  |\n","|    layer3.4.bn1                |    0.512K              |    1.098M  |\n","|    layer3.4.conv2              |    0.59M               |    1.265G  |\n","|    layer3.4.bn2                |    0.512K              |    1.098M  |\n","|    layer3.4.conv3              |    0.262M              |    0.562G  |\n","|    layer3.4.bn3                |    2.048K              |    4.393M  |\n","|   layer3.5                     |   1.117M               |   2.396G   |\n","|    layer3.5.conv1              |    0.262M              |    0.562G  |\n","|    layer3.5.bn1                |    0.512K              |    1.098M  |\n","|    layer3.5.conv2              |    0.59M               |    1.265G  |\n","|    layer3.5.bn2                |    0.512K              |    1.098M  |\n","|    layer3.5.conv3              |    0.262M              |    0.562G  |\n","|    layer3.5.bn3                |    2.048K              |    4.393M  |\n","|   layer3.6                     |   1.117M               |   2.396G   |\n","|    layer3.6.conv1              |    0.262M              |    0.562G  |\n","|    layer3.6.bn1                |    0.512K              |    1.098M  |\n","|    layer3.6.conv2              |    0.59M               |    1.265G  |\n","|    layer3.6.bn2                |    0.512K              |    1.098M  |\n","|    layer3.6.conv3              |    0.262M              |    0.562G  |\n","|    layer3.6.bn3                |    2.048K              |    4.393M  |\n","|   layer3.7                     |   1.117M               |   2.396G   |\n","|    layer3.7.conv1              |    0.262M              |    0.562G  |\n","|    layer3.7.bn1                |    0.512K              |    1.098M  |\n","|    layer3.7.conv2              |    0.59M               |    1.265G  |\n","|    layer3.7.bn2                |    0.512K              |    1.098M  |\n","|    layer3.7.conv3              |    0.262M              |    0.562G  |\n","|    layer3.7.bn3                |    2.048K              |    4.393M  |\n","|   layer3.8                     |   1.117M               |   2.396G   |\n","|    layer3.8.conv1              |    0.262M              |    0.562G  |\n","|    layer3.8.bn1                |    0.512K              |    1.098M  |\n","|    layer3.8.conv2              |    0.59M               |    1.265G  |\n","|    layer3.8.bn2                |    0.512K              |    1.098M  |\n","|    layer3.8.conv3              |    0.262M              |    0.562G  |\n","|    layer3.8.bn3                |    2.048K              |    4.393M  |\n","|   layer3.9                     |   1.117M               |   2.396G   |\n","|    layer3.9.conv1              |    0.262M              |    0.562G  |\n","|    layer3.9.bn1                |    0.512K              |    1.098M  |\n","|    layer3.9.conv2              |    0.59M               |    1.265G  |\n","|    layer3.9.bn2                |    0.512K              |    1.098M  |\n","|    layer3.9.conv3              |    0.262M              |    0.562G  |\n","|    layer3.9.bn3                |    2.048K              |    4.393M  |\n","|   layer3.10                    |   1.117M               |   2.396G   |\n","|    layer3.10.conv1             |    0.262M              |    0.562G  |\n","|    layer3.10.bn1               |    0.512K              |    1.098M  |\n","|    layer3.10.conv2             |    0.59M               |    1.265G  |\n","|    layer3.10.bn2               |    0.512K              |    1.098M  |\n","|    layer3.10.conv3             |    0.262M              |    0.562G  |\n","|    layer3.10.bn3               |    2.048K              |    4.393M  |\n","|   layer3.11                    |   1.117M               |   2.396G   |\n","|    layer3.11.conv1             |    0.262M              |    0.562G  |\n","|    layer3.11.bn1               |    0.512K              |    1.098M  |\n","|    layer3.11.conv2             |    0.59M               |    1.265G  |\n","|    layer3.11.bn2               |    0.512K              |    1.098M  |\n","|    layer3.11.conv3             |    0.262M              |    0.562G  |\n","|    layer3.11.bn3               |    2.048K              |    4.393M  |\n","|   layer3.12                    |   1.117M               |   2.396G   |\n","|    layer3.12.conv1             |    0.262M              |    0.562G  |\n","|    layer3.12.bn1               |    0.512K              |    1.098M  |\n","|    layer3.12.conv2             |    0.59M               |    1.265G  |\n","|    layer3.12.bn2               |    0.512K              |    1.098M  |\n","|    layer3.12.conv3             |    0.262M              |    0.562G  |\n","|    layer3.12.bn3               |    2.048K              |    4.393M  |\n","|   layer3.13                    |   1.117M               |   2.396G   |\n","|    layer3.13.conv1             |    0.262M              |    0.562G  |\n","|    layer3.13.bn1               |    0.512K              |    1.098M  |\n","|    layer3.13.conv2             |    0.59M               |    1.265G  |\n","|    layer3.13.bn2               |    0.512K              |    1.098M  |\n","|    layer3.13.conv3             |    0.262M              |    0.562G  |\n","|    layer3.13.bn3               |    2.048K              |    4.393M  |\n","|   layer3.14                    |   1.117M               |   2.396G   |\n","|    layer3.14.conv1             |    0.262M              |    0.562G  |\n","|    layer3.14.bn1               |    0.512K              |    1.098M  |\n","|    layer3.14.conv2             |    0.59M               |    1.265G  |\n","|    layer3.14.bn2               |    0.512K              |    1.098M  |\n","|    layer3.14.conv3             |    0.262M              |    0.562G  |\n","|    layer3.14.bn3               |    2.048K              |    4.393M  |\n","|   layer3.15                    |   1.117M               |   2.396G   |\n","|    layer3.15.conv1             |    0.262M              |    0.562G  |\n","|    layer3.15.bn1               |    0.512K              |    1.098M  |\n","|    layer3.15.conv2             |    0.59M               |    1.265G  |\n","|    layer3.15.bn2               |    0.512K              |    1.098M  |\n","|    layer3.15.conv3             |    0.262M              |    0.562G  |\n","|    layer3.15.bn3               |    2.048K              |    4.393M  |\n","|   layer3.16                    |   1.117M               |   2.396G   |\n","|    layer3.16.conv1             |    0.262M              |    0.562G  |\n","|    layer3.16.bn1               |    0.512K              |    1.098M  |\n","|    layer3.16.conv2             |    0.59M               |    1.265G  |\n","|    layer3.16.bn2               |    0.512K              |    1.098M  |\n","|    layer3.16.conv3             |    0.262M              |    0.562G  |\n","|    layer3.16.bn3               |    2.048K              |    4.393M  |\n","|   layer3.17                    |   1.117M               |   2.396G   |\n","|    layer3.17.conv1             |    0.262M              |    0.562G  |\n","|    layer3.17.bn1               |    0.512K              |    1.098M  |\n","|    layer3.17.conv2             |    0.59M               |    1.265G  |\n","|    layer3.17.bn2               |    0.512K              |    1.098M  |\n","|    layer3.17.conv3             |    0.262M              |    0.562G  |\n","|    layer3.17.bn3               |    2.048K              |    4.393M  |\n","|   layer3.18                    |   1.117M               |   2.396G   |\n","|    layer3.18.conv1             |    0.262M              |    0.562G  |\n","|    layer3.18.bn1               |    0.512K              |    1.098M  |\n","|    layer3.18.conv2             |    0.59M               |    1.265G  |\n","|    layer3.18.bn2               |    0.512K              |    1.098M  |\n","|    layer3.18.conv3             |    0.262M              |    0.562G  |\n","|    layer3.18.bn3               |    2.048K              |    4.393M  |\n","|   layer3.19                    |   1.117M               |   2.396G   |\n","|    layer3.19.conv1             |    0.262M              |    0.562G  |\n","|    layer3.19.bn1               |    0.512K              |    1.098M  |\n","|    layer3.19.conv2             |    0.59M               |    1.265G  |\n","|    layer3.19.bn2               |    0.512K              |    1.098M  |\n","|    layer3.19.conv3             |    0.262M              |    0.562G  |\n","|    layer3.19.bn3               |    2.048K              |    4.393M  |\n","|   layer3.20                    |   1.117M               |   2.396G   |\n","|    layer3.20.conv1             |    0.262M              |    0.562G  |\n","|    layer3.20.bn1               |    0.512K              |    1.098M  |\n","|    layer3.20.conv2             |    0.59M               |    1.265G  |\n","|    layer3.20.bn2               |    0.512K              |    1.098M  |\n","|    layer3.20.conv3             |    0.262M              |    0.562G  |\n","|    layer3.20.bn3               |    2.048K              |    4.393M  |\n","|   layer3.21                    |   1.117M               |   2.396G   |\n","|    layer3.21.conv1             |    0.262M              |    0.562G  |\n","|    layer3.21.bn1               |    0.512K              |    1.098M  |\n","|    layer3.21.conv2             |    0.59M               |    1.265G  |\n","|    layer3.21.bn2               |    0.512K              |    1.098M  |\n","|    layer3.21.conv3             |    0.262M              |    0.562G  |\n","|    layer3.21.bn3               |    2.048K              |    4.393M  |\n","|   layer3.22                    |   1.117M               |   2.396G   |\n","|    layer3.22.conv1             |    0.262M              |    0.562G  |\n","|    layer3.22.bn1               |    0.512K              |    1.098M  |\n","|    layer3.22.conv2             |    0.59M               |    1.265G  |\n","|    layer3.22.bn2               |    0.512K              |    1.098M  |\n","|    layer3.22.conv3             |    0.262M              |    0.562G  |\n","|    layer3.22.bn3               |    2.048K              |    4.393M  |\n","|  layer4                        |  14.965M               |  32.099G   |\n","|   layer4.0                     |   6.04M                |   12.955G  |\n","|    layer4.0.conv1              |    0.524M              |    1.125G  |\n","|    layer4.0.bn1                |    1.024K              |    2.196M  |\n","|    layer4.0.conv2              |    2.359M              |    5.061G  |\n","|    layer4.0.bn2                |    1.024K              |    2.196M  |\n","|    layer4.0.conv3              |    1.049M              |    2.249G  |\n","|    layer4.0.bn3                |    4.096K              |    8.786M  |\n","|    layer4.0.downsample         |    2.101M              |    4.507G  |\n","|   layer4.1                     |   4.463M               |   9.572G   |\n","|    layer4.1.conv1              |    1.049M              |    2.249G  |\n","|    layer4.1.bn1                |    1.024K              |    2.196M  |\n","|    layer4.1.conv2              |    2.359M              |    5.061G  |\n","|    layer4.1.bn2                |    1.024K              |    2.196M  |\n","|    layer4.1.conv3              |    1.049M              |    2.249G  |\n","|    layer4.1.bn3                |    4.096K              |    8.786M  |\n","|   layer4.2                     |   4.463M               |   9.572G   |\n","|    layer4.2.conv1              |    1.049M              |    2.249G  |\n","|    layer4.2.bn1                |    1.024K              |    2.196M  |\n","|    layer4.2.conv2              |    2.359M              |    5.061G  |\n","|    layer4.2.bn2                |    1.024K              |    2.196M  |\n","|    layer4.2.conv3              |    1.049M              |    2.249G  |\n","|    layer4.2.bn3                |    4.096K              |    8.786M  |\n","|  layer6.conv2d_list            |  1.401M                |  3.005G    |\n","|   layer6.conv2d_list.0         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.1         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.2         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.3         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n","\n","\n","mIoU: 21.439%, Latency: 0.116, FPS: 65.389\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>▁</td></tr><tr><td>latency</td><td>▁</td></tr><tr><td>loss</td><td>█▃▂▁▁</td></tr><tr><td>mIOU</td><td>▁▅▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>65.38925</td></tr><tr><td>latency</td><td>0.11648</td></tr><tr><td>loss</td><td>0.53347</td></tr><tr><td>mIOU</td><td>0.21439</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">smooth-sweep-2</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/1of7cgqi' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/1of7cgqi</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240519_123113-1of7cgqi/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xjb1rfba with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_132306-xjb1rfba</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/xjb1rfba' target=\"_blank\">genial-sweep-3</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/xjb1rfba' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/xjb1rfba</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Deeplab pretraining loading...\n","----------------------------------\n","Loss after 1 epochs: 1.144\n","mIOU after 1 epochs: 0.160%\n","----------------------------------\n","Loss after 2 epochs: 0.760\n","mIOU after 2 epochs: 0.199%\n","----------------------------------\n","Loss after 3 epochs: 0.641\n","mIOU after 3 epochs: 0.215%\n","----------------------------------\n","Loss after 4 epochs: 0.575\n","mIOU after 4 epochs: 0.225%\n","----------------------------------\n","Loss after 5 epochs: 0.536\n","mIOU after 5 epochs: 0.232%\n","| module                         | #parameters or shape   | #flops     |\n","|:-------------------------------|:-----------------------|:-----------|\n","| model                          | 43.901M                | 95.816G    |\n","|  conv1                         |  9.408K                |  0.308G    |\n","|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n","|  bn1                           |  0.128K                |  4.194M    |\n","|   bn1.weight                   |   (64,)                |            |\n","|   bn1.bias                     |   (64,)                |            |\n","|  layer1                        |  0.216M                |  1.81G     |\n","|   layer1.0                     |   75.008K              |   0.629G   |\n","|    layer1.0.conv1              |    4.096K              |    34.345M |\n","|    layer1.0.bn1                |    0.128K              |    1.073M  |\n","|    layer1.0.conv2              |    36.864K             |    0.309G  |\n","|    layer1.0.bn2                |    0.128K              |    1.073M  |\n","|    layer1.0.conv3              |    16.384K             |    0.137G  |\n","|    layer1.0.bn3                |    0.512K              |    4.293M  |\n","|    layer1.0.downsample         |    16.896K             |    0.142G  |\n","|   layer1.1                     |   70.4K                |   0.59G    |\n","|    layer1.1.conv1              |    16.384K             |    0.137G  |\n","|    layer1.1.bn1                |    0.128K              |    1.073M  |\n","|    layer1.1.conv2              |    36.864K             |    0.309G  |\n","|    layer1.1.bn2                |    0.128K              |    1.073M  |\n","|    layer1.1.conv3              |    16.384K             |    0.137G  |\n","|    layer1.1.bn3                |    0.512K              |    4.293M  |\n","|   layer1.2                     |   70.4K                |   0.59G    |\n","|    layer1.2.conv1              |    16.384K             |    0.137G  |\n","|    layer1.2.bn1                |    0.128K              |    1.073M  |\n","|    layer1.2.conv2              |    36.864K             |    0.309G  |\n","|    layer1.2.bn2                |    0.128K              |    1.073M  |\n","|    layer1.2.conv3              |    16.384K             |    0.137G  |\n","|    layer1.2.bn3                |    0.512K              |    4.293M  |\n","|  layer2                        |  1.22M                 |  2.616G    |\n","|   layer2.0                     |   0.379M               |   0.814G   |\n","|    layer2.0.conv1              |    32.768K             |    70.287M |\n","|    layer2.0.bn1                |    0.256K              |    0.549M  |\n","|    layer2.0.conv2              |    0.147M              |    0.316G  |\n","|    layer2.0.bn2                |    0.256K              |    0.549M  |\n","|    layer2.0.conv3              |    65.536K             |    0.141G  |\n","|    layer2.0.bn3                |    1.024K              |    2.196M  |\n","|    layer2.0.downsample         |    0.132M              |    0.283G  |\n","|   layer2.1                     |   0.28M                |   0.601G   |\n","|    layer2.1.conv1              |    65.536K             |    0.141G  |\n","|    layer2.1.bn1                |    0.256K              |    0.549M  |\n","|    layer2.1.conv2              |    0.147M              |    0.316G  |\n","|    layer2.1.bn2                |    0.256K              |    0.549M  |\n","|    layer2.1.conv3              |    65.536K             |    0.141G  |\n","|    layer2.1.bn3                |    1.024K              |    2.196M  |\n","|   layer2.2                     |   0.28M                |   0.601G   |\n","|    layer2.2.conv1              |    65.536K             |    0.141G  |\n","|    layer2.2.bn1                |    0.256K              |    0.549M  |\n","|    layer2.2.conv2              |    0.147M              |    0.316G  |\n","|    layer2.2.bn2                |    0.256K              |    0.549M  |\n","|    layer2.2.conv3              |    65.536K             |    0.141G  |\n","|    layer2.2.bn3                |    1.024K              |    2.196M  |\n","|   layer2.3                     |   0.28M                |   0.601G   |\n","|    layer2.3.conv1              |    65.536K             |    0.141G  |\n","|    layer2.3.bn1                |    0.256K              |    0.549M  |\n","|    layer2.3.conv2              |    0.147M              |    0.316G  |\n","|    layer2.3.bn2                |    0.256K              |    0.549M  |\n","|    layer2.3.conv3              |    65.536K             |    0.141G  |\n","|    layer2.3.bn3                |    1.024K              |    2.196M  |\n","|  layer3                        |  26.09M                |  55.964G   |\n","|   layer3.0                     |   1.512M               |   3.244G   |\n","|    layer3.0.conv1              |    0.131M              |    0.281G  |\n","|    layer3.0.bn1                |    0.512K              |    1.098M  |\n","|    layer3.0.conv2              |    0.59M               |    1.265G  |\n","|    layer3.0.bn2                |    0.512K              |    1.098M  |\n","|    layer3.0.conv3              |    0.262M              |    0.562G  |\n","|    layer3.0.bn3                |    2.048K              |    4.393M  |\n","|    layer3.0.downsample         |    0.526M              |    1.129G  |\n","|   layer3.1                     |   1.117M               |   2.396G   |\n","|    layer3.1.conv1              |    0.262M              |    0.562G  |\n","|    layer3.1.bn1                |    0.512K              |    1.098M  |\n","|    layer3.1.conv2              |    0.59M               |    1.265G  |\n","|    layer3.1.bn2                |    0.512K              |    1.098M  |\n","|    layer3.1.conv3              |    0.262M              |    0.562G  |\n","|    layer3.1.bn3                |    2.048K              |    4.393M  |\n","|   layer3.2                     |   1.117M               |   2.396G   |\n","|    layer3.2.conv1              |    0.262M              |    0.562G  |\n","|    layer3.2.bn1                |    0.512K              |    1.098M  |\n","|    layer3.2.conv2              |    0.59M               |    1.265G  |\n","|    layer3.2.bn2                |    0.512K              |    1.098M  |\n","|    layer3.2.conv3              |    0.262M              |    0.562G  |\n","|    layer3.2.bn3                |    2.048K              |    4.393M  |\n","|   layer3.3                     |   1.117M               |   2.396G   |\n","|    layer3.3.conv1              |    0.262M              |    0.562G  |\n","|    layer3.3.bn1                |    0.512K              |    1.098M  |\n","|    layer3.3.conv2              |    0.59M               |    1.265G  |\n","|    layer3.3.bn2                |    0.512K              |    1.098M  |\n","|    layer3.3.conv3              |    0.262M              |    0.562G  |\n","|    layer3.3.bn3                |    2.048K              |    4.393M  |\n","|   layer3.4                     |   1.117M               |   2.396G   |\n","|    layer3.4.conv1              |    0.262M              |    0.562G  |\n","|    layer3.4.bn1                |    0.512K              |    1.098M  |\n","|    layer3.4.conv2              |    0.59M               |    1.265G  |\n","|    layer3.4.bn2                |    0.512K              |    1.098M  |\n","|    layer3.4.conv3              |    0.262M              |    0.562G  |\n","|    layer3.4.bn3                |    2.048K              |    4.393M  |\n","|   layer3.5                     |   1.117M               |   2.396G   |\n","|    layer3.5.conv1              |    0.262M              |    0.562G  |\n","|    layer3.5.bn1                |    0.512K              |    1.098M  |\n","|    layer3.5.conv2              |    0.59M               |    1.265G  |\n","|    layer3.5.bn2                |    0.512K              |    1.098M  |\n","|    layer3.5.conv3              |    0.262M              |    0.562G  |\n","|    layer3.5.bn3                |    2.048K              |    4.393M  |\n","|   layer3.6                     |   1.117M               |   2.396G   |\n","|    layer3.6.conv1              |    0.262M              |    0.562G  |\n","|    layer3.6.bn1                |    0.512K              |    1.098M  |\n","|    layer3.6.conv2              |    0.59M               |    1.265G  |\n","|    layer3.6.bn2                |    0.512K              |    1.098M  |\n","|    layer3.6.conv3              |    0.262M              |    0.562G  |\n","|    layer3.6.bn3                |    2.048K              |    4.393M  |\n","|   layer3.7                     |   1.117M               |   2.396G   |\n","|    layer3.7.conv1              |    0.262M              |    0.562G  |\n","|    layer3.7.bn1                |    0.512K              |    1.098M  |\n","|    layer3.7.conv2              |    0.59M               |    1.265G  |\n","|    layer3.7.bn2                |    0.512K              |    1.098M  |\n","|    layer3.7.conv3              |    0.262M              |    0.562G  |\n","|    layer3.7.bn3                |    2.048K              |    4.393M  |\n","|   layer3.8                     |   1.117M               |   2.396G   |\n","|    layer3.8.conv1              |    0.262M              |    0.562G  |\n","|    layer3.8.bn1                |    0.512K              |    1.098M  |\n","|    layer3.8.conv2              |    0.59M               |    1.265G  |\n","|    layer3.8.bn2                |    0.512K              |    1.098M  |\n","|    layer3.8.conv3              |    0.262M              |    0.562G  |\n","|    layer3.8.bn3                |    2.048K              |    4.393M  |\n","|   layer3.9                     |   1.117M               |   2.396G   |\n","|    layer3.9.conv1              |    0.262M              |    0.562G  |\n","|    layer3.9.bn1                |    0.512K              |    1.098M  |\n","|    layer3.9.conv2              |    0.59M               |    1.265G  |\n","|    layer3.9.bn2                |    0.512K              |    1.098M  |\n","|    layer3.9.conv3              |    0.262M              |    0.562G  |\n","|    layer3.9.bn3                |    2.048K              |    4.393M  |\n","|   layer3.10                    |   1.117M               |   2.396G   |\n","|    layer3.10.conv1             |    0.262M              |    0.562G  |\n","|    layer3.10.bn1               |    0.512K              |    1.098M  |\n","|    layer3.10.conv2             |    0.59M               |    1.265G  |\n","|    layer3.10.bn2               |    0.512K              |    1.098M  |\n","|    layer3.10.conv3             |    0.262M              |    0.562G  |\n","|    layer3.10.bn3               |    2.048K              |    4.393M  |\n","|   layer3.11                    |   1.117M               |   2.396G   |\n","|    layer3.11.conv1             |    0.262M              |    0.562G  |\n","|    layer3.11.bn1               |    0.512K              |    1.098M  |\n","|    layer3.11.conv2             |    0.59M               |    1.265G  |\n","|    layer3.11.bn2               |    0.512K              |    1.098M  |\n","|    layer3.11.conv3             |    0.262M              |    0.562G  |\n","|    layer3.11.bn3               |    2.048K              |    4.393M  |\n","|   layer3.12                    |   1.117M               |   2.396G   |\n","|    layer3.12.conv1             |    0.262M              |    0.562G  |\n","|    layer3.12.bn1               |    0.512K              |    1.098M  |\n","|    layer3.12.conv2             |    0.59M               |    1.265G  |\n","|    layer3.12.bn2               |    0.512K              |    1.098M  |\n","|    layer3.12.conv3             |    0.262M              |    0.562G  |\n","|    layer3.12.bn3               |    2.048K              |    4.393M  |\n","|   layer3.13                    |   1.117M               |   2.396G   |\n","|    layer3.13.conv1             |    0.262M              |    0.562G  |\n","|    layer3.13.bn1               |    0.512K              |    1.098M  |\n","|    layer3.13.conv2             |    0.59M               |    1.265G  |\n","|    layer3.13.bn2               |    0.512K              |    1.098M  |\n","|    layer3.13.conv3             |    0.262M              |    0.562G  |\n","|    layer3.13.bn3               |    2.048K              |    4.393M  |\n","|   layer3.14                    |   1.117M               |   2.396G   |\n","|    layer3.14.conv1             |    0.262M              |    0.562G  |\n","|    layer3.14.bn1               |    0.512K              |    1.098M  |\n","|    layer3.14.conv2             |    0.59M               |    1.265G  |\n","|    layer3.14.bn2               |    0.512K              |    1.098M  |\n","|    layer3.14.conv3             |    0.262M              |    0.562G  |\n","|    layer3.14.bn3               |    2.048K              |    4.393M  |\n","|   layer3.15                    |   1.117M               |   2.396G   |\n","|    layer3.15.conv1             |    0.262M              |    0.562G  |\n","|    layer3.15.bn1               |    0.512K              |    1.098M  |\n","|    layer3.15.conv2             |    0.59M               |    1.265G  |\n","|    layer3.15.bn2               |    0.512K              |    1.098M  |\n","|    layer3.15.conv3             |    0.262M              |    0.562G  |\n","|    layer3.15.bn3               |    2.048K              |    4.393M  |\n","|   layer3.16                    |   1.117M               |   2.396G   |\n","|    layer3.16.conv1             |    0.262M              |    0.562G  |\n","|    layer3.16.bn1               |    0.512K              |    1.098M  |\n","|    layer3.16.conv2             |    0.59M               |    1.265G  |\n","|    layer3.16.bn2               |    0.512K              |    1.098M  |\n","|    layer3.16.conv3             |    0.262M              |    0.562G  |\n","|    layer3.16.bn3               |    2.048K              |    4.393M  |\n","|   layer3.17                    |   1.117M               |   2.396G   |\n","|    layer3.17.conv1             |    0.262M              |    0.562G  |\n","|    layer3.17.bn1               |    0.512K              |    1.098M  |\n","|    layer3.17.conv2             |    0.59M               |    1.265G  |\n","|    layer3.17.bn2               |    0.512K              |    1.098M  |\n","|    layer3.17.conv3             |    0.262M              |    0.562G  |\n","|    layer3.17.bn3               |    2.048K              |    4.393M  |\n","|   layer3.18                    |   1.117M               |   2.396G   |\n","|    layer3.18.conv1             |    0.262M              |    0.562G  |\n","|    layer3.18.bn1               |    0.512K              |    1.098M  |\n","|    layer3.18.conv2             |    0.59M               |    1.265G  |\n","|    layer3.18.bn2               |    0.512K              |    1.098M  |\n","|    layer3.18.conv3             |    0.262M              |    0.562G  |\n","|    layer3.18.bn3               |    2.048K              |    4.393M  |\n","|   layer3.19                    |   1.117M               |   2.396G   |\n","|    layer3.19.conv1             |    0.262M              |    0.562G  |\n","|    layer3.19.bn1               |    0.512K              |    1.098M  |\n","|    layer3.19.conv2             |    0.59M               |    1.265G  |\n","|    layer3.19.bn2               |    0.512K              |    1.098M  |\n","|    layer3.19.conv3             |    0.262M              |    0.562G  |\n","|    layer3.19.bn3               |    2.048K              |    4.393M  |\n","|   layer3.20                    |   1.117M               |   2.396G   |\n","|    layer3.20.conv1             |    0.262M              |    0.562G  |\n","|    layer3.20.bn1               |    0.512K              |    1.098M  |\n","|    layer3.20.conv2             |    0.59M               |    1.265G  |\n","|    layer3.20.bn2               |    0.512K              |    1.098M  |\n","|    layer3.20.conv3             |    0.262M              |    0.562G  |\n","|    layer3.20.bn3               |    2.048K              |    4.393M  |\n","|   layer3.21                    |   1.117M               |   2.396G   |\n","|    layer3.21.conv1             |    0.262M              |    0.562G  |\n","|    layer3.21.bn1               |    0.512K              |    1.098M  |\n","|    layer3.21.conv2             |    0.59M               |    1.265G  |\n","|    layer3.21.bn2               |    0.512K              |    1.098M  |\n","|    layer3.21.conv3             |    0.262M              |    0.562G  |\n","|    layer3.21.bn3               |    2.048K              |    4.393M  |\n","|   layer3.22                    |   1.117M               |   2.396G   |\n","|    layer3.22.conv1             |    0.262M              |    0.562G  |\n","|    layer3.22.bn1               |    0.512K              |    1.098M  |\n","|    layer3.22.conv2             |    0.59M               |    1.265G  |\n","|    layer3.22.bn2               |    0.512K              |    1.098M  |\n","|    layer3.22.conv3             |    0.262M              |    0.562G  |\n","|    layer3.22.bn3               |    2.048K              |    4.393M  |\n","|  layer4                        |  14.965M               |  32.099G   |\n","|   layer4.0                     |   6.04M                |   12.955G  |\n","|    layer4.0.conv1              |    0.524M              |    1.125G  |\n","|    layer4.0.bn1                |    1.024K              |    2.196M  |\n","|    layer4.0.conv2              |    2.359M              |    5.061G  |\n","|    layer4.0.bn2                |    1.024K              |    2.196M  |\n","|    layer4.0.conv3              |    1.049M              |    2.249G  |\n","|    layer4.0.bn3                |    4.096K              |    8.786M  |\n","|    layer4.0.downsample         |    2.101M              |    4.507G  |\n","|   layer4.1                     |   4.463M               |   9.572G   |\n","|    layer4.1.conv1              |    1.049M              |    2.249G  |\n","|    layer4.1.bn1                |    1.024K              |    2.196M  |\n","|    layer4.1.conv2              |    2.359M              |    5.061G  |\n","|    layer4.1.bn2                |    1.024K              |    2.196M  |\n","|    layer4.1.conv3              |    1.049M              |    2.249G  |\n","|    layer4.1.bn3                |    4.096K              |    8.786M  |\n","|   layer4.2                     |   4.463M               |   9.572G   |\n","|    layer4.2.conv1              |    1.049M              |    2.249G  |\n","|    layer4.2.bn1                |    1.024K              |    2.196M  |\n","|    layer4.2.conv2              |    2.359M              |    5.061G  |\n","|    layer4.2.bn2                |    1.024K              |    2.196M  |\n","|    layer4.2.conv3              |    1.049M              |    2.249G  |\n","|    layer4.2.bn3                |    4.096K              |    8.786M  |\n","|  layer6.conv2d_list            |  1.401M                |  3.005G    |\n","|   layer6.conv2d_list.0         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.1         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.2         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.3         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n","\n","\n","mIoU: 21.426%, Latency: 0.118, FPS: 64.448\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>▁</td></tr><tr><td>latency</td><td>▁</td></tr><tr><td>loss</td><td>█▄▂▁▁</td></tr><tr><td>mIOU</td><td>▁▅▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>64.44818</td></tr><tr><td>latency</td><td>0.1177</td></tr><tr><td>loss</td><td>0.53576</td></tr><tr><td>mIOU</td><td>0.21426</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">genial-sweep-3</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/xjb1rfba' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/xjb1rfba</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240519_132306-xjb1rfba/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wa0tsz5z with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_141506-wa0tsz5z</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/wa0tsz5z' target=\"_blank\">lunar-sweep-4</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/wa0tsz5z' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/wa0tsz5z</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Deeplab pretraining loading...\n","----------------------------------\n","Loss after 1 epochs: 1.316\n","mIOU after 1 epochs: 0.146%\n","----------------------------------\n","Loss after 2 epochs: 0.877\n","mIOU after 2 epochs: 0.184%\n","----------------------------------\n","Loss after 3 epochs: 0.748\n","mIOU after 3 epochs: 0.199%\n","----------------------------------\n","Loss after 4 epochs: 0.666\n","mIOU after 4 epochs: 0.210%\n","----------------------------------\n","Loss after 5 epochs: 0.616\n","mIOU after 5 epochs: 0.216%\n","| module                         | #parameters or shape   | #flops     |\n","|:-------------------------------|:-----------------------|:-----------|\n","| model                          | 43.901M                | 95.816G    |\n","|  conv1                         |  9.408K                |  0.308G    |\n","|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n","|  bn1                           |  0.128K                |  4.194M    |\n","|   bn1.weight                   |   (64,)                |            |\n","|   bn1.bias                     |   (64,)                |            |\n","|  layer1                        |  0.216M                |  1.81G     |\n","|   layer1.0                     |   75.008K              |   0.629G   |\n","|    layer1.0.conv1              |    4.096K              |    34.345M |\n","|    layer1.0.bn1                |    0.128K              |    1.073M  |\n","|    layer1.0.conv2              |    36.864K             |    0.309G  |\n","|    layer1.0.bn2                |    0.128K              |    1.073M  |\n","|    layer1.0.conv3              |    16.384K             |    0.137G  |\n","|    layer1.0.bn3                |    0.512K              |    4.293M  |\n","|    layer1.0.downsample         |    16.896K             |    0.142G  |\n","|   layer1.1                     |   70.4K                |   0.59G    |\n","|    layer1.1.conv1              |    16.384K             |    0.137G  |\n","|    layer1.1.bn1                |    0.128K              |    1.073M  |\n","|    layer1.1.conv2              |    36.864K             |    0.309G  |\n","|    layer1.1.bn2                |    0.128K              |    1.073M  |\n","|    layer1.1.conv3              |    16.384K             |    0.137G  |\n","|    layer1.1.bn3                |    0.512K              |    4.293M  |\n","|   layer1.2                     |   70.4K                |   0.59G    |\n","|    layer1.2.conv1              |    16.384K             |    0.137G  |\n","|    layer1.2.bn1                |    0.128K              |    1.073M  |\n","|    layer1.2.conv2              |    36.864K             |    0.309G  |\n","|    layer1.2.bn2                |    0.128K              |    1.073M  |\n","|    layer1.2.conv3              |    16.384K             |    0.137G  |\n","|    layer1.2.bn3                |    0.512K              |    4.293M  |\n","|  layer2                        |  1.22M                 |  2.616G    |\n","|   layer2.0                     |   0.379M               |   0.814G   |\n","|    layer2.0.conv1              |    32.768K             |    70.287M |\n","|    layer2.0.bn1                |    0.256K              |    0.549M  |\n","|    layer2.0.conv2              |    0.147M              |    0.316G  |\n","|    layer2.0.bn2                |    0.256K              |    0.549M  |\n","|    layer2.0.conv3              |    65.536K             |    0.141G  |\n","|    layer2.0.bn3                |    1.024K              |    2.196M  |\n","|    layer2.0.downsample         |    0.132M              |    0.283G  |\n","|   layer2.1                     |   0.28M                |   0.601G   |\n","|    layer2.1.conv1              |    65.536K             |    0.141G  |\n","|    layer2.1.bn1                |    0.256K              |    0.549M  |\n","|    layer2.1.conv2              |    0.147M              |    0.316G  |\n","|    layer2.1.bn2                |    0.256K              |    0.549M  |\n","|    layer2.1.conv3              |    65.536K             |    0.141G  |\n","|    layer2.1.bn3                |    1.024K              |    2.196M  |\n","|   layer2.2                     |   0.28M                |   0.601G   |\n","|    layer2.2.conv1              |    65.536K             |    0.141G  |\n","|    layer2.2.bn1                |    0.256K              |    0.549M  |\n","|    layer2.2.conv2              |    0.147M              |    0.316G  |\n","|    layer2.2.bn2                |    0.256K              |    0.549M  |\n","|    layer2.2.conv3              |    65.536K             |    0.141G  |\n","|    layer2.2.bn3                |    1.024K              |    2.196M  |\n","|   layer2.3                     |   0.28M                |   0.601G   |\n","|    layer2.3.conv1              |    65.536K             |    0.141G  |\n","|    layer2.3.bn1                |    0.256K              |    0.549M  |\n","|    layer2.3.conv2              |    0.147M              |    0.316G  |\n","|    layer2.3.bn2                |    0.256K              |    0.549M  |\n","|    layer2.3.conv3              |    65.536K             |    0.141G  |\n","|    layer2.3.bn3                |    1.024K              |    2.196M  |\n","|  layer3                        |  26.09M                |  55.964G   |\n","|   layer3.0                     |   1.512M               |   3.244G   |\n","|    layer3.0.conv1              |    0.131M              |    0.281G  |\n","|    layer3.0.bn1                |    0.512K              |    1.098M  |\n","|    layer3.0.conv2              |    0.59M               |    1.265G  |\n","|    layer3.0.bn2                |    0.512K              |    1.098M  |\n","|    layer3.0.conv3              |    0.262M              |    0.562G  |\n","|    layer3.0.bn3                |    2.048K              |    4.393M  |\n","|    layer3.0.downsample         |    0.526M              |    1.129G  |\n","|   layer3.1                     |   1.117M               |   2.396G   |\n","|    layer3.1.conv1              |    0.262M              |    0.562G  |\n","|    layer3.1.bn1                |    0.512K              |    1.098M  |\n","|    layer3.1.conv2              |    0.59M               |    1.265G  |\n","|    layer3.1.bn2                |    0.512K              |    1.098M  |\n","|    layer3.1.conv3              |    0.262M              |    0.562G  |\n","|    layer3.1.bn3                |    2.048K              |    4.393M  |\n","|   layer3.2                     |   1.117M               |   2.396G   |\n","|    layer3.2.conv1              |    0.262M              |    0.562G  |\n","|    layer3.2.bn1                |    0.512K              |    1.098M  |\n","|    layer3.2.conv2              |    0.59M               |    1.265G  |\n","|    layer3.2.bn2                |    0.512K              |    1.098M  |\n","|    layer3.2.conv3              |    0.262M              |    0.562G  |\n","|    layer3.2.bn3                |    2.048K              |    4.393M  |\n","|   layer3.3                     |   1.117M               |   2.396G   |\n","|    layer3.3.conv1              |    0.262M              |    0.562G  |\n","|    layer3.3.bn1                |    0.512K              |    1.098M  |\n","|    layer3.3.conv2              |    0.59M               |    1.265G  |\n","|    layer3.3.bn2                |    0.512K              |    1.098M  |\n","|    layer3.3.conv3              |    0.262M              |    0.562G  |\n","|    layer3.3.bn3                |    2.048K              |    4.393M  |\n","|   layer3.4                     |   1.117M               |   2.396G   |\n","|    layer3.4.conv1              |    0.262M              |    0.562G  |\n","|    layer3.4.bn1                |    0.512K              |    1.098M  |\n","|    layer3.4.conv2              |    0.59M               |    1.265G  |\n","|    layer3.4.bn2                |    0.512K              |    1.098M  |\n","|    layer3.4.conv3              |    0.262M              |    0.562G  |\n","|    layer3.4.bn3                |    2.048K              |    4.393M  |\n","|   layer3.5                     |   1.117M               |   2.396G   |\n","|    layer3.5.conv1              |    0.262M              |    0.562G  |\n","|    layer3.5.bn1                |    0.512K              |    1.098M  |\n","|    layer3.5.conv2              |    0.59M               |    1.265G  |\n","|    layer3.5.bn2                |    0.512K              |    1.098M  |\n","|    layer3.5.conv3              |    0.262M              |    0.562G  |\n","|    layer3.5.bn3                |    2.048K              |    4.393M  |\n","|   layer3.6                     |   1.117M               |   2.396G   |\n","|    layer3.6.conv1              |    0.262M              |    0.562G  |\n","|    layer3.6.bn1                |    0.512K              |    1.098M  |\n","|    layer3.6.conv2              |    0.59M               |    1.265G  |\n","|    layer3.6.bn2                |    0.512K              |    1.098M  |\n","|    layer3.6.conv3              |    0.262M              |    0.562G  |\n","|    layer3.6.bn3                |    2.048K              |    4.393M  |\n","|   layer3.7                     |   1.117M               |   2.396G   |\n","|    layer3.7.conv1              |    0.262M              |    0.562G  |\n","|    layer3.7.bn1                |    0.512K              |    1.098M  |\n","|    layer3.7.conv2              |    0.59M               |    1.265G  |\n","|    layer3.7.bn2                |    0.512K              |    1.098M  |\n","|    layer3.7.conv3              |    0.262M              |    0.562G  |\n","|    layer3.7.bn3                |    2.048K              |    4.393M  |\n","|   layer3.8                     |   1.117M               |   2.396G   |\n","|    layer3.8.conv1              |    0.262M              |    0.562G  |\n","|    layer3.8.bn1                |    0.512K              |    1.098M  |\n","|    layer3.8.conv2              |    0.59M               |    1.265G  |\n","|    layer3.8.bn2                |    0.512K              |    1.098M  |\n","|    layer3.8.conv3              |    0.262M              |    0.562G  |\n","|    layer3.8.bn3                |    2.048K              |    4.393M  |\n","|   layer3.9                     |   1.117M               |   2.396G   |\n","|    layer3.9.conv1              |    0.262M              |    0.562G  |\n","|    layer3.9.bn1                |    0.512K              |    1.098M  |\n","|    layer3.9.conv2              |    0.59M               |    1.265G  |\n","|    layer3.9.bn2                |    0.512K              |    1.098M  |\n","|    layer3.9.conv3              |    0.262M              |    0.562G  |\n","|    layer3.9.bn3                |    2.048K              |    4.393M  |\n","|   layer3.10                    |   1.117M               |   2.396G   |\n","|    layer3.10.conv1             |    0.262M              |    0.562G  |\n","|    layer3.10.bn1               |    0.512K              |    1.098M  |\n","|    layer3.10.conv2             |    0.59M               |    1.265G  |\n","|    layer3.10.bn2               |    0.512K              |    1.098M  |\n","|    layer3.10.conv3             |    0.262M              |    0.562G  |\n","|    layer3.10.bn3               |    2.048K              |    4.393M  |\n","|   layer3.11                    |   1.117M               |   2.396G   |\n","|    layer3.11.conv1             |    0.262M              |    0.562G  |\n","|    layer3.11.bn1               |    0.512K              |    1.098M  |\n","|    layer3.11.conv2             |    0.59M               |    1.265G  |\n","|    layer3.11.bn2               |    0.512K              |    1.098M  |\n","|    layer3.11.conv3             |    0.262M              |    0.562G  |\n","|    layer3.11.bn3               |    2.048K              |    4.393M  |\n","|   layer3.12                    |   1.117M               |   2.396G   |\n","|    layer3.12.conv1             |    0.262M              |    0.562G  |\n","|    layer3.12.bn1               |    0.512K              |    1.098M  |\n","|    layer3.12.conv2             |    0.59M               |    1.265G  |\n","|    layer3.12.bn2               |    0.512K              |    1.098M  |\n","|    layer3.12.conv3             |    0.262M              |    0.562G  |\n","|    layer3.12.bn3               |    2.048K              |    4.393M  |\n","|   layer3.13                    |   1.117M               |   2.396G   |\n","|    layer3.13.conv1             |    0.262M              |    0.562G  |\n","|    layer3.13.bn1               |    0.512K              |    1.098M  |\n","|    layer3.13.conv2             |    0.59M               |    1.265G  |\n","|    layer3.13.bn2               |    0.512K              |    1.098M  |\n","|    layer3.13.conv3             |    0.262M              |    0.562G  |\n","|    layer3.13.bn3               |    2.048K              |    4.393M  |\n","|   layer3.14                    |   1.117M               |   2.396G   |\n","|    layer3.14.conv1             |    0.262M              |    0.562G  |\n","|    layer3.14.bn1               |    0.512K              |    1.098M  |\n","|    layer3.14.conv2             |    0.59M               |    1.265G  |\n","|    layer3.14.bn2               |    0.512K              |    1.098M  |\n","|    layer3.14.conv3             |    0.262M              |    0.562G  |\n","|    layer3.14.bn3               |    2.048K              |    4.393M  |\n","|   layer3.15                    |   1.117M               |   2.396G   |\n","|    layer3.15.conv1             |    0.262M              |    0.562G  |\n","|    layer3.15.bn1               |    0.512K              |    1.098M  |\n","|    layer3.15.conv2             |    0.59M               |    1.265G  |\n","|    layer3.15.bn2               |    0.512K              |    1.098M  |\n","|    layer3.15.conv3             |    0.262M              |    0.562G  |\n","|    layer3.15.bn3               |    2.048K              |    4.393M  |\n","|   layer3.16                    |   1.117M               |   2.396G   |\n","|    layer3.16.conv1             |    0.262M              |    0.562G  |\n","|    layer3.16.bn1               |    0.512K              |    1.098M  |\n","|    layer3.16.conv2             |    0.59M               |    1.265G  |\n","|    layer3.16.bn2               |    0.512K              |    1.098M  |\n","|    layer3.16.conv3             |    0.262M              |    0.562G  |\n","|    layer3.16.bn3               |    2.048K              |    4.393M  |\n","|   layer3.17                    |   1.117M               |   2.396G   |\n","|    layer3.17.conv1             |    0.262M              |    0.562G  |\n","|    layer3.17.bn1               |    0.512K              |    1.098M  |\n","|    layer3.17.conv2             |    0.59M               |    1.265G  |\n","|    layer3.17.bn2               |    0.512K              |    1.098M  |\n","|    layer3.17.conv3             |    0.262M              |    0.562G  |\n","|    layer3.17.bn3               |    2.048K              |    4.393M  |\n","|   layer3.18                    |   1.117M               |   2.396G   |\n","|    layer3.18.conv1             |    0.262M              |    0.562G  |\n","|    layer3.18.bn1               |    0.512K              |    1.098M  |\n","|    layer3.18.conv2             |    0.59M               |    1.265G  |\n","|    layer3.18.bn2               |    0.512K              |    1.098M  |\n","|    layer3.18.conv3             |    0.262M              |    0.562G  |\n","|    layer3.18.bn3               |    2.048K              |    4.393M  |\n","|   layer3.19                    |   1.117M               |   2.396G   |\n","|    layer3.19.conv1             |    0.262M              |    0.562G  |\n","|    layer3.19.bn1               |    0.512K              |    1.098M  |\n","|    layer3.19.conv2             |    0.59M               |    1.265G  |\n","|    layer3.19.bn2               |    0.512K              |    1.098M  |\n","|    layer3.19.conv3             |    0.262M              |    0.562G  |\n","|    layer3.19.bn3               |    2.048K              |    4.393M  |\n","|   layer3.20                    |   1.117M               |   2.396G   |\n","|    layer3.20.conv1             |    0.262M              |    0.562G  |\n","|    layer3.20.bn1               |    0.512K              |    1.098M  |\n","|    layer3.20.conv2             |    0.59M               |    1.265G  |\n","|    layer3.20.bn2               |    0.512K              |    1.098M  |\n","|    layer3.20.conv3             |    0.262M              |    0.562G  |\n","|    layer3.20.bn3               |    2.048K              |    4.393M  |\n","|   layer3.21                    |   1.117M               |   2.396G   |\n","|    layer3.21.conv1             |    0.262M              |    0.562G  |\n","|    layer3.21.bn1               |    0.512K              |    1.098M  |\n","|    layer3.21.conv2             |    0.59M               |    1.265G  |\n","|    layer3.21.bn2               |    0.512K              |    1.098M  |\n","|    layer3.21.conv3             |    0.262M              |    0.562G  |\n","|    layer3.21.bn3               |    2.048K              |    4.393M  |\n","|   layer3.22                    |   1.117M               |   2.396G   |\n","|    layer3.22.conv1             |    0.262M              |    0.562G  |\n","|    layer3.22.bn1               |    0.512K              |    1.098M  |\n","|    layer3.22.conv2             |    0.59M               |    1.265G  |\n","|    layer3.22.bn2               |    0.512K              |    1.098M  |\n","|    layer3.22.conv3             |    0.262M              |    0.562G  |\n","|    layer3.22.bn3               |    2.048K              |    4.393M  |\n","|  layer4                        |  14.965M               |  32.099G   |\n","|   layer4.0                     |   6.04M                |   12.955G  |\n","|    layer4.0.conv1              |    0.524M              |    1.125G  |\n","|    layer4.0.bn1                |    1.024K              |    2.196M  |\n","|    layer4.0.conv2              |    2.359M              |    5.061G  |\n","|    layer4.0.bn2                |    1.024K              |    2.196M  |\n","|    layer4.0.conv3              |    1.049M              |    2.249G  |\n","|    layer4.0.bn3                |    4.096K              |    8.786M  |\n","|    layer4.0.downsample         |    2.101M              |    4.507G  |\n","|   layer4.1                     |   4.463M               |   9.572G   |\n","|    layer4.1.conv1              |    1.049M              |    2.249G  |\n","|    layer4.1.bn1                |    1.024K              |    2.196M  |\n","|    layer4.1.conv2              |    2.359M              |    5.061G  |\n","|    layer4.1.bn2                |    1.024K              |    2.196M  |\n","|    layer4.1.conv3              |    1.049M              |    2.249G  |\n","|    layer4.1.bn3                |    4.096K              |    8.786M  |\n","|   layer4.2                     |   4.463M               |   9.572G   |\n","|    layer4.2.conv1              |    1.049M              |    2.249G  |\n","|    layer4.2.bn1                |    1.024K              |    2.196M  |\n","|    layer4.2.conv2              |    2.359M              |    5.061G  |\n","|    layer4.2.bn2                |    1.024K              |    2.196M  |\n","|    layer4.2.conv3              |    1.049M              |    2.249G  |\n","|    layer4.2.bn3                |    4.096K              |    8.786M  |\n","|  layer6.conv2d_list            |  1.401M                |  3.005G    |\n","|   layer6.conv2d_list.0         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.1         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.2         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.3         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n","\n","\n","mIoU: 20.096%, Latency: 0.137, FPS: 62.711\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>▁</td></tr><tr><td>latency</td><td>▁</td></tr><tr><td>loss</td><td>█▄▂▁▁</td></tr><tr><td>mIOU</td><td>▁▅▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>62.71103</td></tr><tr><td>latency</td><td>0.13693</td></tr><tr><td>loss</td><td>0.61631</td></tr><tr><td>mIOU</td><td>0.20096</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">lunar-sweep-4</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/wa0tsz5z' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/wa0tsz5z</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240519_141506-wa0tsz5z/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v24cez3b with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240519_150529-v24cez3b</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/v24cez3b' target=\"_blank\">autumn-sweep-5</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/sweeps/0bsj16g0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/v24cez3b' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/v24cez3b</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Deeplab pretraining loading...\n","----------------------------------\n","Loss after 1 epochs: 0.982\n","mIOU after 1 epochs: 0.184%\n","----------------------------------\n","Loss after 2 epochs: 0.542\n","mIOU after 2 epochs: 0.230%\n","----------------------------------\n","Loss after 3 epochs: 0.472\n","mIOU after 3 epochs: 0.245%\n","----------------------------------\n","Loss after 4 epochs: 0.433\n","mIOU after 4 epochs: 0.254%\n","----------------------------------\n","Loss after 5 epochs: 0.408\n","mIOU after 5 epochs: 0.261%\n","| module                         | #parameters or shape   | #flops     |\n","|:-------------------------------|:-----------------------|:-----------|\n","| model                          | 43.901M                | 95.816G    |\n","|  conv1                         |  9.408K                |  0.308G    |\n","|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n","|  bn1                           |  0.128K                |  4.194M    |\n","|   bn1.weight                   |   (64,)                |            |\n","|   bn1.bias                     |   (64,)                |            |\n","|  layer1                        |  0.216M                |  1.81G     |\n","|   layer1.0                     |   75.008K              |   0.629G   |\n","|    layer1.0.conv1              |    4.096K              |    34.345M |\n","|    layer1.0.bn1                |    0.128K              |    1.073M  |\n","|    layer1.0.conv2              |    36.864K             |    0.309G  |\n","|    layer1.0.bn2                |    0.128K              |    1.073M  |\n","|    layer1.0.conv3              |    16.384K             |    0.137G  |\n","|    layer1.0.bn3                |    0.512K              |    4.293M  |\n","|    layer1.0.downsample         |    16.896K             |    0.142G  |\n","|   layer1.1                     |   70.4K                |   0.59G    |\n","|    layer1.1.conv1              |    16.384K             |    0.137G  |\n","|    layer1.1.bn1                |    0.128K              |    1.073M  |\n","|    layer1.1.conv2              |    36.864K             |    0.309G  |\n","|    layer1.1.bn2                |    0.128K              |    1.073M  |\n","|    layer1.1.conv3              |    16.384K             |    0.137G  |\n","|    layer1.1.bn3                |    0.512K              |    4.293M  |\n","|   layer1.2                     |   70.4K                |   0.59G    |\n","|    layer1.2.conv1              |    16.384K             |    0.137G  |\n","|    layer1.2.bn1                |    0.128K              |    1.073M  |\n","|    layer1.2.conv2              |    36.864K             |    0.309G  |\n","|    layer1.2.bn2                |    0.128K              |    1.073M  |\n","|    layer1.2.conv3              |    16.384K             |    0.137G  |\n","|    layer1.2.bn3                |    0.512K              |    4.293M  |\n","|  layer2                        |  1.22M                 |  2.616G    |\n","|   layer2.0                     |   0.379M               |   0.814G   |\n","|    layer2.0.conv1              |    32.768K             |    70.287M |\n","|    layer2.0.bn1                |    0.256K              |    0.549M  |\n","|    layer2.0.conv2              |    0.147M              |    0.316G  |\n","|    layer2.0.bn2                |    0.256K              |    0.549M  |\n","|    layer2.0.conv3              |    65.536K             |    0.141G  |\n","|    layer2.0.bn3                |    1.024K              |    2.196M  |\n","|    layer2.0.downsample         |    0.132M              |    0.283G  |\n","|   layer2.1                     |   0.28M                |   0.601G   |\n","|    layer2.1.conv1              |    65.536K             |    0.141G  |\n","|    layer2.1.bn1                |    0.256K              |    0.549M  |\n","|    layer2.1.conv2              |    0.147M              |    0.316G  |\n","|    layer2.1.bn2                |    0.256K              |    0.549M  |\n","|    layer2.1.conv3              |    65.536K             |    0.141G  |\n","|    layer2.1.bn3                |    1.024K              |    2.196M  |\n","|   layer2.2                     |   0.28M                |   0.601G   |\n","|    layer2.2.conv1              |    65.536K             |    0.141G  |\n","|    layer2.2.bn1                |    0.256K              |    0.549M  |\n","|    layer2.2.conv2              |    0.147M              |    0.316G  |\n","|    layer2.2.bn2                |    0.256K              |    0.549M  |\n","|    layer2.2.conv3              |    65.536K             |    0.141G  |\n","|    layer2.2.bn3                |    1.024K              |    2.196M  |\n","|   layer2.3                     |   0.28M                |   0.601G   |\n","|    layer2.3.conv1              |    65.536K             |    0.141G  |\n","|    layer2.3.bn1                |    0.256K              |    0.549M  |\n","|    layer2.3.conv2              |    0.147M              |    0.316G  |\n","|    layer2.3.bn2                |    0.256K              |    0.549M  |\n","|    layer2.3.conv3              |    65.536K             |    0.141G  |\n","|    layer2.3.bn3                |    1.024K              |    2.196M  |\n","|  layer3                        |  26.09M                |  55.964G   |\n","|   layer3.0                     |   1.512M               |   3.244G   |\n","|    layer3.0.conv1              |    0.131M              |    0.281G  |\n","|    layer3.0.bn1                |    0.512K              |    1.098M  |\n","|    layer3.0.conv2              |    0.59M               |    1.265G  |\n","|    layer3.0.bn2                |    0.512K              |    1.098M  |\n","|    layer3.0.conv3              |    0.262M              |    0.562G  |\n","|    layer3.0.bn3                |    2.048K              |    4.393M  |\n","|    layer3.0.downsample         |    0.526M              |    1.129G  |\n","|   layer3.1                     |   1.117M               |   2.396G   |\n","|    layer3.1.conv1              |    0.262M              |    0.562G  |\n","|    layer3.1.bn1                |    0.512K              |    1.098M  |\n","|    layer3.1.conv2              |    0.59M               |    1.265G  |\n","|    layer3.1.bn2                |    0.512K              |    1.098M  |\n","|    layer3.1.conv3              |    0.262M              |    0.562G  |\n","|    layer3.1.bn3                |    2.048K              |    4.393M  |\n","|   layer3.2                     |   1.117M               |   2.396G   |\n","|    layer3.2.conv1              |    0.262M              |    0.562G  |\n","|    layer3.2.bn1                |    0.512K              |    1.098M  |\n","|    layer3.2.conv2              |    0.59M               |    1.265G  |\n","|    layer3.2.bn2                |    0.512K              |    1.098M  |\n","|    layer3.2.conv3              |    0.262M              |    0.562G  |\n","|    layer3.2.bn3                |    2.048K              |    4.393M  |\n","|   layer3.3                     |   1.117M               |   2.396G   |\n","|    layer3.3.conv1              |    0.262M              |    0.562G  |\n","|    layer3.3.bn1                |    0.512K              |    1.098M  |\n","|    layer3.3.conv2              |    0.59M               |    1.265G  |\n","|    layer3.3.bn2                |    0.512K              |    1.098M  |\n","|    layer3.3.conv3              |    0.262M              |    0.562G  |\n","|    layer3.3.bn3                |    2.048K              |    4.393M  |\n","|   layer3.4                     |   1.117M               |   2.396G   |\n","|    layer3.4.conv1              |    0.262M              |    0.562G  |\n","|    layer3.4.bn1                |    0.512K              |    1.098M  |\n","|    layer3.4.conv2              |    0.59M               |    1.265G  |\n","|    layer3.4.bn2                |    0.512K              |    1.098M  |\n","|    layer3.4.conv3              |    0.262M              |    0.562G  |\n","|    layer3.4.bn3                |    2.048K              |    4.393M  |\n","|   layer3.5                     |   1.117M               |   2.396G   |\n","|    layer3.5.conv1              |    0.262M              |    0.562G  |\n","|    layer3.5.bn1                |    0.512K              |    1.098M  |\n","|    layer3.5.conv2              |    0.59M               |    1.265G  |\n","|    layer3.5.bn2                |    0.512K              |    1.098M  |\n","|    layer3.5.conv3              |    0.262M              |    0.562G  |\n","|    layer3.5.bn3                |    2.048K              |    4.393M  |\n","|   layer3.6                     |   1.117M               |   2.396G   |\n","|    layer3.6.conv1              |    0.262M              |    0.562G  |\n","|    layer3.6.bn1                |    0.512K              |    1.098M  |\n","|    layer3.6.conv2              |    0.59M               |    1.265G  |\n","|    layer3.6.bn2                |    0.512K              |    1.098M  |\n","|    layer3.6.conv3              |    0.262M              |    0.562G  |\n","|    layer3.6.bn3                |    2.048K              |    4.393M  |\n","|   layer3.7                     |   1.117M               |   2.396G   |\n","|    layer3.7.conv1              |    0.262M              |    0.562G  |\n","|    layer3.7.bn1                |    0.512K              |    1.098M  |\n","|    layer3.7.conv2              |    0.59M               |    1.265G  |\n","|    layer3.7.bn2                |    0.512K              |    1.098M  |\n","|    layer3.7.conv3              |    0.262M              |    0.562G  |\n","|    layer3.7.bn3                |    2.048K              |    4.393M  |\n","|   layer3.8                     |   1.117M               |   2.396G   |\n","|    layer3.8.conv1              |    0.262M              |    0.562G  |\n","|    layer3.8.bn1                |    0.512K              |    1.098M  |\n","|    layer3.8.conv2              |    0.59M               |    1.265G  |\n","|    layer3.8.bn2                |    0.512K              |    1.098M  |\n","|    layer3.8.conv3              |    0.262M              |    0.562G  |\n","|    layer3.8.bn3                |    2.048K              |    4.393M  |\n","|   layer3.9                     |   1.117M               |   2.396G   |\n","|    layer3.9.conv1              |    0.262M              |    0.562G  |\n","|    layer3.9.bn1                |    0.512K              |    1.098M  |\n","|    layer3.9.conv2              |    0.59M               |    1.265G  |\n","|    layer3.9.bn2                |    0.512K              |    1.098M  |\n","|    layer3.9.conv3              |    0.262M              |    0.562G  |\n","|    layer3.9.bn3                |    2.048K              |    4.393M  |\n","|   layer3.10                    |   1.117M               |   2.396G   |\n","|    layer3.10.conv1             |    0.262M              |    0.562G  |\n","|    layer3.10.bn1               |    0.512K              |    1.098M  |\n","|    layer3.10.conv2             |    0.59M               |    1.265G  |\n","|    layer3.10.bn2               |    0.512K              |    1.098M  |\n","|    layer3.10.conv3             |    0.262M              |    0.562G  |\n","|    layer3.10.bn3               |    2.048K              |    4.393M  |\n","|   layer3.11                    |   1.117M               |   2.396G   |\n","|    layer3.11.conv1             |    0.262M              |    0.562G  |\n","|    layer3.11.bn1               |    0.512K              |    1.098M  |\n","|    layer3.11.conv2             |    0.59M               |    1.265G  |\n","|    layer3.11.bn2               |    0.512K              |    1.098M  |\n","|    layer3.11.conv3             |    0.262M              |    0.562G  |\n","|    layer3.11.bn3               |    2.048K              |    4.393M  |\n","|   layer3.12                    |   1.117M               |   2.396G   |\n","|    layer3.12.conv1             |    0.262M              |    0.562G  |\n","|    layer3.12.bn1               |    0.512K              |    1.098M  |\n","|    layer3.12.conv2             |    0.59M               |    1.265G  |\n","|    layer3.12.bn2               |    0.512K              |    1.098M  |\n","|    layer3.12.conv3             |    0.262M              |    0.562G  |\n","|    layer3.12.bn3               |    2.048K              |    4.393M  |\n","|   layer3.13                    |   1.117M               |   2.396G   |\n","|    layer3.13.conv1             |    0.262M              |    0.562G  |\n","|    layer3.13.bn1               |    0.512K              |    1.098M  |\n","|    layer3.13.conv2             |    0.59M               |    1.265G  |\n","|    layer3.13.bn2               |    0.512K              |    1.098M  |\n","|    layer3.13.conv3             |    0.262M              |    0.562G  |\n","|    layer3.13.bn3               |    2.048K              |    4.393M  |\n","|   layer3.14                    |   1.117M               |   2.396G   |\n","|    layer3.14.conv1             |    0.262M              |    0.562G  |\n","|    layer3.14.bn1               |    0.512K              |    1.098M  |\n","|    layer3.14.conv2             |    0.59M               |    1.265G  |\n","|    layer3.14.bn2               |    0.512K              |    1.098M  |\n","|    layer3.14.conv3             |    0.262M              |    0.562G  |\n","|    layer3.14.bn3               |    2.048K              |    4.393M  |\n","|   layer3.15                    |   1.117M               |   2.396G   |\n","|    layer3.15.conv1             |    0.262M              |    0.562G  |\n","|    layer3.15.bn1               |    0.512K              |    1.098M  |\n","|    layer3.15.conv2             |    0.59M               |    1.265G  |\n","|    layer3.15.bn2               |    0.512K              |    1.098M  |\n","|    layer3.15.conv3             |    0.262M              |    0.562G  |\n","|    layer3.15.bn3               |    2.048K              |    4.393M  |\n","|   layer3.16                    |   1.117M               |   2.396G   |\n","|    layer3.16.conv1             |    0.262M              |    0.562G  |\n","|    layer3.16.bn1               |    0.512K              |    1.098M  |\n","|    layer3.16.conv2             |    0.59M               |    1.265G  |\n","|    layer3.16.bn2               |    0.512K              |    1.098M  |\n","|    layer3.16.conv3             |    0.262M              |    0.562G  |\n","|    layer3.16.bn3               |    2.048K              |    4.393M  |\n","|   layer3.17                    |   1.117M               |   2.396G   |\n","|    layer3.17.conv1             |    0.262M              |    0.562G  |\n","|    layer3.17.bn1               |    0.512K              |    1.098M  |\n","|    layer3.17.conv2             |    0.59M               |    1.265G  |\n","|    layer3.17.bn2               |    0.512K              |    1.098M  |\n","|    layer3.17.conv3             |    0.262M              |    0.562G  |\n","|    layer3.17.bn3               |    2.048K              |    4.393M  |\n","|   layer3.18                    |   1.117M               |   2.396G   |\n","|    layer3.18.conv1             |    0.262M              |    0.562G  |\n","|    layer3.18.bn1               |    0.512K              |    1.098M  |\n","|    layer3.18.conv2             |    0.59M               |    1.265G  |\n","|    layer3.18.bn2               |    0.512K              |    1.098M  |\n","|    layer3.18.conv3             |    0.262M              |    0.562G  |\n","|    layer3.18.bn3               |    2.048K              |    4.393M  |\n","|   layer3.19                    |   1.117M               |   2.396G   |\n","|    layer3.19.conv1             |    0.262M              |    0.562G  |\n","|    layer3.19.bn1               |    0.512K              |    1.098M  |\n","|    layer3.19.conv2             |    0.59M               |    1.265G  |\n","|    layer3.19.bn2               |    0.512K              |    1.098M  |\n","|    layer3.19.conv3             |    0.262M              |    0.562G  |\n","|    layer3.19.bn3               |    2.048K              |    4.393M  |\n","|   layer3.20                    |   1.117M               |   2.396G   |\n","|    layer3.20.conv1             |    0.262M              |    0.562G  |\n","|    layer3.20.bn1               |    0.512K              |    1.098M  |\n","|    layer3.20.conv2             |    0.59M               |    1.265G  |\n","|    layer3.20.bn2               |    0.512K              |    1.098M  |\n","|    layer3.20.conv3             |    0.262M              |    0.562G  |\n","|    layer3.20.bn3               |    2.048K              |    4.393M  |\n","|   layer3.21                    |   1.117M               |   2.396G   |\n","|    layer3.21.conv1             |    0.262M              |    0.562G  |\n","|    layer3.21.bn1               |    0.512K              |    1.098M  |\n","|    layer3.21.conv2             |    0.59M               |    1.265G  |\n","|    layer3.21.bn2               |    0.512K              |    1.098M  |\n","|    layer3.21.conv3             |    0.262M              |    0.562G  |\n","|    layer3.21.bn3               |    2.048K              |    4.393M  |\n","|   layer3.22                    |   1.117M               |   2.396G   |\n","|    layer3.22.conv1             |    0.262M              |    0.562G  |\n","|    layer3.22.bn1               |    0.512K              |    1.098M  |\n","|    layer3.22.conv2             |    0.59M               |    1.265G  |\n","|    layer3.22.bn2               |    0.512K              |    1.098M  |\n","|    layer3.22.conv3             |    0.262M              |    0.562G  |\n","|    layer3.22.bn3               |    2.048K              |    4.393M  |\n","|  layer4                        |  14.965M               |  32.099G   |\n","|   layer4.0                     |   6.04M                |   12.955G  |\n","|    layer4.0.conv1              |    0.524M              |    1.125G  |\n","|    layer4.0.bn1                |    1.024K              |    2.196M  |\n","|    layer4.0.conv2              |    2.359M              |    5.061G  |\n","|    layer4.0.bn2                |    1.024K              |    2.196M  |\n","|    layer4.0.conv3              |    1.049M              |    2.249G  |\n","|    layer4.0.bn3                |    4.096K              |    8.786M  |\n","|    layer4.0.downsample         |    2.101M              |    4.507G  |\n","|   layer4.1                     |   4.463M               |   9.572G   |\n","|    layer4.1.conv1              |    1.049M              |    2.249G  |\n","|    layer4.1.bn1                |    1.024K              |    2.196M  |\n","|    layer4.1.conv2              |    2.359M              |    5.061G  |\n","|    layer4.1.bn2                |    1.024K              |    2.196M  |\n","|    layer4.1.conv3              |    1.049M              |    2.249G  |\n","|    layer4.1.bn3                |    4.096K              |    8.786M  |\n","|   layer4.2                     |   4.463M               |   9.572G   |\n","|    layer4.2.conv1              |    1.049M              |    2.249G  |\n","|    layer4.2.bn1                |    1.024K              |    2.196M  |\n","|    layer4.2.conv2              |    2.359M              |    5.061G  |\n","|    layer4.2.bn2                |    1.024K              |    2.196M  |\n","|    layer4.2.conv3              |    1.049M              |    2.249G  |\n","|    layer4.2.bn3                |    4.096K              |    8.786M  |\n","|  layer6.conv2d_list            |  1.401M                |  3.005G    |\n","|   layer6.conv2d_list.0         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.1         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.2         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n","|   layer6.conv2d_list.3         |   0.35M                |   0.751G   |\n","|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n","|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n","\n","\n","mIoU: 23.719%, Latency: 0.148, FPS: 64.528\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>▁</td></tr><tr><td>latency</td><td>▁</td></tr><tr><td>loss</td><td>█▃▂▁▁</td></tr><tr><td>mIOU</td><td>▁▆▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FPS</td><td>64.52771</td></tr><tr><td>latency</td><td>0.14766</td></tr><tr><td>loss</td><td>0.40814</td></tr><tr><td>mIOU</td><td>0.23719</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">autumn-sweep-5</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/v24cez3b' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/v24cez3b</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240519_150529-v24cez3b/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["if torch.cuda.is_available():\n","    print(\"Start hyperparameter sweeps\\n\")\n","    wandb.agent(sweep_id, function=model_pipeline, count=5)\n","else:\n","    print(\"CUDA is Not available\")"]},{"cell_type":"markdown","metadata":{},"source":["# 8 - Build final model"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T16:43:09.093751Z","iopub.status.busy":"2024-05-25T16:43:09.093399Z","iopub.status.idle":"2024-05-25T16:43:09.102174Z","shell.execute_reply":"2024-05-25T16:43:09.101462Z","shell.execute_reply.started":"2024-05-25T16:43:09.093716Z"},"trusted":true},"outputs":[],"source":["# best configuration (TO CONFIGURE)\n","config = dict(\n","    epochs=50,\n","    batch_size=2,\n","    learning_rate=0.001,\n","    momentum=0.9,\n","    weight_decay=5e-4,\n","    architecture=\"DeepLabV2\",\n","    checkpoint_dir=\"/kaggle/working/checkpoints\" )"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T17:09:18.301722Z","iopub.status.busy":"2024-05-25T17:09:18.300810Z","iopub.status.idle":"2024-05-25T17:14:51.686942Z","shell.execute_reply":"2024-05-25T17:14:51.685620Z","shell.execute_reply.started":"2024-05-25T17:09:18.301684Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Building the model with the best configuration\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240525_170918-jnfyuzzm</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/jnfyuzzm' target=\"_blank\">ethereal-frost-31</a></strong> to <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/jnfyuzzm' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/jnfyuzzm</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Deeplab pretraining loading...\n","Checkpoint found. Resuming from epoch 1.\n","----------------------------------\n","Loss after 1 epochs: 0.848\n","mIOU after 1 epochs: 0.172%\n","Checkpoint saved in /kaggle/working/checkpoints/checkpoint.pth | Epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/tmp/ipykernel_34/254748031.py\", line 12, in model_pipeline\n","    train(model, train_loader, criterion, optimizer, config, start_epoch)\n","  File \"/tmp/ipykernel_34/1800657508.py\", line 8, in train\n","    for _, (inputs, targets) in enumerate(dataloader):\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n","    data = self._next_data()\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n","    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/tmp/ipykernel_34/1371185722.py\", line 36, in __getitem__\n","    image = Image.open(img_name).convert('RGB')\n","  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 933, in convert\n","    self.load()\n","  File \"/opt/conda/lib/python3.10/site-packages/PIL/ImageFile.py\", line 269, in load\n","    n, err_code = decoder.decode(b)\n","KeyboardInterrupt\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>mIOU</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.84764</td></tr><tr><td>mIOU</td><td>0.17162</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">ethereal-frost-31</strong> at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/jnfyuzzm' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a/runs/jnfyuzzm</a><br/> View project at: <a href='https://wandb.ai/polito-tmazzarini/MLDL-step2a' target=\"_blank\">https://wandb.ai/polito-tmazzarini/MLDL-step2a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240525_170918-jnfyuzzm/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding the model with the best configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Build, train and analyze the model with the pipeline\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA is Not available\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[9], line 12\u001b[0m, in \u001b[0;36mmodel_pipeline\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m      9\u001b[0m model, train_loader, val_loader, criterion, optimizer, start_epoch \u001b[38;5;241m=\u001b[39m make(config)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# and use them to train the model\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# and test its final performance\u001b[39;00m\n\u001b[1;32m     15\u001b[0m val(model, val_loader)\n","Cell \u001b[0;32mIn[24], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, criterion, optimizer, config, start_epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m total_mIOU \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m total_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     10\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mcuda(), id_processing(targets)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     12\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[12], line 36\u001b[0m, in \u001b[0;36mCityScapes.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m label_name \u001b[38;5;241m=\u001b[39m img_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgtFine\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_leftImg8bit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_gtFine_labelTrainIds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Load image and label\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m label \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(label_name)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_transform:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:933\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m    887\u001b[0m ):\n\u001b[1;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if torch.cuda.is_available():\n","    print(\"Building the model with the best configuration\")\n","    # Build, train and analyze the model with the pipeline\n","    model = model_pipeline(config)\n","else:\n","    print(\"CUDA is Not available\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T11:30:22.267496Z","iopub.status.busy":"2024-05-22T11:30:22.266521Z","iopub.status.idle":"2024-05-22T11:30:22.271626Z","shell.execute_reply":"2024-05-22T11:30:22.270654Z","shell.execute_reply.started":"2024-05-22T11:30:22.267459Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOekpKEeKXtTbQhIZpLmV9P","gpuType":"T4","mount_file_id":"1XNh4ReVvaCnFcvxsLVHahkWxy2OqKrm4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5000492,"sourceId":8403691,"sourceType":"datasetVersion"},{"modelInstanceId":39736,"sourceId":47461,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
